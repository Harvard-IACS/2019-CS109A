var tipuesearch = {"pages":[{"title":"Calendars","text":"pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } Select full calendar or weekly schedule tab from the spreadsheet below.","tags":"pages","url":"pages/calendars.html"},{"title":"FAQ","text":"pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } General Does the individual HW mean I have to submit on my own but can I still work with my HW partner? Individual CS109A HW means you are supposed to work on your own, without any human intervention, assistance, or input. You are not allowed to work with partner. You are allowed to use OHs to ask questions, but we may not be able to answer all of your questions or help with all of your coding. You are allowed to use all of your materials from the course up to the HW, look at problem resolution online, and look at libraries documentation. Do I have access to the video recorded materials if I am not an Extension School student? Yes. All CS109A students have access to all video captured materials. Extension School students also have access to live-streaming due to the nature of some members of the student body of that school. If you have any issues accessing the video content, please send an email to our helpline with your name and HUID. Can I access live streaming? Only Harvard Extension School students have access to live-streaming of CS109A lectures, labs, and sections. However, our Friday Standard Section will be live-streamed to all the students that wish to participate in the Helix classroom, so you can attend in person or live online. Can I make-up quizzes? No. Only 50% of quiz grades will count towards your final grade. This policy is to reduce stress and is in place so that missing a quiz on occasion should not affect your final grade. Auditors Can I audit this course? What can I and cannot do? Yes, you are welcome to audit this course and attend lecture, sections and lab. However, auditors should not submit HWs or participate in projects, and should refrain from using any course TF resources that are destined and created for our registered students like Ed. Extension School I am an Extension School Student, can I take the quizzes? And do they count towards my grade? All CS109A students have access to quizzes. If you are a Harvard Extension School student, the quizzes will not be considered towards your final grade. I am an Extension School student, can I attend lectures and OH in person? Yes, as a student from a Harvard School you are welcome to attend all learning instances (lecture, OH, Sections, and Labs) in person. Given the distance nature of the student body of Harvard Extension School, we also provide live streaming and video capture of our learning instances.","tags":"pages","url":"pages/faq.html"},{"title":"Homework Policies & Submission Instructions","text":"pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } V. September 25, 2019 General Policies Colaboration Except for HW4 and HW7 which will be done by each student individually , you're allowed and encouraged to work with a fellow student on the homework. This does not mean that you are to divide and conquer. In the spirit of learning and getting the most out of this course and out of collaborating with your peer, you should solve each problem on your own, compare with your partner, and decide on a common solution. Importing Libraries As much as possible, try and stick to the hints and functions we import at the top of the homework, as those are the ideas and tools the class supports and is aiming to teach. And if a problem specifies a particular library you're required to use that library, and possibly others from the import list. You are allowed to use other libraries such as seaborn. Submitting HW Late Submissions will not be accepted. Extensions are provided only for medical reasons with a doctor's note. If there are issues, send an email to the Helpline . Homework assignments will be done in Python in the Jupyter Notebook environment. When you are finished editing your notebook, re-run all the cells to make sure they work . Normally, you need only submit the .ipynb file with one caveat: If your notebook references other files such as images which are necessary for interpreting your work, they must be uploaded as well. You may also choose to \"attach\" the images to the notebook itself. See the section on markdown attachments under \"other additions\" here for details. Please do not submit .zip or .rar files. File Naming Convention Do not include your name in the paper or the filename as we try to keep grading as anonymous as possible. Making a HW Group in Canvas DO NOT join a group if you are submitting the assignment alone. DO NOT make new groups. Look for an empty group among the pre-made groups for each assignment and join it. Follow instructions below. Click \"People\" in the navbar Click the \"Groups\" tab Type in the search box: \"HW#\" (replace # with the homework number, e.g. HW3) Choose an empty group and have both members in your pair click \"Join\". Again, this must be done before you submit and before the homework deadline. If you haven't joined a group before the homework deadline, we will assume you are working alone. Groups do not persist across assignments. You need to make a group for every assignment. Warning: If you are submitting in a pair: both members must join a Canvas group BEFORE they submit and BEFORE the homework deadline, whichever is earlier. If your group is not in place when you submit or if you submit after the assignment deadline, then you are submitting alone. This is a Canvas limitation. Making a HW Group in Canvas Video","tags":"pages","url":"pages/hw.html"},{"title":"Videos","text":"pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } Lecture recordings can be viewed here","tags":"pages","url":"pages/videos.html"},{"title":"Projects","text":"pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } Project Guidelines Project A | Measuring our Environment: Introducing Physical Sensors Project B | Predicting the Midterm Election Project C | Predicting Types of Crime Project D | Spotify Playlist Generation Project E | Trump Tweets and Market Volatility","tags":"pages","url":"pages/projects.html"},{"title":"Resources","text":"pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } GitHub Repo Online OH Zoom Link Ed Homework Policies & Submission Instructions Setting up Anaconda & Git for Windows Forking a Repo","tags":"pages","url":"pages/resources.html"},{"title":"Schedule","text":"Week Lecture (Mon) Lecture (Wed) Lab (Thu) Advanced Section (Wed) Assignment (R:Released Tue - D:Due Wed) 1 Lecture 1: What is Data Science? Lab 1: Intro to Python (numpy, graphing libraries, program structure, Jupyter Notebook) R:HW0 2 Lecture 2: Data, Stats, and Visualization Lecture 3: Pandas and Scraping Lab 2: Python: sklearn, matplotlib R:HW1 - D:HW0 3 Lecture 4: Introduction to Regression amd kNN Regression Lecture 5: Linnear Regression, Bootstrap and Confidence Intervals Lab 3: Scikit-learn for Simple Linear Regression Advanced Section 1: Linear Algebra and Hypothesis Testing R:HW2 - D:HW1 4 Lecture 6: Multi and Poly Regression Lecture 7: Model selection and Cross Validation Lab 4: Multiple Linear Regression and Cross Validation Advanced Section 2: Regularization Methods and Their Justifications R:HW3 - D:HW2 5 Lecture 8: Regularization and EDA Lecture 9: Visualization for Communication Lab 5: Matplotlib & Seaborn No Advanced Section No Assignment 6 Lecture 10: kNN Classification & Logistic Regression I Lecture 11: Loistic Regression II Lab 6: Logistic Regression Advanced Section 3:Generalized Linear Models R:HW4 (individual) - D:HW3 7 No Lecture (Holiday) Lecture 12: Dealing with Missing Data, Imputation Lab 7: KNN Classification & Imputation No Advanced Section No Assignment 8 Lecture 13: EthiCS Lecture 14: PCA Lab 8: PCA Advanced Section 4: PCA R:HW5 - D:HW4 9 Lecture 15: Classification Trees Lecture 16: Regression Trees, Bagging, & Random Forest Lab 9: Random Forests and Boosting No Advanced Section R:HW6 - D:HW5 10 Lecture 17: Boosting Methods & Stacking Lecture 18: Neural Networks I - Perceptron, Back Propagation, SGD Lab 10: Intro to Neural Networks & Keras No Advanced Section No Assignment 11 Lecture 19: Neural Networks II - NN as Function Approximation; Design Choices Lecture 20: Neural Networks III - Dropout & Regularization Lab 11: Dropout Advanced Section 5: Decision Trees & Ensemble Methods R:HW7 (individual) - D:HW6 12 Lecture 21: Neural Networks IV - Solvers Lecture 22: Visulization for Model Interpretation Lab 12: VIZ Advanced Section 6: SGD No Assignment 13 Lecture 23: Experimental Design & Testing I No Lecture (Thanksgiving) No Lab R:HW8 - D:HW7 [Due on Tuesday] 14 Lecture 24: Experimental Design & Testing II Lab 13: Experimental Design D:HW8 15 Reading Period 16 Finals Week","tags":"pages","url":"pages/schedule.html"},{"title":"Syllabus","text":"pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } Introduction to Data Science CS 109A, STAT 121A, AC 209A, CSCI E-109A Syllabus - Fall 2019 Welcome to CS109a/STAT121a/AC209a, also offered by the DCE as CSCI E-109a, Introduction to Data Science. This course is the first half of a one‐year introduction to data science. The course focuses on the analysis of messy, real life data to perform predictions using statistical and machine learning methods. The material of the course is divided into 3 modules. Each module will integrate the five key facets of an investigation using data: 1. data collection ‐ data wrangling, cleaning, and sampling to get a suitable data set; 2. data management ‐ accessing data quickly and reliably; 3. exploratory data analysis – generating hypotheses and building intuition; 4. prediction or statistical learning; and 5. communication – summarizing results through visualization, stories, and interpretable summaries. Only one of CS 109a, AC 209a, or Stat 121a can be taken for credit. Students who have previously taken CS 109, AC 209, or Stat 121 cannot take CS 109a, AC 209a, or Stat 121a for credit. Course Logistics Prerequisites You are expected to have programming experience at the level of CS 50 or above, and statistics knowledge at the level of Stat 100 or above (Stat 110 recommended). HW0 is designed to test your knowledge on the prerequisites. Successful completion of this assignment will show that this course is suitable for you. HW0 will not be graded but you are required to submit. Course Components Lectures The class consists of two weekly lectures. Lectures are held Mon and Wed 1:30pm ‐ 2:45 pm in Northwest Building (NW), Lecture Hall B-103. Attendance to lectures is mandatory for FAS students. We will have in class quizzes to assess your understanding of the material and to help us identify gaps. Labs Labs are designed as hands-on in-class activities. The instructor will go over practice problems similar to the homework problems and review difficult material. Attendance to labs is optional but strongly encouraged . Lab sessions are held Thur 4:30-5:45 pm in Pierce 301 . Sections Lectures and labs are supplemented by 1 hour sections led by teaching fellows. There are two types of sections: a) Standard Sections : which will be a mix of review of material and practice problems similar to the HW Standard Sections are held Fri 10:30-11:45 am at 1 Story St. Room 306 and Mon 4:30-5:45 pm in Science Center 110 Note: Sections are not held every week. Consult the course calendar for exact dates. The material covered on Friday and Monday is identical. b) Advanced Sections which will cover advanced topics like the mathematical underpinnings of the methods seen in lecture and lab and extensions of those methods. The material covered in the Advanced Sections is required for all AC 209A students. Advanced Sections are held Weds 4:30-5:45 pm at Maxwell Dworkin G115 Note: Advanced Sections are not held every week. Consult the course calendar for exact dates. Video Recordings All learning instances—lectures, labs, and sections—will be recorded. DCE students can stream these events in real time with a TF monitoring the accompanying chat room. Recordings will then be made available to all students within 24 hours via Canvas. Instructor Office Hours Pavlos & Kevin : Monday 3-5pm, IACS lobby Chris : Wednesday 3-4pm, Maxwell-Dworkin B125 Assignments There will be an initial self-assessment homework called HW0 and 8 more graded homework assignments. Some of them will be due in a week (1, 2, 5, 8) and some of them in two weeks (3, 4, 6, 7). You have the option to work and submit in pairs for all the assignments except HW4 and HW7 which you will do individually. You will be working in Jupyter Notebooks which you can run in your own environment or in the SEAS JupyterHub cloud. Instructions for Setting up Your Environment Instructions for Using JupyterHub On weeks with new assignments they will be released by Wednesday 3 pm. Standard assignments are graded out of 5 points. AC209a students will have additional homework content for most assignments worth 1 point. Quizzes Quizzes will be taken at the end of class and the material will be based on what was discussed in lecture; there will be no AC209a content in the quizzes. DCE students' quizzes will not count toward their final grade. 50% of the quizzes will be dropped from your grade. Final Project There will be a final group project (2-4 students) due during Exams period. See Calendar for specific dates. Participation Students as expected to be actively engaged with the course. This includes: attending lectures making use of resources such as office hours, labs, and sections participating in the Ed discussion forum — both through asking thoughtful questions and by answering the questions of others DCE students will not be penalized for the inability to attend lectures, labs, etc. live. Recommended Textbook An Introduction to Statistical Learning by James, Witten, Hastie, Tibshirani. The book is available here: Free electronic version : http://www-bcf.usc.edu/~gareth/ISL/ (Links to an external site). HOLLIS : http://link.springer.com.ezp-prod1.hul.harvard.edu/book/10.1007%2F978-1-4614-7138-7 Amazon: https://www.amazon.com/Introduction-Statistical-Learning-Applications-Statistics/dp/1461471370 (Links to an external site) . Course Policies Getting Help For questions about homework, course content, package installation, JupyterHub, and after you have tried to troubleshoot yourselves, the process to get help is: 1. Post the question in Ed and hopefully your peers will answer. Note that in Ed questions are visible to everyone. The TFs monitor the posts. 2. Go to Office Hours , this is the best way to get help. 3. For private matters send an email to the Helpline: cs109a2019@gmail.com . The Helpline is monitored by TFs. 4. For personal and confidential matters send an email to the instructors . Grading Guidelines and Regrading Policy Homework will be graded based on: 1. How correct your code is (the Notebook cells should run, we are not troubleshooting code) 2. How you have interpreted the results — we want text not just code. It should be a report. 3. How well you present the results. The scale is 1-5. For more details, check out The CS109A Grade . Questions on Graded Homework and Regrading Policy We take great care in making sure all homework assignments are graded properly. However, if you find that your assignment has grading oversights/errors you may: Email the helpline with subject line \"Regrade HW1: Grader=johnsmith\" within 48 hours of the grade release (the grader's name can be found at the end of your notebook). If still unsatisfied with first regrading outcome, you may submit a reason via email to the Helpline with subject line \"Regrade HW1: Second request\" within 2 days of receiving the initial regarding response. NOTE: once regrading is done, you may receive a grade that could be lower than the initial grade. Collaboration Policy We encourage you to talk and discuss the assignments with your fellow students (and on Piazza), but you are not allowed to look at any other student's assignment or code outside of your pair. Discussion is encouraged; copying is not allowed. Please refer to the Academic Honesty section in The CS109A Grade . Late Day Policy Homework is due on Wednesdays. There are no late days. Late submissions will not be accepted. Communication from Staff to Students Class announcements will be through Canvas . All homework and quizzes will be posted and submitted through Canvas, as well as all feedback forms. NOTE: make sure you adjust your account settings so you can receive emails from Canvas. Submitting an assignment Please consult Homework Policies & Submission Instructions Course Grade Your final score for the course will be computed using the following weights: Non-Extension Students Assignment Final Grade Weight Homework0 1% Paired Homework (6) 39% Individual Homework (2) 17 % Quizzes 10% Project 30% Participation 3% Total 100% Extension Students Assignment Final Grade Weight Homework0 1% Paired Homework (6) 43% Individual Homework (2) 19% Project 33% Participation 4% Total 100% Software We will be using Jupyter Notebooks, Python 3, and various python modules. You can access the notebook viewer either on your own machine by installing the Anaconda platform (Links to an external site) which includes Jupyter/IPython as well all packages that will be required for the course, or by using the SEAS JupyterHub from Canvas. Details in class. Accommodations for Students with Disabilities Students needing academic adjustments or accommodations because of a documented disability must present their Faculty Letter from the Accessible Education Office (AEO) and speak with Kevin by the end of the third week of the term: Friday, September 15. Failure to do so may result in us being unable to respond in a timely manner. All discussions will remain confidential. Diversity and Inclusion Statement Data Science, like many fields of science, has historically only been represented by a small sliver of the population. This is despite some of the early computer scientist pioneers being women (see Ada Lovelace and Grace Hopper for two examples). Recent initiatives have attempted to overcome some barriers to entry: Made /w Code . We would like to attempt to discuss diversity in data science from time to time where appropriate and possible. Please contact us (in person or electronically) or submit anonymous feedback if you have any suggestions to improve the diversity of the course materials. Furthermore, we would like to create a learning environment for our students that supports a diversity of thoughts, perspectives and experiences, and honors your identities (including race, gender, class, sexuality, religion, ability, etc.) To help accomplish this:If you have a name and/or set of pronouns that differ from those that appear in your official Harvard records, please let us know! If you feel like your performance in the class is being impacted by your experiences outside of class, please don't hesitate to come and talk with us. We want to be a resource for you. Remember that you can also submit anonymous feedback (which will lead to me making a general announcement to the class, if necessary to address your concerns). If you prefer to speak with someone outside of the course, you may find helpful resources at the Harvard Office of Diversity and Inclusion. We (like many people) are still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to us about it. (Again, anonymous feedback is always an option.) As a participant in course discussions, you should also strive to honor the diversity of your classmates. Academic Honesty Ethical behavior is an important trait of a Data Scientist, from ethically handling data to attribution of code and work of others. Thus, in CS109 we give a strong emphasis to Academic Honesty. As a student your best guidelines are to be reasonable and fair. We encourage teamwork for problem sets and allow submission in pairs for most problem sets, but you should not split the homework and you should work on all the problems together. For more detailed expectations, please refer to the Academic Honesty section in The CS109A Grade .","tags":"pages","url":"pages/syllabus.html"},{"title":"S-Section 05: Logistic Regression, Multiple Logistic Regression, and KNN-classification","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109A Introduction to Data Science Standard Section 5: Logistic Regression, Multiple Logistic Regression, and KNN-classification Harvard University Fall 2019 Instructors : Pavlos Protopapas, Kevin Rader, and Chris Tanner Section Leaders : Marios Mattheakis, Abhimanyu (Abhi) Vasishth, Robbert (Rob) Struyven In this section we will be covering Linear Regression, KNN-Classification, and Logistic Regression on the famous iris dataset. Specifically, we will: Import data and data exploration. Fit a linear regression model for classification, understand drawbacks, and interpret results. Fit a simple logistic regression model for classification, compare performance, and interpret results. Visualize Predictions and Decision boundaries. Fit a higher order polynomial logistic regression model for classification, compare performance, plot decision boundaries, and interpret results. Fit a higher order polynomial logistic regression model for classification with different regularization parameters C ( [10000, 100, 1] ) Optional: Fit a KNN-classification model for classification, plot decision boundaries, and interpret results. Optional Homework Tip: Pipeline building to sequentially apply a list of transforms (e.g. scaling, polynomial feature creation) and a final estimator. For this section we will be using the following packages: In [ ]: # Data and Stats packages import numpy as np import pandas as pd import statsmodels.api as sm from statsmodels.api import OLS from sklearn import datasets from sklearn.model_selection import train_test_split from sklearn.linear_model import LogisticRegression from sklearn.linear_model import LinearRegression from sklearn.neighbors import KNeighborsClassifier from sklearn.metrics import accuracy_score # Visualization packages % matplotlib inline import matplotlib.pyplot as plt import seaborn as sns # Aesthetic settings from IPython.display import display pd . set_option ( 'display.max_columns' , 500 ) pd . set_option ( 'display.width' , 500 ) import warnings warnings . filterwarnings ( \"ignore\" ) 1. Import data and data exploration. In [ ]: dataset = datasets . load_iris () dataset . keys () What our the target and features? In [ ]: print ( dataset . target_names ) print ( dataset . feature_names ) As we can see, the response variable (y) is the flower type, it has 3 classes: setosa versicolor virginica The 4 predictor variables are flower characteristics (x): 'sepal length (cm)' 'sepal width (cm)' 'petal length (cm)' 'petal width (cm)' In [ ]: X = pd . DataFrame ( data = dataset . data , columns = dataset . feature_names ) y = pd . DataFrame ( data = dataset . target , columns = [ 'species' ]) print ( X . shape ) print ( y . shape ) In [ ]: display ( X . head ()) display ( X . describe ()) In [ ]: display ( y . head ()) display ( y . describe ()) Explore Data Check which variables have high correlations and distinctive patterns with the response. Any patterns worth mentioning? In [ ]: full_df = pd . concat ([ X , y ], axis = 1 ) full_df . head () In [ ]: sns . pairplot ( full_df ) plt . show () Are the features sepal/petal length and width uniformally distributed or do you observe some clusters of data points? What do you expect? Let's add color according to our response variable: 'species' = flower species. In [ ]: sns . pairplot ( full_df , hue = 'species' ) plt . show () Some features like 'petal length' and 'petal width' do have very high correlations and distinctive patterns with the response variable 'flower species'. When we would use these features for predicting the flower species, the classification wouldn't be very difficult. Certain ranges of 'petal length' and 'petal width' are very much correlated with a specific flower species and they are almost seperating our classes perfectly. Just for illustration purposes we will continue to use only 'sepal width (cm)' and 'sepal length (cm)'. We are making the problem harder for ourselves by only using 'weaker' or less-discriminative features. In [ ]: X = X [[ 'sepal width (cm)' , 'sepal length (cm)' ]] Train-Test Split In [ ]: X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = 0.33 , random_state = 42 ) In [ ]: print ( X_train . shape ) print ( y_train . shape ) print ( X_test . shape ) print ( y_test . shape ) 2. Fit a linear regression model for classification, understand drawbacks, and interpret results. In [ ]: model_linear_sklearn = LinearRegression () #Add constant to x_train and x_test X_train_cst = sm . add_constant ( X_train ) X_test_cst = sm . add_constant ( X_test ) #Training model_linear_sklearn . fit ( X_train_cst , y_train ) #Predict y_pred_train = model_linear_sklearn . predict ( X_train_cst ) y_pred_test = model_linear_sklearn . predict ( X_test_cst ) #Performance Evaluation train_score = accuracy_score ( y_train , y_pred_train ) * 100 test_score = accuracy_score ( y_test , y_pred_test ) * 100 print ( \"Training Set Accuracy:\" , str ( train_score ) + '%' ) print ( \"Testing Set Accuracy:\" , str ( test_score ) + '%' ) Why do we get this error? Something is wrong with y_train and y_pred_train... In [ ]: y_train [: 5 ] In [ ]: y_pred_train [: 5 ] The fact that our linear regression is outputting continuous predicstions is one of the major drawbacks of linear regression for classification. We can solve this in two manners: simply rounding our prediction by using np.round()) and converting it to an int data type with .astype(int) or use a modified algorithm that has bounded outputs (more about Logistic Regression later) In [ ]: np . round ( y_pred_train [: 5 ]) In [ ]: np . round ( y_pred_train [: 5 ]) . astype ( int ) In [ ]: model_linear_sklearn = LinearRegression () #Add constant to x_train and x_test X_train_cst = sm . add_constant ( X_train ) X_test_cst = sm . add_constant ( X_test ) #Training model_linear_sklearn . fit ( X_train_cst , y_train ) #Predict y_pred_train = np . round ( model_linear_sklearn . predict ( X_train_cst )) . astype ( int ) y_pred_test = np . round ( model_linear_sklearn . predict ( X_test_cst )) . astype ( int ) #Performance Evaluation train_score = accuracy_score ( y_train , y_pred_train ) * 100 test_score = accuracy_score ( y_test , y_pred_test ) * 100 print ( \"Training Set Accuracy:\" , str ( train_score ) + '%' ) print ( \"Testing Set Accuracy:\" , str ( test_score ) + '%' ) Get Performance by Class (Lookup Confusion Matrix) Each row of the matrix represents the instances in an actual class Each column represents the instances in a predicted class (or vice versa) The name stems from the fact that it makes it easy to see if the system is confusing two classes (i.e. commonly mislabeling one as another). In [ ]: confusion_matrix_linear = pd . crosstab ( y_test . values . flatten (), y_pred_test . flatten (), rownames = [ 'Actual Class' ], colnames = [ 'Predicted Class' ]) display ( confusion_matrix_linear ) How many classes do we have in our y_test and in our y_pred_test? Why do we have 4 different predicted classes? Can we use Linear Regression for classification? Four Assumptions of Linear Regression: Linearity: Our dependent variable Y is a linear combination of the explanatory variables X (and the error terms) Observations are independent of one another I.I.D error terms that are Normally Distributed ~ $N(0,\\sigma&#94;2)$ Design matrix X is Full Rank. Suppose we have a binary outcome variable. Can we use Linear Regression? Then we will have the following problems: The error terms are heteroskedastic $\\epsilon$ is not normally distributed because Y takes on only two values The predicted probabilities can be greater than 1 or less than 0 Datasets where linear regression is problematic: Binary response data where there are only two outcomes (yes/no, 0/1, etc.) Categorical or Ordinal Data of any type, where the outcome is one of a number of discrete (possibly ordered) classes Count data in which the outcome is restricted to non-negative integers. Continuous data in which the noise is not normally distributed Generalized Linear Models (GLMs), of which Logistic regression is a specific type, to the resque: Logistic regression is most useful for binary response and categorical data. 3. Fit a simple logistic regression model for classification, compare performance, plot decision boundaries, and interpret results. The logistic regression formula: $$\\hat{p}= \\dfrac{e&#94;{w&#94;T x}}{1+e&#94;{w&#94;T x}}$$ This is equivalent to: $$\\hat{p}= \\dfrac{1}{1+e&#94;{-w&#94;T x}}$$ Medium Article: Detailed overview of Logistic Regression In [ ]: #Training model_logistic = LogisticRegression ( C = 100 ) . fit ( X_train_cst , y_train ) #Predict y_pred_train = model_logistic . predict ( X_train_cst ) y_pred_test = model_logistic . predict ( X_test_cst ) #Performance Evaluation train_score = accuracy_score ( y_train , y_pred_train ) * 100 test_score = accuracy_score ( y_test , y_pred_test ) * 100 print ( \"Training Set Accuracy:\" , str ( train_score ) + '%' ) print ( \"Testing Set Accuracy:\" , str ( test_score ) + '%' ) Let's compare logistic regression against linear regression predictions We fix X_train['sepal width (cm)'] to its mean value. ```x_1 = X_train['sepal width (cm)']```` x_1_range = np.ones_like(x_2_range)*x_1.mean() We varie X_train['sepal length (cm)'] from its minimum to its maximum and look how the predicted class evolves. x_2 = X_train['sepal length (cm)'] x_2_min, x_2_max = x_2.min(), x_2.max()+0.3 x_2_range = np.arange(x_2_min, x_2_max, 0.003) In [ ]: # Making our input features (x_2 varying, x_1 constat = mean of x_1) x_1 = X_train [ 'sepal width (cm)' ] x_2 = X_train [ 'sepal length (cm)' ] x_2_min , x_2_max = x_2 . min () - 0.1 , x_2 . max () + 0.3 x_2_range = np . arange ( x_2_min , x_2_max , 0.003 ) x_constant = np . ones_like ( x_2_range ) x_1_range = np . ones_like ( x_2_range ) * x_1 . mean () # Construct our input features X_with_varying_x_2 = np . stack ([ x_constant . ravel (), x_1_range . ravel () , x_2_range . ravel () ], axis = 1 ) # Make linear Predictions prediction_linear = model_linear_sklearn . predict ( X_with_varying_x_2 ) # Make logistic Predictions prediction_proba = model_logistic . predict_proba ( X_with_varying_x_2 ) prediction_thresholded = model_logistic . predict ( X_with_varying_x_2 ) f , ax = plt . subplots ( 1 , 2 , figsize = ( 14 , 6 )) # Plot Linear Predictions ax [ 0 ] . plot ( x_2_range , prediction_linear , label = 'Predicted Output (raw = continuous)' ) ax [ 0 ] . plot ( x_2_range , np . round ( prediction_linear ), label = 'Predicted Class (round = integer)' ) ax [ 0 ] . legend () ax [ 0 ] . set_title ( 'Linear Regression: raw output and rounded output.' ) ax [ 0 ] . set_ylim (( - 0.1 , 3.1 )) ax [ 0 ] . set_xlabel ( 'sepal length (cm)' ) # Plot Logistic Predictions ax [ 1 ] . plot ( x_2_range , prediction_proba [:, 0 ], label = 'Class 0' ) ax [ 1 ] . plot ( x_2_range , prediction_proba [:, 1 ], label = 'Class 1' ) ax [ 1 ] . plot ( x_2_range , prediction_proba [:, 2 ], label = 'Class 2' ) ax [ 1 ] . plot ( x_2_range , prediction_thresholded , label = 'Predicted Class' ) ax [ 1 ] . legend () ax [ 1 ] . set_title ( 'Logistic Regression: Predict_Proba Output per Class and the Predicted Class' ) ax [ 1 ] . set_xlabel ( 'sepal length (cm)' ) ax [ 1 ] . set_ylim (( - 0.1 , 3.1 )) plt . show () How does our Logistic Regression come up with mutiple class predictions? Each class $y_i$ has a sigmoid function that tries to predict the probability of the tested input belonging to that specific class $y_i$. In our case when we have 3 classes, thus we have 3 sigmoid functions (the blue, orange and green line in the right figure). LogisticRegression().predict_proba(...) : returns probability estimates $P(y_i|x)$ for each $y_i$. In our case .predict_proba(...) returns 3 values (one for each class). In the figure we observe that : we have a high probability of predicting Class 0 in regions with low 'sepal length' values (left) . we have a high probability of predicting Class 1 in regions with medium 'sepal length' regions (middle) . have a high probability of predicting Class 2 in regions with high 'sepal length' regions (right) . LogisticRegression().predict(...) : returns 1 value: the predicted class label. The class with the highest probability given by .predict_proba(...) is exactly the predicted class output of .predict(...) In the figure our final prediction is the red line . Get Performance by Class (Lookup Confusion Matrix) In [ ]: confusion_matrix_logistic = pd . crosstab ( y_test . values . flatten (), y_pred_test . flatten (), rownames = [ 'Actual Class' ], colnames = [ 'Predicted Class' ]) display ( confusion_matrix_logistic ) Let's compare the confusion matrix of our linear model to the confusion matrix of our logistic regression model: In [ ]: print ( '######################################' ) print ( 'Confusion Matrix Linear Regression:' ) display ( confusion_matrix_linear ) print ( ' \\n ######################################' ) print ( 'Confusion Matrix Logistic Regression:' ) display ( confusion_matrix_logistic ) print ( '######################################' ) Now we do observe that the logistic regression has the correct number of predicted classes. 4. Visualize Predictions and Decision boundaries. What are decision boundaries: In general, a pattern classifier carves up (or tesselates or partitions) the feature space into volumes called decision regions. All feature vectors in a decision region are assigned to the same category. In [ ]: X_train . head () In [ ]: def plot_points ( ax ): for i , y_class in enumerate ( set ( y_train . values . flatten ())): index = ( y_train == y_class ) . values ax . scatter ( X_train [ index ][ 'sepal width (cm)' ], X_train [ index ][ 'sepal length (cm)' ], c = colors [ i ], s = 65 , edgecolor = 'w' , label = names [ i ]) In [ ]: f , ax = plt . subplots ( 1 , 1 , figsize = ( 6 , 6 )) colors = [ \"red\" , \"green\" , \"blue\" ] names = dataset . target_names plot_points ( ax ) ax . legend ( bbox_to_anchor = ( 1 , 1 ), loc = 'upper left' , ncol = 1 ) ax . set_title ( 'Classes of Flowers' ) ax . set_ylabel ( 'sepal length (cm)' ) ax . set_xlabel ( 'sepal width (cm)' ) plt . show () Plotting the decision boundary: by using the following functions: np.meshgrid(..) : 'constructing a grid': np.meshgrid() returns coordinate matrices from coordinate vectors. plt.contourf(..) : contourf draws filled contours. In [ ]: x_1 = X_train [ 'sepal width (cm)' ] x_2 = X_train [ 'sepal length (cm)' ] # Just for illustration purposes we use a margin of 0.2 to the # left, right, top and bottum of our minimal and maximal points. # This way our minimal and maximal points won't lie exactly # on the axis. x_1_min , x_1_max = x_1 . min () - 0.2 , x_1 . max () + 0.2 x_2_min , x_2_max = x_2 . min () - 0.2 , x_2 . max () + 0.2 xx_1 , xx_2 = np . meshgrid ( np . arange ( x_1_min , x_1_max , 0.003 ), np . arange ( x_2_min , x_2_max , 0.003 )) In [ ]: # Plotting decision regions f , ax = plt . subplots ( 1 , 1 , figsize = ( 6 , 6 )) X_mesh = sm . add_constant ( np . stack (( xx_1 . ravel (), xx_2 . ravel ()), axis = 1 )) Z = model_logistic . predict ( X_mesh ) Z = Z . reshape ( xx_1 . shape ) ax . contourf ( xx_1 , xx_2 , Z , alpha = 0.5 , colors = colors , levels = 2 ) plot_points ( ax ) ax . legend ( bbox_to_anchor = ( 1 , 1 ), loc = 'upper left' , ncol = 1 ) ax . set_title ( 'Classes of Flowers' ) ax . set_ylabel ( 'sepal length (cm)' ) ax . set_xlabel ( 'sepal width (cm)' ) plt . show () Why are the decision boundaries of this Logistic Regression linear? Imagine the simple case where we have only a 2 class classification problem: The logistic regression formula can be written as: $$\\hat{p}= \\dfrac{e&#94;{w&#94;T x}}{1+e&#94;{w&#94;T x}}$$ This is equivalent to: $$\\hat{p}= \\dfrac{1}{1+e&#94;{-w&#94;T x}}$$ We have x_1 (sepal width), x_2 (sepal length), and our intercept (constant =1) $$\\hat{p}= \\dfrac{1}{1+e&#94;{-(w_0 *1 + w_1 *x_1 + w_2* x_2)}}$$ Since we don't use multiple higher order polynomial features like $x_1&#94;2, x_2&#94;2$, our logistic model only depends on the first order simple features $x_1$ and $x_2$. What do we have to do to find the the decision boundary? The decision boundaries are exactly at the position where our algorithm \"hesitates\" when predicting which class to classify. The output probability of our sigmoid (or softmax) is exactly 0.5. Solving our sigmoid function for $p=0.5$: $$\\hat{p}= \\dfrac{1}{1+e&#94;{-w&#94;T x}} = 0.5 = \\dfrac{1}{1+1} $$ $$ e&#94;{-w&#94;T x} = 1$$ $$ -w&#94;T x = 0$$ $$ w&#94;T x = 0$$ $$ w_0*1 + w_1 *x_1 + w_2 *1x_2 = 0$$ When we only use two predictor features this constraint of $p=0.5$ results in a linear system; thus we observe a linear decision boundary. In our case when we have three classes. 5. Fit a higher order polynomial logistic regression model for classification, compare performance, plot decision boundaries, and interpret results. In [ ]: X_train_cst . head () In [ ]: X_train_poly_cst = X_train_cst . copy () X_train_poly_cst [ 'sepal width (cm)&#94;2' ] = X_train_cst [ 'sepal width (cm)' ] ** 2 X_train_poly_cst [ 'sepal length (cm)&#94;2' ] = X_train_cst [ 'sepal length (cm)' ] ** 2 X_test_poly_cst = X_test_cst . copy () X_test_poly_cst [ 'sepal width (cm)&#94;2' ] = X_test_poly_cst [ 'sepal width (cm)' ] ** 2 X_test_poly_cst [ 'sepal length (cm)&#94;2' ] = X_test_poly_cst [ 'sepal length (cm)' ] ** 2 X_test_poly_cst . head () In [ ]: #Training model_logistic_poly = LogisticRegression ( C = 10000 ) . fit ( X_train_poly_cst , y_train ) #Predict y_pred_train = model_logistic_poly . predict ( X_train_poly_cst ) y_pred_test = model_logistic_poly . predict ( X_test_poly_cst ) #Performance Evaluation train_score = accuracy_score ( y_train , y_pred_train ) * 100 test_score = accuracy_score ( y_test , y_pred_test ) * 100 print ( \"Training Set Accuracy:\" , str ( train_score ) + '%' ) print ( \"Testing Set Accuracy:\" , str ( test_score ) + '%' ) Our test performance is decreasing, what might be happening? How would you test if this is happening? How would you inhibit this phenomenon from happening? In [ ]: # Plotting decision regions f , ax = plt . subplots ( 1 , 1 , figsize = ( 6 , 6 )) X_mesh_poly = sm . add_constant ( np . stack (( xx_1 . ravel (), xx_2 . ravel (), xx_1 . ravel () ** 2 , xx_2 . ravel () ** 2 ), axis = 1 )) Z = model_logistic_poly . predict ( X_mesh_poly ) Z = Z . reshape ( xx_1 . shape ) ax . contourf ( xx_1 , xx_2 , Z , alpha = 0.5 , colors = colors , levels = 2 ) plot_points ( ax ) ax . legend ( bbox_to_anchor = ( 1 , 1 ), loc = 'upper left' , ncol = 1 ) ax . set_title ( 'Classes of Flowers' ) ax . set_ylabel ( 'sepal length (cm)' ) ax . set_xlabel ( 'sepal width (cm)' ) plt . show () What do you observe regarding the form of the decision boundaries? Does this make sense? $$\\hat{p}= \\dfrac{e&#94;{w&#94;T x}}{1+e&#94;{w&#94;T x}}$$ This is equivalent to: $$\\hat{p}= \\dfrac{1}{1+e&#94;{-w&#94;T x}}$$ Now we use $x_1$ (sepal width), $x_2$ (sepal length), an intercept (constant =1), PLUS two higher order terms while making predictions: $x_1&#94;2$ = (sepal_width)&#94;2 $x_2&#94;2$ = (sepal_length)&#94;2 $$\\hat{p}= \\dfrac{1}{1+e&#94;{-(w_0 *1 + w_1 *x_1 + w_2* x_2 + w_3 *x_1&#94;2 + w_4* x_2&#94;2))}}$$ Now solving for $p=0.5$ results in an equation also dependent on $x_1&#94;2$ and $x_2&#94;2$: thus we observe non-linear decision boundaries. 6. Fit a higher order polynomial logistic regression model for classification with different regularization parameters C ( [10000, 100, 1] ) In [ ]: f , ax = plt . subplots ( 1 , 3 , figsize = ( 6 * 3 , 6 )) model_logistics = [] model_logistics_test_accs_scores = [] model_logistics_train_accs_scores = [] for test , C in enumerate ([ 10000 , 100 , 1 ]): model_logistics . append ( LogisticRegression ( C = C ) . fit ( X_train_poly_cst , y_train )) y_pred_train = model_logistics [ test ] . predict ( X_train_poly_cst ) y_pred_test = model_logistics [ test ] . predict ( X_test_poly_cst ) model_logistics_train_accs_scores . append ( accuracy_score ( y_train , y_pred_train ) * 100 ) model_logistics_test_accs_scores . append ( accuracy_score ( y_test , y_pred_test ) * 100 ) Z = model_logistics [ test ] . predict ( X_mesh_poly ) Z = Z . reshape ( xx_1 . shape ) ax [ test ] . contourf ( xx_1 , xx_2 , Z , alpha = 0.5 , colors = colors , levels = 2 ) plot_points ( ax [ test ]) ax [ test ] . legend ( loc = 'upper left' , ncol = 1 ) ax [ test ] . set_title ( 'Classes of Flowers, with C = ' + str ( C )) ax [ test ] . set_ylabel ( 'sepal length (cm)' ) ax [ test ] . set_xlabel ( 'sepal width (cm)' ) plt . show () What do you observe? How are the decision boundaries looking? What happens when the regularization term C changes? You may want to look at the documentation of sklearn.linear.LogisticRegression(): In [ ]: # To get the documentation uncomment and run the following command: # LogisticRegression? What do expect regarding the evolution of the norm of the coefficients of our models when the regularizatoin term C changes? Our list contains all 3 models with different values for C ( take a look at the first parameter within brackets ) In [ ]: model_logistics In [ ]: for test , model in enumerate ( model_logistics ): print ( ' \\n Regularization parameter : \\t C = {} ' . format ( model . C )) print ( \"Training Set Accuracy : \\t {} \" . format ( model_logistics_train_accs_scores [ test ]) + '%' ) print ( \"Testing Set Accuracy : \\t\\t {} \" . format ( model_logistics_test_accs_scores [ test ]) + '%' ) print ( 'Mean absolute coeficient : \\t {:0.2f} ' . format ( np . mean ( np . abs ( model . coef_ )))) Interpretation of Results: What happens when our Regularization Parameter decreases? The amount of regularizaiton increases. This results in: The Training Set Accuracy decreasing a little bit (not much of a problem) The Test Set Accuracy decreasing a little bit (better generalization!) Our size of coefficents decreases on average. END OF STANDARD SECTION Optional: Fit a KNN-classification model for classification, plot decision boundaries, and interpret results. In [ ]: #Training model_KNN_classifier = KNeighborsClassifier ( n_neighbors = 1 ) . fit ( X_train_cst , y_train ) In [ ]: #Predict y_pred_train = model_KNN_classifier . predict ( X_train_cst ) y_pred_test = model_KNN_classifier . predict ( X_test_cst ) #Performance Evaluation train_score = accuracy_score ( y_train , y_pred_train ) * 100 test_score = accuracy_score ( y_test , y_pred_test ) * 100 print ( \"Training Set Accuracy:\" , str ( train_score ) + '%' ) print ( \"Testing Set Accuracy:\" , str ( test_score ) + '%' ) The fact we have a big gap of performance between the test and training set means we are overfitting, and can be explained by using \"n_neighbors=1\". Based on your knowledge of KNN-regression can you guess how the decision boundary of the KNN-classification will look when using \"n_neighbors=1\"? In [ ]: # Plotting decision regions f , ax = plt . subplots ( 1 , 1 , figsize = ( 6 , 6 )) Z = model_KNN_classifier . predict ( X_mesh ) Z = Z . reshape ( xx_1 . shape ) ax . contourf ( xx_1 , xx_2 , Z , alpha = 0.5 , colors = colors , levels = 2 ) plot_points ( ax ) ax . legend ( bbox_to_anchor = ( 1 , 1 ), loc = 'upper left' , ncol = 1 ) ax . set_title ( 'Classes of Flowers' ) ax . set_ylabel ( 'sepal length (cm)' ) ax . set_xlabel ( 'sepal width (cm)' ) plt . show () 8. Optional Homework Tip: Pipeline building to sequentially apply a list of transforms (e.g. scaling, polynomial feature creation) and a final estimator. Instead of manually building our polynomial features which might take a lot of lines of code we can use a pipeline to sequentially create polynomials before fitting our logistic regression. Scaling can also be done inside the make_pipeline . Previously we did: X_train_poly_cst=X_train_cst.copy() X_train_poly_cst['sepal width (cm)&#94;2'] = X_train_cst['sepal width (cm)']**2 X_train_poly_cst['sepal length (cm)&#94;2'] = X_train_cst['sepal length (cm)']**2 X_test_poly_cst=X_test_cst.copy() X_test_poly_cst['sepal width (cm)&#94;2'] = X_test_poly_cst['sepal width (cm)']**2 X_test_poly_cst['sepal length (cm)&#94;2'] = X_test_poly_cst['sepal length (cm)']**2 Now it is a one-liner: make_pipeline(PolynomialFeatures(degree=2), LogisticRegression()) In [ ]: # your code here from sklearn.pipeline import make_pipeline from sklearn.preprocessing import PolynomialFeatures polynomial_logreg_estimator = make_pipeline ( PolynomialFeatures ( degree = 2 , include_bias = False ), LogisticRegression ()) #Training polynomial_logreg_estimator . fit ( X_train_poly_cst , y_train ) #Predict y_pred_train = polynomial_logreg_estimator . predict ( X_train_poly_cst ) y_pred_test = polynomial_logreg_estimator . predict ( X_test_poly_cst ) #Performance Evaluation train_score = accuracy_score ( y_train , y_pred_train ) * 100 test_score = accuracy_score ( y_test , y_pred_test ) * 100 print ( \"Training Set Accuracy:\" , str ( train_score ) + '%' ) print ( \"Testing Set Accuracy:\" , str ( test_score ) + '%' ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"sections","url":"sections/sec_5/"},{"title":"S-Section 05:  Logistic Regression, Multiple Logistic Regression, and KNN-classification","text":"Jupyter Notebooks S-Section 5: Logistic Regression, Multiple Logistic Regression, and KNN-classification","tags":"sections","url":"sections/section5/"},{"title":"Lab 7:","text":"Notebooks Lab 7 - KNN Classification Lab 7 - KNN Classification","tags":"labs","url":"labs/lab7/"},{"title":"Lecture 12: KNN Classification & Imputation","text":"Slides Lecture 12 Slides - PDF Lecture 12 Slides - PPTX Notebooks Lecture 7 Notebook","tags":"lectures","url":"lectures/lecture12/"},{"title":"Lecture 12: KNN Classification & Imputation","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109A Introduction to Data Science Lecture 12 ($k$-NN Classification and Missingness) Harvard University Fall 2019 Instructors: Pavlos Protopapas, Kevin Rader, and Chris Tanner In [ ]: % matplotlib inline import sys import numpy as np import pylab as pl import pandas as pd import statsmodels.api as sm import matplotlib.pyplot as plt import matplotlib import sklearn as sk from sklearn.linear_model import LogisticRegression from sklearn.neighbors import KNeighborsClassifier import sklearn.metrics as met In [ ]: df_heart = pd . read_csv ( 'Heart.csv' ) df_heart . head () In [ ]: data_x = df_heart . MaxHR data_y = df_heart . AHD . map ( lambda x : 0 if x == 'No' else 1 ) knn1 = KNeighborsClassifier ( n_neighbors = 1 ) knn5 = KNeighborsClassifier ( n_neighbors = 5 ) knn10 = KNeighborsClassifier ( n_neighbors = 10 ) knn50 = KNeighborsClassifier ( n_neighbors = 50 ) knn1 . fit ( data_x . values . reshape ( - 1 , 1 ), data_y ); knn5 . fit ( data_x . values . reshape ( - 1 , 1 ), data_y ); knn10 . fit ( data_x . values . reshape ( - 1 , 1 ), data_y ); knn50 . fit ( data_x . values . reshape ( - 1 , 1 ), data_y ); fig = plt . figure () fig . patch . set_alpha ( 0.0 ) plt . xkcd ( scale = 0.1 , length = 0.0 ) plt . gcf () . subplots_adjust ( bottom = 0.20 , left = 0.16 , right = 0.86 ) x = np . linspace ( np . min ( data_x ), np . max ( data_x )) yhat1 = knn1 . predict ( x . reshape ( - 1 , 1 )) yhat5 = knn5 . predict ( x . reshape ( - 1 , 1 )) yhat10 = knn10 . predict ( x . reshape ( - 1 , 1 )) yhat50 = knn50 . predict ( x . reshape ( - 1 , 1 )) plt . plot ( data_x , data_y , 'o' , alpha = 0.1 , label = 'Data' ) plt . plot ( x , yhat1 , label = 'knn1' ) plt . plot ( x , yhat5 , label = 'knn5' ) plt . plot ( x , yhat10 , label = 'knn10' ) plt . plot ( x , yhat50 , label = 'knn50' ) plt . legend () plt . xlabel ( \"MaxHR\" ) plt . ylabel ( \"Heart disease (AHD)\" ) plt . show () In [ ]: phat1 = knn1 . predict_proba ( x . reshape ( - 1 , 1 ))[:, 1 ] phat5 = knn5 . predict_proba ( x . reshape ( - 1 , 1 ))[:, 1 ] phat10 = knn10 . predict_proba ( x . reshape ( - 1 , 1 ))[:, 1 ] phat50 = knn50 . predict_proba ( x . reshape ( - 1 , 1 ))[:, 1 ] plt . plot ( data_x , data_y , 'o' , alpha = 0.1 , label = 'Data' ) plt . plot ( x , phat1 , label = 'knn1' ) plt . plot ( x , phat5 , label = 'knn5' ) plt . plot ( x , phat10 , label = 'knn10' ) plt . plot ( x , phat50 , label = 'knn50' ) plt . legend () plt . xlabel ( \"MaxHR\" ) plt . ylabel ( \"Heart disease (AHD)\" ) plt . show () In [ ]: #two predictors knn1 = KNeighborsClassifier ( n_neighbors = 1 ) knn5 = KNeighborsClassifier ( n_neighbors = 5 ) knn10 = KNeighborsClassifier ( n_neighbors = 10 ) knn50 = KNeighborsClassifier ( n_neighbors = 50 ) data_x = df_heart [[ 'MaxHR' , 'RestBP' ]] data_y = df_heart . AHD . map ( lambda x : 0 if x == 'No' else 1 ) knn1 . fit ( data_x , data_y ); knn5 . fit ( data_x , data_y ); knn10 . fit ( data_x , data_y ); knn50 . fit ( data_x , data_y ); print ( knn1 . score ( data_x , data_y )) print ( knn5 . score ( data_x , data_y )) print ( knn10 . score ( data_x , data_y )) print ( knn50 . score ( data_x , data_y )) In [ ]: # Don't forget to split into train and test # (or better yet, use cross-validation) # to determine what k is actually best! Dealing with Missingness In [ ]: # There are some missing values to begin with print ( df_heart . shape ) print ( df_heart . dropna () . shape ) In [ ]: import numpy.random as random random . seed ( 109 ) n = df_heart [ \"MaxHR\" ] . size # create 20 missing completely at random observations miss = random . choice ( n , 20 ) heart_mcar = pd . read_csv ( 'Heart.csv' ) heart_mcar . loc [ miss , \"MaxHR\" ] = np . nan print ( heart_mcar [ \"MaxHR\" ][ miss ] . head ()) print ( heart_mcar . dropna () . shape ) In [ ]: # create 20 missing at random observations miss = random . binomial ( 1 , 0.1 + 0.2 * df_heart [ \"Sex\" ], n ) heart_mar = pd . read_csv ( 'Heart.csv' ) heart_mar . loc [ miss == 1 , \"MaxHR\" ] = np . nan print ( heart_mar . loc [ miss == 1 , \"MaxHR\" ] . head ()) print ( heart_mar . dropna () . shape ) In [ ]: # create 20 missing not at random observations miss = random . binomial ( 1 , 0.1 * ( df_heart [ \"MaxHR\" ] > df_heart [ \"MaxHR\" ] . mean ()), n ) heart_mnar = pd . read_csv ( 'Heart.csv' ) heart_mnar . loc [ miss == 1 , \"MaxHR\" ] = np . nan print ( heart_mnar . loc [ miss == 1 , \"MaxHR\" ] . head ()) print ( heart_mnar . dropna () . shape ) In [ ]: # sklearn is not happy when you give it missing values knn50 = KNeighborsClassifier ( n_neighbors = 50 ) data_x = heart_mcar [[ 'MaxHR' , 'RestBP' ]] data_y = df_heart . AHD . map ( lambda x : 0 if x == 'No' else 1 ) knn50 . fit ( data_x , data_y ); In [ ]: # So let's just fill in the mean to make it happy data_x = data_x . fillna ( data_x . mean ()) knn50 . fit ( data_x , data_y ); if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"lectures","url":"lectures/lecture12/notebook/"},{"title":"Lab 6: Logistic Regression","text":"Jupyter Notebooks Lab 6: Logistic Regression Lab 6: Logistic Regression Solutions","tags":"labs","url":"labs/lab06/"},{"title":"Lab 6: Logistic Regression","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS-109A Introduction to Data Science Lab 6: Logistic Regression Harvard University Fall 2019 Instructors: Pavlos Protopapas, Kevin Rader, Chris Tanner Lab Instructors: Chris Tanner and Eleni Kaxiras. Contributors: Will Claybaugh, David Sondak, Chris Tanner In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } span.sub-q { font-weight: bold; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Learning Goals In this lab, we'll explore different models used to predict which of several labels applies to a new datapoint based on labels observed in the training data. By the end of this lab, you should: Be familiar with the sklearn implementations of Linear Regression Logistic Regression Be able to make an informed choice of model based on the data at hand (Bonus) Structure your sklearn code into Pipelines to make building, fitting, and tracking your models easier (Bonus) Apply weights to each class in the model to achieve your desired tradeoffs between discovery and false alarm in various classes In [2]: % matplotlib inline import numpy as np import scipy as sp import matplotlib.pyplot as plt import pandas as pd pd . set_option ( 'display.width' , 500 ) pd . set_option ( 'display.max_columns' , 100 ) pd . set_option ( 'display.notebook_repr_html' , True ) from sklearn.model_selection import train_test_split Part 1: The Wine Dataset The dataset contains 11 chemical features of various wines, along with experts' rating of that wine's quality. The quality scale technically runs from 1-10, but only 3-9 are actually used in the data. Our goal will be to distinguish good wines from bad wines based on their chemical properties. Read-in and checking We do the usual read-in and verification of the data: In [5]: wines_df = pd . read_csv ( \"../data/wines.csv\" , index_col = 0 ) wines_df . head () Out[5]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } fixed acidity volatile acidity citric acid residual sugar chlorides free sulfur dioxide total sulfur dioxide density pH sulphates alcohol quality red good 0 8.9 0.590 0.50 2.0 0.337 27.0 81.0 0.99640 3.04 1.61 9.5 6 1 0 1 7.7 0.690 0.22 1.9 0.084 18.0 94.0 0.99610 3.31 0.48 9.5 5 1 0 2 8.8 0.685 0.26 1.6 0.088 16.0 23.0 0.99694 3.32 0.47 9.4 5 1 0 3 11.4 0.460 0.50 2.7 0.122 4.0 17.0 1.00060 3.13 0.70 10.2 5 1 0 4 8.8 0.240 0.54 2.5 0.083 25.0 57.0 0.99830 3.39 0.54 9.2 5 1 0 In [6]: wines_df . describe () Out[6]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } fixed acidity volatile acidity citric acid residual sugar chlorides free sulfur dioxide total sulfur dioxide density pH sulphates alcohol quality red good count 1000.000000 1000.000000 1000.00000 1000.000000 1000.000000 1000.00000 1000.00000 1000.000000 1000.000000 1000.000000 1000.000000 1000.000000 1000.00000 1000.000000 mean 7.558400 0.397455 0.30676 4.489250 0.067218 25.29650 91.03100 0.995351 3.251980 0.572990 10.489433 5.796000 0.50000 0.189000 std 1.559455 0.189923 0.16783 4.112419 0.046931 17.06237 59.57269 0.002850 0.164416 0.169583 1.151195 0.844451 0.50025 0.391705 min 3.800000 0.080000 0.00000 0.800000 0.009000 1.00000 6.00000 0.987400 2.740000 0.280000 8.500000 3.000000 0.00000 0.000000 25% 6.500000 0.260000 0.22000 1.800000 0.042000 12.00000 37.75000 0.993480 3.140000 0.460000 9.500000 5.000000 0.00000 0.000000 50% 7.200000 0.340000 0.30000 2.400000 0.060000 22.00000 86.00000 0.995690 3.240000 0.550000 10.300000 6.000000 0.50000 0.000000 75% 8.200000 0.520000 0.40000 6.100000 0.080000 35.00000 135.00000 0.997400 3.360000 0.650000 11.300000 6.000000 1.00000 0.000000 max 15.500000 1.580000 1.00000 26.050000 0.611000 131.00000 313.00000 1.003690 3.900000 2.000000 14.000000 8.000000 1.00000 1.000000 Building the training/test data As usual, we split the data before we begin our analysis. Today, we take the 'quality' variable as our target. There's a debate to be had about the best way to handle this variable. It has 10 categories (1-10), though only 3-9 are used. While the variable is definitely ordinal- we can put the categories in an order everyone agrees on- the variable probably isn't a simple numeric feature; it's not clear whether the gap between a 5 and a 6 wine is the same as the gap between an 8 and a 9. Ordinal regression is one possibility for our analysis (beyond the scope of this course), but we'll view the quality variable as categorical. Further, we'll simplify it down to 'good' and 'bad' wines (quality at or above 7, and quality at or below 6, respectively). This binary column already exists in the data, under the name 'good'. In [7]: wines_train , wines_test = train_test_split ( wines_df , test_size = 0.2 , random_state = 8 , stratify = wines_df [ 'good' ]) x_train = wines_train . drop ([ 'quality' , 'good' ], axis = 1 ) y_train = wines_train [ 'good' ] x_test = wines_test . drop ([ 'quality' , 'good' ], axis = 1 ) y_test = wines_test [ 'good' ] x_train . head () Out[7]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } fixed acidity volatile acidity citric acid residual sugar chlorides free sulfur dioxide total sulfur dioxide density pH sulphates alcohol red 744 7.6 0.30 0.37 1.6 0.087 27.0 177.0 0.99438 3.09 0.50 9.8 0 51 7.6 0.29 0.49 2.7 0.092 25.0 60.0 0.99710 3.31 0.61 10.1 1 213 13.2 0.46 0.52 2.2 0.071 12.0 35.0 1.00060 3.10 0.56 9.0 1 883 8.6 0.33 0.34 11.8 0.059 42.0 240.0 0.99882 3.17 0.52 10.0 0 98 7.7 0.41 0.76 1.8 0.611 8.0 45.0 0.99680 3.06 1.26 9.4 1 Now that we've split, let's explore some patterns in the data In [8]: from pandas.plotting import scatter_matrix scatter_matrix ( wines_train , figsize = ( 30 , 20 )); It looks like there aren't any particularly strong correlations among the predictors (maybe sulfur dioxide and free sulfur dioxide) so we're safe to keep them all. It also looks like the different quality categories have roughly the same distribution of most variables, with volatile/fixed acidity and alcohol seeming like the most useful predictors. Part 2 (Introduction): Binary Logistic Regression Linear regression is usually a good baseline model, but since the outcome we're trying to predict only takes values 0 and 1 we'll want to use logistic regression instead of basic linear regression. We'll begin with statsmodels , because cs109 likes confidence intervals and checking that coefficients make sense. In [16]: import statsmodels.api as sm sm_fitted_logit = sm . Logit ( y_train , sm . add_constant ( x_train )) . fit () #sm_fitted_logit.summary() ### ORIGINAL VERSION. GAVE AttributeError: module 'scipy.stats' has no attribute 'chisqprob' sm_fitted_logit . summary2 () ### WORKS Optimization terminated successfully. Current function value: 0.372167 Iterations 10 Out[16]: Model: Logit Pseudo R-squared: 0.232 Dependent Variable: good AIC: 621.4673 Date: 2018-10-17 23:20 BIC: 682.3672 No. Observations: 800 Log-Likelihood: -297.73 Df Model: 12 LL-Null: -387.52 Df Residuals: 787 LLR p-value: 5.1997e-32 Converged: 1.0000 Scale: 1.0000 No. Iterations: 10.0000 Coef. Std.Err. z P>|z| [0.025 0.975] const 296.7882 178.7587 1.6603 0.0969 -53.5724 647.1488 fixed acidity 0.4228 0.1962 2.1546 0.0312 0.0382 0.8073 volatile acidity -3.6301 1.1006 -3.2983 0.0010 -5.7872 -1.4729 citric acid -0.8217 1.0638 -0.7724 0.4399 -2.9066 1.2633 residual sugar 0.1628 0.0759 2.1454 0.0319 0.0141 0.3115 chlorides -18.8903 8.1523 -2.3172 0.0205 -34.8684 -2.9121 free sulfur dioxide 0.0026 0.0089 0.2864 0.7746 -0.0150 0.0201 total sulfur dioxide -0.0036 0.0038 -0.9597 0.3372 -0.0110 0.0038 density -312.9457 182.0829 -1.7187 0.0857 -669.8215 43.9302 pH 1.5112 1.1276 1.3402 0.1802 -0.6989 3.7212 sulphates 2.5571 0.8610 2.9700 0.0030 0.8696 4.2446 alcohol 0.4945 0.2190 2.2580 0.0239 0.0653 0.9236 red 0.6751 0.6490 1.0403 0.2982 -0.5968 1.9470 Let's talk about the output: First, \"optimization terminated successfully\". Recall that linear regression and its simple formula for the optimal betas is a rarity in machine learning and statistics: most models are fit to the data algorithmically, not via a formula. This message is letting us know that the algorithm seems to have worked. Second, the pseudo $R&#94;2$ is rather low (.23). As with regular $R&#94;2$, we might take this as a sign that the model is struggling. Finally, let's look at the coefficients. Several of the coefficients are statistically significant, including Fixed acidity - good Volatile Acidity - bad Residual Sugar - good (judge have a sweet tooth?) Chlorides - bad Sulphates - good Alcohol - good (judges like getting drunk?) The rest only reach a coefficient size we would often observe by chance alone, without any actual effect from the predictor More formal interpretations are of coefficients are long-winded. \"A one unit increase in alcohol (holding all else constant) results in a predicted 0.494 increase in the log odds of a wine being classified as good\". We can't be more precise because the effect of one unit of alcohol depends on how much alcohol there already is. The one unit increase/decrease matters more if the wine is otherwise on the border between good and bad. If the wine is undrinkable (in the far left tail of the sigmoidal curve) one unit of alcohol barely moves the probability, while if the wine is in the middle of the curve that unit of acidity has much more practical impact. Discussion Are there any bones you'd like to pick with the model I've laid out? Can you think of a better logistic regression model? Prediction One of the really cool features of logistic regression is that it hands back probabilities of a given case being 1 or 0, rather than just 1s and 0s. That lets us do neat things like set different cutoffs for what counts as a 1 and do ROC analysis and so on. Here, we'll just set the cutoff at 0.5: if a 1 is reported as more likely, predict a 1. (You can play with the cutoff yourself and see if you can make the model do better by trading false positives and false negatives). Because this is statsmodels, we'll need to import a tool or do the test set score calculation ourselves. Here, it's easy enough to implement: do the predictions compare with .5 find out what percentage of our binary predictions matched the truth In [17]: sm_binary_prediction = sm_fitted_logit . predict ( sm . add_constant ( x_test )) >= . 5 np . sum ( y_test == sm_binary_prediction ) / len ( y_test ) Out[17]: 0.80500000000000005 Wow! 80% is a pretty good performance! We can pretty much tell the bad wines from the good. Here's a sanity check: In [18]: np . sum ( y_test == 0 ) / len ( y_test ) Out[18]: 0.81000000000000005 Oh... no... wait. A model that says \"all wines are bad\" also scores 80% on the test set. Our fancy model isn't really doing that well. Moral of the story : Before you congratulate a model, think of a truly trivial model to compare it to. Exercise 1 Re-create the results above but this time work with sklearn . Use the LogisticRegression class. Follow the usual .fit , .score procedure. To match statsmodel 's coefficient values (roughly), you will need to adjust the input parameters: C solver One other parameter See the sklearn documentation Hint: statsmodels uses a Newton-Raphson method to optimize the beta values. In [19]: from sklearn.linear_model import LogisticRegression print ( \"target: \\n {} \" . format ( sm_fitted_logit . params )) # #fitted_lr = LogisticRegression(C=___, solver=___, ___) target: const 296.788181 fixed acidity 0.422755 volatile acidity -3.630081 citric acid -0.821665 residual sugar 0.162801 chlorides -18.890258 free sulfur dioxide 0.002563 total sulfur dioxide -0.003620 density -312.945669 pH 1.511186 sulphates 2.557134 alcohol 0.494461 red 0.675074 dtype: float64 Answer : In [20]: # your code here from sklearn.linear_model import LogisticRegression fitted_lr = LogisticRegression ( C = 1000000 , solver = 'newton-cg' , max_iter = 250 ) . fit ( x_train , y_train ) print ( fitted_lr . coef_ ) print ( \"Test set score:\" , fitted_lr . score ( x_test , y_test )) [[ 4.14100069e-01 -3.63742842e+00 -8.21051016e-01 1.59009157e-01 -1.89819092e+01 2.59239593e-03 -3.63950860e-03 -3.02921757e+02 1.46959411e+00 2.53829773e+00 5.04848999e-01 6.56941898e-01]] Test set score: 0.805 /Users/pavlos/anaconda3/lib/python3.6/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge warn('The line search algorithm did not converge', LineSearchWarning) /Users/pavlos/anaconda3/lib/python3.6/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge warn('The line search algorithm did not converge', LineSearchWarning) In [21]: # uncoment me and execute me - this will erase your cell ... #%load solutions/sklearn_logistic.py Speaker note: When presenting solution, model reading the documentation from the webpage. How does one know where to look? Speaker note: Mention the wide variety of solvers and how (some) use different levels of derivatives to converge in fewer steps The Decision Boundary One powerful way to think about classification models is to consider where and how they draw the line between predicting \"class A\" and \"class B\". The code below lets you play with a 2d logistic regression. Points towards yellow will be predicted as 1s, points towards violet will be predicted as 0s. In [100]: from scipy.special import expit def plot_logistic_contour ( beta0 , betaX , betaY , betaXY = 0 , betaX2 = 0 , betaY2 = 0 ): delta =. 1 x_values = np . arange ( - 3.0 , 3.0 , delta ) y_values = np . arange ( - 3.0 , 3.0 , delta ) x_grid , y_grid = np . meshgrid ( x_values , y_values ) logistic_output = expit ( beta0 + betaX * x_grid + betaY * y_grid + betaXY * x_grid * y_grid + betaX2 * x_grid ** 2 + betaY2 * y_grid ** 2 ) contour_figure = plt . contour ( x_grid , y_grid , logistic_output ) plt . clabel ( contour_figure , inline = 1 , fontsize = 10 ); plt . xlim ( - 3 , 3 ) plt . ylim ( - 3 , 3 ) plt . show () #plot_logistic_contour(beta0=1, betaX=2, betaY=3, betaXY=0, betaY2=.1) In [101]: # Use this cell to experiment plot_logistic_contour ( beta0 = 1 , betaX = 2 , betaY = 3 ) Exercise 2 What happens to the decision boundary as the coefficient on X increases? What happens if you increase the Y coefficient to match? What does the constant term control? What impact do higher-order and interaction terms have on the boundary? What parameter settings should I show the class? Answers : your answer here The boundary tips towards vertical The boundary is in the same place as it was originally, but is squished together. The model is much more certain about how to predict points a given distance from the boundary It shifts the boundary, perpendicular to its current orientation Including squared terms allows quadratic decision boundaries, and the interraction term allows hyperbolic boundaries In [ ]: # %load solutions/boundaries.txt Part 3 (The Real Challenge): Multiclass Classification Before we move on, let's consider a more common use case of logistic regression: predicting not just a binary variable, but what level a categorical variable will take. Instead of breaking the quality variable into 'good' and 'other', let's discretize into 'good, 'medium', and 'bad'. In [103]: # copy the original data so that we're free to make changes wines_df_recode = wines_df . copy () # use the 'cut' function to reduce a variable down to particular bins. Here the lowest bin is 0-4, next is 5-7, # and the last is 7-10 wines_df_recode [ 'quality' ] = pd . cut ( wines_df_recode [ 'quality' ],[ 0 , 4 , 7 , 10 ], labels = [ 0 , 1 , 2 ]) # drop the un-needed columns x_data = wines_df_recode . drop ([ 'quality' , 'good' ], axis = 1 ) y_data = wines_df_recode [ 'quality' ] x_train , x_test , y_train , y_test = train_test_split ( x_data , y_data , test_size =. 2 , random_state = 8 , stratify = y_data ) print ( wines_df [ 'quality' ] . head ()) print ( wines_df_recode [ 'quality' ] . head ()) 0 6 1 5 2 5 3 5 4 5 Name: quality, dtype: int64 0 1 1 1 2 1 3 1 4 1 Name: quality, dtype: category Categories (3, int64): [0 < 1 < 2] The cut function obviously stores a lot of extra information for us. It's a very useful tool for discretizing an existing variable. Exercise 3 Adapt your earlier logistic regression code to fit to the new training data. What is stored in .coef_ and .intercept_ ? How well does this model predict the test data? Put the model's performance in context. Think of a trivial model to compare to, and provide its accuracy score on the test set. Answers : 1. In [104]: # your code here from sklearn.linear_model import LogisticRegression fitted_lr = LogisticRegression ( C = 1000000 , solver = 'newton-cg' , max_iter = 250 ) . fit ( x_train , y_train ) print ( \"Coefficients:\" ) print ( fitted_lr . coef_ ) print ( \"Intercepts:\" ) print ( fitted_lr . intercept_ ) Coefficients: [[ 6.06000051e-01 5.45943244e+00 -1.38986070e+00 3.88646170e-02 5.97366917e+00 -2.69884562e-02 -9.53878816e-03 -2.25455372e+02 4.75794718e+00 2.67521123e+00 -6.84063062e-01 -4.48731203e+00] [ -5.28771517e-01 -3.97268408e+00 7.41069180e-01 -7.17514587e-02 -2.69608502e+00 -9.68978915e-03 8.73756253e-03 4.11071885e+02 -4.29878546e+00 -3.12832471e+00 3.39917000e-01 2.61809854e+00] [ 1.48645657e-01 -3.70337304e+00 4.99981786e-01 5.30637763e-02 -5.27689580e+01 2.87090179e-02 -1.44187735e-03 -2.79438251e+02 2.70692558e+00 1.80587581e+00 3.08621873e-01 1.69324095e+00]] Intercepts: [ 207.3234292 -389.74968855 261.7602309 ] In [105]: # %load solutions/multi_logistic.py your answer here 1. We get three sets of coefficients, and three intercepts. We need three sets because (under the default 'one versus rest' strategy) we fit three models. When predicting, model 1 reports a probability of the new example coming from class A or from the cloud of remaining classes. Model 2 reports the probability of whether the example comes from class B or the cloud of remaining classes, and so on. We take this set of scores and pick the biggest one (we classify as whichever class has the biggest ratio of \"this class\" to \"not this class\"). In [106]: # %load solutions/multi_logistic.txt 2. In [107]: # your code here fitted_lr . score ( x_test , y_test ) Out[107]: 0.94499999999999995 In [108]: # %load solutions/score1.py your answer here 2. The model does pretty well at predicting the test data... 3. In [109]: # make a dumb prediction that always guesses 1, the most common class # your code here dumb_prediction = np . ones ( len ( y_test )) np . sum ( y_test == dumb_prediction ) / len ( y_test ) Out[109]: 0.94499999999999995 In [110]: # %load solutions/trivial_model.py your solution here But, a trivial model that guesses the most likely class also does really well on the test set, too. In [23]: # %load solutions/3.3.txt Summary Logistic regression extends OLS to work naturally with a dependent variable that's only ever 0 and 1. In fact, Logistic regression is even more general and is used for predicting the probability of an example belonging to each of $N$ classes. The code for the two cases is identical and just like LinearRegression : .fit , .score , and all the rest Significant predictors does not imply that the model actually works well. Signifigance can be driven by data size alone. The data aren't enough to do what we want Warning : Logistic regression tries to hand back valid probabilities. As with all models, you can't trust the results until you validate them- if you're going to use raw probabilities instead of just predicted class, take the time to verify that if you pool all cases where the model says \"I'm 30% confident it's class A\" 30% of them actually are class A. Part 4: Dimensionality Reduction Our models are clearly struggling, but it's hard to tell why. Let's PCA to shrink the problem down to 2d (with as little loss as possible) and see if that gives us a clue about what makes this problem tough. In [30]: from sklearn.decomposition import PCA from sklearn.preprocessing import StandardScaler # scale the datasets scale_transformer = StandardScaler ( copy = True ) . fit ( x_train ) x_train_scaled = scale_transformer . transform ( x_train ) x_test_scaled = scale_transformer . transform ( x_test ) # reduce dimensions pca_transformer = PCA ( 2 ) . fit ( x_train_scaled ) x_train_2d = pca_transformer . transform ( x_train_scaled ) x_test_2d = pca_transformer . transform ( x_test_scaled ) print ( x_train_2d . shape ) x_train_2d [ 0 : 5 ,:] (800, 2) Out[30]: array([[-1.28544114, 0.68052132], [ 0.96475386, 0.76553387], [ 2.6086408 , 3.00836197], [-2.1666654 , 2.27721531], [ 5.49112049, 5.07139127]]) Some comments: Both scaling and reducing dimension follow the same pattern: we fit the object to the training data, then use .transform to convert the training and test data. This ensures that, for instance, we scale the test data using the training mean and variance, not its own mean and variance We need to equalize the variance of each feature before applying PCA, otherwise certain dimensions will dominate the scaling: our PCA dimensions would just be the features with the largest spread. In [31]: ## plot each group # notice that we set up lists to track each group's plotting color and label colors = [ 'r' , 'c' , 'b' ] label_text = [ \"Bad Wines\" , \"Medium Wines\" , \"Good Wines\" ] # and we loop over the different groups for cur_quality in [ 0 , 1 , 2 ]: cur_df = x_train_2d [ y_train == cur_quality ] plt . scatter ( cur_df [:, 0 ], cur_df [:, 1 ], c = colors [ cur_quality ], label = label_text [ cur_quality ]) # all plots need labels plt . xlabel ( \"PCA Dimension 1\" ) plt . ylabel ( \"PCA Dimention 2\" ) plt . legend (); Well, that gives us some idea of why the problem is difficult: the good wines and bad wines are hiding right among the average wines. It does look like the wines separate into two groups, though, possibly one for reds and one for whites. Exercise 4 What critique can you make against the plot above? Why does this plot not prove that the different wines are hopelessly similar? The wine data we've used so far consist entirely of continuous predictors. Would PCA work with categorical data? Answer : your answer here The PCA dimensions are chosen without regard to the y variable. Thus it is possible that the very next PCA dimension will lift the red points up out of the page, push the blue points down into it, and leave the cyan points where they are; such a dimension would separate the different types of wine and make classification easy. PCA would not work with categorical data. PCA requires there to be a meaningful notion of distance between points. Categorical or ordinal data is not enough. In [39]: # %load solutions/4.txt Exercise 5 Edit the code above to plot the locations of red wines and white wines Answer : In [41]: # your code here ## plot each group # notice that we set up lists to track each group's plotting color and label colors = [ 'r' , 'c' , 'b' ] label_text = [ \"Reds\" , \"Whites\" ] # and we loop over the different groups for cur_color in [ 0 , 1 ]: cur_df = x_train_2d [ x_train [ 'red' ] == cur_color ] plt . scatter ( cur_df [:, 0 ], cur_df [:, 1 ], c = colors [ cur_color ], label = label_text [ cur_color ]) # all plots need labels plt . xlabel ( \"PCA Dimension 1\" ) plt . ylabel ( \"PCA Dimention 2\" ) plt . legend (); Evaluating PCA - Variance Explained One of the criticisms we made of the PCA plot was that it's lost something from the original data. Let's actually investigate how much of the original data's structure the 2d PCA captures. We'll look at the explained_variance_ratio_ portion of the PCA fit. This lists, in order, the percentage of the x data's total variance that is captured by the nth PCA dimension. In [44]: var_explained = pca_transformer . explained_variance_ratio_ print ( \"Variance explained by each PCA component:\" , var_explained ) print ( \"Total Variance Explained:\" , np . sum ( var_explained )) Variance explained by each PCA component: [ 0.34458293 0.20000825] Total Variance Explained: 0.544591176215 The first PCA dimension captures 33% of the variance in the data, and the second PCA dimension adds another 20%. Together, we've got about half of the total variation in the training data covered with just these two dimensions. Exercise 6 Fit a PCA that finds the first 10 PCA components of our training data Use np.cumsum to print out the variance we'd be able to explain by using n PCA dimensions for n=1 through 10 Does the 10-dimension PCA agree with the 2d PCA on how much variance the first components explain? Do the 10d and 2d PCAs find the same first two dimensions? Why or why not? Make a plot of number of PCA dimensions against total variance explained. What PCA dimension looks good to you? Hint: np.cumsum stands for 'cumulative sum', so np.cumsum([1,3,2,-1,2]) is [1,4,6,5,7] Answer : In [46]: #your code here pca_10_transformer = PCA ( 10 ) . fit ( x_train_scaled ) pca_10_transformer np . cumsum ( pca_10_transformer . explained_variance_ratio_ ) Out[46]: array([ 0.34458293, 0.54459118, 0.68072424, 0.76478572, 0.82637787, 0.87162134, 0.91543851, 0.95019104, 0.972941 , 0.98900677]) 3. your answer here The 10d PCA and the 2d PCA agree about how much variance the first two components explain. The 10d and 2d PCA give the same components in the same order. This means it's safe to simply fit a PCA with the largest number of components you expect you will need, and take a subset as appropriate. In [51]: # %load solutions/6.3.txt 4. In [35]: #your code here plt . scatter ( range ( 1 , 11 ), np . cumsum ( pca_10_transformer . explained_variance_ratio_ )) plt . xlabel ( \"PCA Dimension\" ) plt . ylabel ( \"Total Variance Captured\" ) plt . title ( \"Variance Explained by PCA\" ); In [54]: # %load solutions/6.4.py A PCA dimension of 3, 4, or 5 looks good to me. These values are roughly where we hit diminishing returns on variance explained. Plots like the one above are called 'Scree' or 'Elbow' plots. They are often used to heuristically select a good number of PCA dimensions. Summary PCA maps a high-dimensional space into a lower dimensional space. The PCA dimensions are ordered by how much of the original data's variance they capture There are other cool and useful properties of the PCA dimensions (orthogonal, etc.). See a textbook . PCA on a given dataset always gives the same dimensions in the same order. You can select the number of dimensions by fitting a big PCA and examining a plot of the cumulative variance explained. Part 5: Did we fail? None of the models worked, and we can't tell good wines from bad. Was it all a waste of time and money? Not really. All analyses are a roll of the dice. Some analyses fail, like this one did, becuase the data at hand just don't support the task we've set out. What can we do about it? Be honest about the methods and the null result. Lots of analyses fail. Collect a dataset you think has a better chance of success. Maybe we collected the wrong chemical signals... Keep trying new approaches. Just beware of overfitting the data you're validating on. Always have a test set locked away for when the final model is built. Change the question. Maybe something you noticed during analysis seems interesting or useful (classifying red versus white). But again, you the more you try, the more you might overfit, so have test data locked away. Just move on. If the odds of success start to seem small, maybe you need a new project. The Moral of the Lab Sometimes, the data just aren't enough to adequately predict outcomes. In this lab we saw that no amount of modeling finesse would let us use a wine's chemical properties to tell good wines and bad wines from mediocre ones. The chemical properties were very good at telling red wines from whites, however. PCA helped us visualize the data and confirm that the highly rated wines just aren't chemically distinct from the other wines. NOT ALL ANALYSES YIELD USEFUL RESULTS Sometimes (arguably most of the time), the data aren't suitable for a task or just don't have anything interesting to say. Part 6 (Sidebar): Pipelines Remember when we were trying to adapt our LDA model to run on the training data with 'red' dropped? We had to invent new variable names and define functions and it was generally much harder than it needed to be. Pipelines are sklearn 's tool for packaging an entire analysis together into a single object. This enables convenient inspection, saving, deployment, and (yes) cross validation of the model. Let's look at an example (we'll switch the model to KNN to justify some later analysis). In [36]: from sklearn.pipeline import Pipeline knn_pipeline = Pipeline ( [ ( 'scaling' , StandardScaler ()), # scale all columns ( 'dim_reduction' , PCA ()), # PCA to reduce dimension ( 'model' , KNeighborsClassifier ()) # KNN to predict ] ) # run with default settings () knn_pipeline . fit ( x_train , y_train ) print ( \"Test set score (default parameters)\" , knn_pipeline . score ( x_test , y_test )) # particular sub-component settings are accessed with the component name, two # underscores, and the parameter name knn_pipeline . set_params ( dim_reduction__n_components = 2 , model__n_neighbors = 5 ) knn_pipeline . fit ( x_train , y_train ) print ( \"Test set score (updated parameters)\" , knn_pipeline . score ( x_test , y_test )) Test set score (default parameters) 0.945 Test set score (updated parameters) 0.945 There's also a convenience function make_pipeline that lets us skip naming the different steps. Notice the default names are all-lowercase versions of the class names (standardscaler, pca, kneighborsclassifier) In [37]: from sklearn.pipeline import make_pipeline knn_pipeline = make_pipeline ( StandardScaler (), PCA (), KNeighborsClassifier ()) knn_pipeline Out[37]: Pipeline(memory=None, steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None, svd_solver='auto', tol=0.0, whiten=False)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=5, p=2, weights='uniform'))]) It's easy to run the whole modelling process on new data: In [38]: red_model = knn_pipeline . fit ( x_train . drop ( 'red' , axis = 1 ), x_train [ 'red' ]) red_model . score ( x_test . drop ( 'red' , axis = 1 ), x_test [ 'red' ]) Out[38]: 1.0 As promised, cross validation tools work directly with the pipeline object. In [39]: from sklearn.model_selection import cross_val_score cross_val_score ( knn_pipeline , x_train , y_train , cv = 3 ) Out[39]: array([0.94029851, 0.94360902, 0.94360902]) In [40]: from sklearn.model_selection import GridSearchCV search_dict = { 'pca__n_components' : [ 3 , 5 , 10 ], 'kneighborsclassifier__n_neighbors' : [ 1 , 2 , 3 , 4 , 5 ] } cv_results = GridSearchCV ( knn_pipeline , search_dict , cv = 3 ) . fit ( x_train , y_train ) cv_results . best_params_ Out[40]: {'kneighborsclassifier__n_neighbors': 5, 'pca__n_components': 3} Note : In general, more PCA components will work better for prediction. However, KNN often performs worse as dimension increases, meaning there may be a meaningful balance point between capturing more variance and a space small enough for KNN to work well. Part 7 (Sidebar): Weighting the training points Some models can accept weights on the training points to given them greater priority in the model's fitting process. This can be useful if, for instance, certain classes are rare but we want to be sure the model classifies them correctly (e.g. we're trying to classify cancers and one form is rare but very aggressive). In general, weighting training points is like moving along the ROC curve; we change some model parameters to alter the mistakes the model makes to be more in line with our tastes. Let's see this in action with a logistic regression: In [41]: unweighted_lr = LogisticRegression ( C = 1000000 ) . fit ( x_train , y_train ) weight_dict = { 0 : 100 , 1 : 1 , 2 : 100 } weighted_lr = LogisticRegression ( C = 1000000 , class_weight = weight_dict ) . fit ( x_train , y_train ) In [42]: from sklearn.metrics import confusion_matrix print ( \"Rows: True Lables (Bad, Medium, Good), \\n Colummns: Predicted Lables (Bad, Medium, Good)\" ) print () print ( \"unweighted:\" ) print ( confusion_matrix ( y_test , unweighted_lr . predict ( x_test ))) print ( \"weighted:\" ) print ( confusion_matrix ( y_test , weighted_lr . predict ( x_test ))) Rows: True Lables (Bad, Medium, Good), Colummns: Predicted Lables (Bad, Medium, Good) unweighted: [[ 0 7 0] [ 0 189 0] [ 0 4 0]] weighted: [[ 1 6 0] [ 17 156 16] [ 0 2 2]] Without weighting, the model plays it safe and predicts that all of the test set wines are medium. With weighting, the model is told to care more about getting the bad and good wines right. The model does as we've asked and correctly IDs 3 good/bad test wines, at the price of 17 falsely bad wines and 16 falsely good wines. However, if identifying bad and good wines is, as implied, 100 times more important than identifying medium wines, we've made a really good trade. Exercise 7 What happens if you give a weight of 0 to the medium wines? What weighting gives results that accord with your personal sense of what the model should be doing? How many actually-medium bottles is a single good bottle worth? Answers : The model learns a classification rule that never predicts 'medium'. It's as it we dropped the medium wines from training. 100, 1, 100 looks the best to me. We get a 1-in-8 sucess rate on the wines flagged as good. However, I found these values by looking at the test set confusion matrix; it's not clear they'd maintain the 1-in-8 ratio on new data. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab06-nb/"},{"title":"Lab 6: Logistic Regression","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS-109A Introduction to Data Science Lab 6: Logistic Regression Harvard University Fall 2019 Instructors: Pavlos Protopapas, Kevin Rader, Chris Tanner Lab Instructors: Chris Tanner and Eleni Kaxiras. Contributors: Chris Tanner In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } span.sub-q { font-weight: bold; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Learning Goals (EDIT) In this lab, we'll explore different models used to predict which of several labels applies to a new datapoint based on labels observed in the training data. By the end of this lab, you should: Be familiar with the sklearn implementations of Linear Regression Logistic Regression Be able to make an informed choice of model based on the data at hand (Bonus) Structure your sklearn code into Pipelines to make building, fitting, and tracking your models easier In [2]: # IMPORTS GALORE % matplotlib inline import numpy as np import scipy as sp import matplotlib.pyplot as plt import pandas as pd from pandas.plotting import scatter_matrix import statsmodels.api as sm from statsmodels.api import OLS from sklearn.model_selection import train_test_split from sklearn.preprocessing import PolynomialFeatures from sklearn.preprocessing import StandardScaler from sklearn.linear_model import LinearRegression from sklearn.linear_model import Ridge from sklearn.linear_model import Lasso from sklearn.metrics import r2_score from sklearn.metrics import accuracy_score from sklearn.metrics import roc_curve from sklearn.metrics import auc pd . set_option ( 'display.width' , 500 ) pd . set_option ( 'display.max_columns' , 100 ) pd . set_option ( 'display.notebook_repr_html' , True ) Part 1: The AirBnB NYC 2019 Dataset + EDA The dataset contains information about AirBnB hosts in NYC from 2019. There are 49k unique hosts and 16 features for each: id: listing ID name: name of the listing host_id: host ID host_name: name of the host neighbourhood_group: NYC borough neighbourhood: neighborhood latitude: latitude coordinates longitude: longitude coordinates room_type: listing space type (e.g., private room, entire home) price: price in dollars per night minimum_nights: number of min. nights required for booking number_of_reviews: number of reviews last_review: date of the last review reviews_per_month: number of reviews per month calculated_host_listings_count: number of listings the host has availability_365: number of days the listing is available for booking Our goal is to predict the price of unseen housing units as being 'affordable' or 'unaffordable', by using their features. We will assume that this task is for a particular client who has a specific budget and would like to simplify the problem by classifying any unit that costs \\< \\$150 per night as 'affordable' and any unit that costs \\\\$150 or great as 'unaffordable'. For this task, we will exercise our normal data science pipeline -- from EDA to modelling and visualization. In particular, we will show the performance of 3 classifiers: Maximum Likelihood Estimate (MLE) Linear Regression Logistic Regression Let's get started! And awaaaaay we go! Read-in and checking We do the usual read-in and verification of the data: In [3]: df = pd . read_csv ( \"../data/nyc_airbnb.csv\" ) #, index_col=0) df . head () Out[3]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id name host_id host_name neighbourhood_group neighbourhood latitude longitude room_type price minimum_nights number_of_reviews last_review reviews_per_month calculated_host_listings_count availability_365 0 2539 Clean & quiet apt home by the park 2787 John Brooklyn Kensington 40.64749 -73.97237 Private room 149 1 9 2018-10-19 0.21 6 365 1 2595 Skylit Midtown Castle 2845 Jennifer Manhattan Midtown 40.75362 -73.98377 Entire home/apt 225 1 45 2019-05-21 0.38 2 355 2 3647 THE VILLAGE OF HARLEM....NEW YORK ! 4632 Elisabeth Manhattan Harlem 40.80902 -73.94190 Private room 150 3 0 NaN NaN 1 365 3 3831 Cozy Entire Floor of Brownstone 4869 LisaRoxanne Brooklyn Clinton Hill 40.68514 -73.95976 Entire home/apt 89 1 270 2019-07-05 4.64 1 194 4 5022 Entire Apt: Spacious Studio/Loft by central park 7192 Laura Manhattan East Harlem 40.79851 -73.94399 Entire home/apt 80 10 9 2018-11-19 0.10 1 0 Building the training/dev/testing data As usual, we split the data before we begin our analysis. It would be unfair to cheat by looking at the testing data. Let's divide the data into 60% training, 20% development (aka validation), 20% testing. However, before we split the data, let's make the simple transformation and converting the prices into a categories of being affordable or not. In [4]: df [ 'affordable' ] = np . where ( df [ 'price' ] < 150 , 1 , 0 ) df Out[4]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id name host_id host_name neighbourhood_group neighbourhood latitude longitude room_type price minimum_nights number_of_reviews last_review reviews_per_month calculated_host_listings_count availability_365 affordable 0 2539 Clean & quiet apt home by the park 2787 John Brooklyn Kensington 40.64749 -73.97237 Private room 149 1 9 2018-10-19 0.21 6 365 1 1 2595 Skylit Midtown Castle 2845 Jennifer Manhattan Midtown 40.75362 -73.98377 Entire home/apt 225 1 45 2019-05-21 0.38 2 355 0 2 3647 THE VILLAGE OF HARLEM....NEW YORK ! 4632 Elisabeth Manhattan Harlem 40.80902 -73.94190 Private room 150 3 0 NaN NaN 1 365 0 3 3831 Cozy Entire Floor of Brownstone 4869 LisaRoxanne Brooklyn Clinton Hill 40.68514 -73.95976 Entire home/apt 89 1 270 2019-07-05 4.64 1 194 1 4 5022 Entire Apt: Spacious Studio/Loft by central park 7192 Laura Manhattan East Harlem 40.79851 -73.94399 Entire home/apt 80 10 9 2018-11-19 0.10 1 0 1 5 5099 Large Cozy 1 BR Apartment In Midtown East 7322 Chris Manhattan Murray Hill 40.74767 -73.97500 Entire home/apt 200 3 74 2019-06-22 0.59 1 129 0 6 5121 BlissArtsSpace! 7356 Garon Brooklyn Bedford-Stuyvesant 40.68688 -73.95596 Private room 60 45 49 2017-10-05 0.40 1 0 1 7 5178 Large Furnished Room Near B'way 8967 Shunichi Manhattan Hell's Kitchen 40.76489 -73.98493 Private room 79 2 430 2019-06-24 3.47 1 220 1 8 5203 Cozy Clean Guest Room - Family Apt 7490 MaryEllen Manhattan Upper West Side 40.80178 -73.96723 Private room 79 2 118 2017-07-21 0.99 1 0 1 9 5238 Cute & Cozy Lower East Side 1 bdrm 7549 Ben Manhattan Chinatown 40.71344 -73.99037 Entire home/apt 150 1 160 2019-06-09 1.33 4 188 0 10 5295 Beautiful 1br on Upper West Side 7702 Lena Manhattan Upper West Side 40.80316 -73.96545 Entire home/apt 135 5 53 2019-06-22 0.43 1 6 1 11 5441 Central Manhattan/near Broadway 7989 Kate Manhattan Hell's Kitchen 40.76076 -73.98867 Private room 85 2 188 2019-06-23 1.50 1 39 1 12 5803 Lovely Room 1, Garden, Best Area, Legal rental 9744 Laurie Brooklyn South Slope 40.66829 -73.98779 Private room 89 4 167 2019-06-24 1.34 3 314 1 13 6021 Wonderful Guest Bedroom in Manhattan for SINGLES 11528 Claudio Manhattan Upper West Side 40.79826 -73.96113 Private room 85 2 113 2019-07-05 0.91 1 333 1 14 6090 West Village Nest - Superhost 11975 Alina Manhattan West Village 40.73530 -74.00525 Entire home/apt 120 90 27 2018-10-31 0.22 1 0 1 15 6848 Only 2 stops to Manhattan studio 15991 Allen & Irina Brooklyn Williamsburg 40.70837 -73.95352 Entire home/apt 140 2 148 2019-06-29 1.20 1 46 1 16 7097 Perfect for Your Parents + Garden 17571 Jane Brooklyn Fort Greene 40.69169 -73.97185 Entire home/apt 215 2 198 2019-06-28 1.72 1 321 0 17 7322 Chelsea Perfect 18946 Doti Manhattan Chelsea 40.74192 -73.99501 Private room 140 1 260 2019-07-01 2.12 1 12 1 18 7726 Hip Historic Brownstone Apartment with Backyard 20950 Adam And Charity Brooklyn Crown Heights 40.67592 -73.94694 Entire home/apt 99 3 53 2019-06-22 4.44 1 21 1 19 7750 Huge 2 BR Upper East Cental Park 17985 Sing Manhattan East Harlem 40.79685 -73.94872 Entire home/apt 190 7 0 NaN NaN 2 249 0 20 7801 Sweet and Spacious Brooklyn Loft 21207 Chaya Brooklyn Williamsburg 40.71842 -73.95718 Entire home/apt 299 3 9 2011-12-28 0.07 1 0 0 21 8024 CBG CtyBGd HelpsHaiti rm#1:1-4 22486 Lisel Brooklyn Park Slope 40.68069 -73.97706 Private room 130 2 130 2019-07-01 1.09 6 347 1 22 8025 CBG Helps Haiti Room#2.5 22486 Lisel Brooklyn Park Slope 40.67989 -73.97798 Private room 80 1 39 2019-01-01 0.37 6 364 1 23 8110 CBG Helps Haiti Rm #2 22486 Lisel Brooklyn Park Slope 40.68001 -73.97865 Private room 110 2 71 2019-07-02 0.61 6 304 1 24 8490 MAISON DES SIRENES1,bohemian apartment 25183 Nathalie Brooklyn Bedford-Stuyvesant 40.68371 -73.94028 Entire home/apt 120 2 88 2019-06-19 0.73 2 233 1 25 8505 Sunny Bedroom Across Prospect Park 25326 Gregory Brooklyn Windsor Terrace 40.65599 -73.97519 Private room 60 1 19 2019-06-23 1.37 2 85 1 26 8700 Magnifique Suite au N de Manhattan - vue Cloitres 26394 Claude & Sophie Manhattan Inwood 40.86754 -73.92639 Private room 80 4 0 NaN NaN 1 0 1 27 9357 Midtown Pied-a-terre 30193 Tommi Manhattan Hell's Kitchen 40.76715 -73.98533 Entire home/apt 150 10 58 2017-08-13 0.49 1 75 0 28 9518 SPACIOUS, LOVELY FURNISHED MANHATTAN BEDROOM 31374 Shon Manhattan Inwood 40.86482 -73.92106 Private room 44 3 108 2019-06-15 1.11 3 311 1 29 9657 Modern 1 BR / NYC / EAST VILLAGE 21904 Dana Manhattan East Village 40.72920 -73.98542 Entire home/apt 180 14 29 2019-04-19 0.24 1 67 0 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 48865 36472171 1 bedroom in sunlit apartment 99144947 Brenda Manhattan Inwood 40.86845 -73.92449 Private room 80 1 0 NaN NaN 1 79 1 48866 36472710 CozyHideAway Suite 274225617 Alberth Queens Briarwood 40.70786 -73.81448 Entire home/apt 58 1 0 NaN NaN 1 159 1 48867 36473044 The place you were dreaming for.(only for guys) 261338177 Diana Brooklyn Gravesend 40.59080 -73.97116 Shared room 25 1 0 NaN NaN 6 338 1 48868 36473253 Heaven for you(only for guy) 261338177 Diana Brooklyn Gravesend 40.59118 -73.97119 Shared room 25 7 0 NaN NaN 6 365 1 48869 36474023 Cozy, Sunny Brooklyn Escape 1550580 Julia Brooklyn Bedford-Stuyvesant 40.68759 -73.95705 Private room 45 4 0 NaN NaN 1 7 1 48870 36474911 Cozy, clean Williamsburg 1- bedroom apartment 1273444 Tanja Brooklyn Williamsburg 40.71197 -73.94946 Entire home/apt 99 4 0 NaN NaN 1 22 1 48871 36475746 A LARGE ROOM - 1 MONTH MINIMUM - WASHER&DRYER 144008701 Ozzy Ciao Manhattan Harlem 40.82233 -73.94687 Private room 35 29 0 NaN NaN 2 31 1 48872 36476675 Nycity-MyHome 8636072 Ben Manhattan Hell's Kitchen 40.76236 -73.99255 Entire home/apt 260 3 0 NaN NaN 1 9 0 48873 36477307 Brooklyn paradise 241945355 Clement & Rose Brooklyn Flatlands 40.63116 -73.92616 Entire home/apt 170 1 0 NaN NaN 2 363 0 48874 36477588 Short Term Rental in East Harlem 214535893 Jeffrey Manhattan East Harlem 40.79760 -73.93947 Private room 50 7 0 NaN NaN 1 22 1 48875 36478343 Welcome all as family 274273284 Anastasia Manhattan East Harlem 40.78749 -73.94749 Private room 140 1 0 NaN NaN 1 180 1 48876 36478357 Cozy, Air-Conditioned Private Bedroom in Harlem 177932088 Joseph Manhattan Harlem 40.80953 -73.95410 Private room 60 1 0 NaN NaN 1 26 1 48877 36479230 Studio sized room with beautiful light 65767720 Melanie Brooklyn Bushwick 40.70418 -73.91471 Private room 42 7 0 NaN NaN 1 16 1 48878 36479723 Room for rest 41326856 Jeerathinan Queens Elmhurst 40.74477 -73.87727 Private room 45 1 0 NaN NaN 5 172 1 48879 36480292 Gorgeous 1.5 Bdr with a private yard- Williams... 540335 Lee Brooklyn Williamsburg 40.71728 -73.94394 Entire home/apt 120 20 0 NaN NaN 1 22 1 48880 36481315 The Raccoon Artist Studio in Williamsburg New ... 208514239 Melki Brooklyn Williamsburg 40.71232 -73.94220 Entire home/apt 120 1 0 NaN NaN 3 365 1 48881 36481615 Peaceful space in Greenpoint, BK 274298453 Adrien Brooklyn Greenpoint 40.72585 -73.94001 Private room 54 6 0 NaN NaN 1 15 1 48882 36482231 Bushwick _ Myrtle-Wyckoff 66058896 Luisa Brooklyn Bushwick 40.69652 -73.91079 Private room 40 20 0 NaN NaN 1 31 1 48883 36482416 Sunny Bedroom NYC! Walking to Central Park!! 131529729 Kendall Manhattan East Harlem 40.79755 -73.93614 Private room 75 2 0 NaN NaN 2 364 1 48884 36482783 Brooklyn Oasis in the heart of Williamsburg 274307600 Jonathan Brooklyn Williamsburg 40.71790 -73.96238 Private room 190 7 0 NaN NaN 1 341 0 48885 36482809 Stunning Bedroom NYC! Walking to Central Park!! 131529729 Kendall Manhattan East Harlem 40.79633 -73.93605 Private room 75 2 0 NaN NaN 2 353 1 48886 36483010 Comfy 1 Bedroom in Midtown East 274311461 Scott Manhattan Midtown 40.75561 -73.96723 Entire home/apt 200 6 0 NaN NaN 1 176 0 48887 36483152 Garden Jewel Apartment in Williamsburg New York 208514239 Melki Brooklyn Williamsburg 40.71232 -73.94220 Entire home/apt 170 1 0 NaN NaN 3 365 0 48888 36484087 Spacious Room w/ Private Rooftop, Central loca... 274321313 Kat Manhattan Hell's Kitchen 40.76392 -73.99183 Private room 125 4 0 NaN NaN 1 31 1 48889 36484363 QUIT PRIVATE HOUSE 107716952 Michael Queens Jamaica 40.69137 -73.80844 Private room 65 1 0 NaN NaN 2 163 1 48890 36484665 Charming one bedroom - newly renovated rowhouse 8232441 Sabrina Brooklyn Bedford-Stuyvesant 40.67853 -73.94995 Private room 70 2 0 NaN NaN 2 9 1 48891 36485057 Affordable room in Bushwick/East Williamsburg 6570630 Marisol Brooklyn Bushwick 40.70184 -73.93317 Private room 40 4 0 NaN NaN 2 36 1 48892 36485431 Sunny Studio at Historical Neighborhood 23492952 Ilgar & Aysel Manhattan Harlem 40.81475 -73.94867 Entire home/apt 115 10 0 NaN NaN 1 27 1 48893 36485609 43rd St. Time Square-cozy single bed 30985759 Taz Manhattan Hell's Kitchen 40.75751 -73.99112 Shared room 55 1 0 NaN NaN 6 2 1 48894 36487245 Trendy duplex in the very heart of Hell's Kitchen 68119814 Christophe Manhattan Hell's Kitchen 40.76404 -73.98933 Private room 90 7 0 NaN NaN 1 23 1 48895 rows × 17 columns NOTE: The affordable column now has a value of 1 whenever the price is < 150, and 0 otherwise. Also, the feature named neighbourhood_group can be easily confused with neighbourhood , so let's go ahead and rename it to borough , as that is more distinct: In [5]: df . rename ( columns = { \"neighbourhood_group\" : \"borough\" }, inplace = True ) df Out[5]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id name host_id host_name borough neighbourhood latitude longitude room_type price minimum_nights number_of_reviews last_review reviews_per_month calculated_host_listings_count availability_365 affordable 0 2539 Clean & quiet apt home by the park 2787 John Brooklyn Kensington 40.64749 -73.97237 Private room 149 1 9 2018-10-19 0.21 6 365 1 1 2595 Skylit Midtown Castle 2845 Jennifer Manhattan Midtown 40.75362 -73.98377 Entire home/apt 225 1 45 2019-05-21 0.38 2 355 0 2 3647 THE VILLAGE OF HARLEM....NEW YORK ! 4632 Elisabeth Manhattan Harlem 40.80902 -73.94190 Private room 150 3 0 NaN NaN 1 365 0 3 3831 Cozy Entire Floor of Brownstone 4869 LisaRoxanne Brooklyn Clinton Hill 40.68514 -73.95976 Entire home/apt 89 1 270 2019-07-05 4.64 1 194 1 4 5022 Entire Apt: Spacious Studio/Loft by central park 7192 Laura Manhattan East Harlem 40.79851 -73.94399 Entire home/apt 80 10 9 2018-11-19 0.10 1 0 1 5 5099 Large Cozy 1 BR Apartment In Midtown East 7322 Chris Manhattan Murray Hill 40.74767 -73.97500 Entire home/apt 200 3 74 2019-06-22 0.59 1 129 0 6 5121 BlissArtsSpace! 7356 Garon Brooklyn Bedford-Stuyvesant 40.68688 -73.95596 Private room 60 45 49 2017-10-05 0.40 1 0 1 7 5178 Large Furnished Room Near B'way 8967 Shunichi Manhattan Hell's Kitchen 40.76489 -73.98493 Private room 79 2 430 2019-06-24 3.47 1 220 1 8 5203 Cozy Clean Guest Room - Family Apt 7490 MaryEllen Manhattan Upper West Side 40.80178 -73.96723 Private room 79 2 118 2017-07-21 0.99 1 0 1 9 5238 Cute & Cozy Lower East Side 1 bdrm 7549 Ben Manhattan Chinatown 40.71344 -73.99037 Entire home/apt 150 1 160 2019-06-09 1.33 4 188 0 10 5295 Beautiful 1br on Upper West Side 7702 Lena Manhattan Upper West Side 40.80316 -73.96545 Entire home/apt 135 5 53 2019-06-22 0.43 1 6 1 11 5441 Central Manhattan/near Broadway 7989 Kate Manhattan Hell's Kitchen 40.76076 -73.98867 Private room 85 2 188 2019-06-23 1.50 1 39 1 12 5803 Lovely Room 1, Garden, Best Area, Legal rental 9744 Laurie Brooklyn South Slope 40.66829 -73.98779 Private room 89 4 167 2019-06-24 1.34 3 314 1 13 6021 Wonderful Guest Bedroom in Manhattan for SINGLES 11528 Claudio Manhattan Upper West Side 40.79826 -73.96113 Private room 85 2 113 2019-07-05 0.91 1 333 1 14 6090 West Village Nest - Superhost 11975 Alina Manhattan West Village 40.73530 -74.00525 Entire home/apt 120 90 27 2018-10-31 0.22 1 0 1 15 6848 Only 2 stops to Manhattan studio 15991 Allen & Irina Brooklyn Williamsburg 40.70837 -73.95352 Entire home/apt 140 2 148 2019-06-29 1.20 1 46 1 16 7097 Perfect for Your Parents + Garden 17571 Jane Brooklyn Fort Greene 40.69169 -73.97185 Entire home/apt 215 2 198 2019-06-28 1.72 1 321 0 17 7322 Chelsea Perfect 18946 Doti Manhattan Chelsea 40.74192 -73.99501 Private room 140 1 260 2019-07-01 2.12 1 12 1 18 7726 Hip Historic Brownstone Apartment with Backyard 20950 Adam And Charity Brooklyn Crown Heights 40.67592 -73.94694 Entire home/apt 99 3 53 2019-06-22 4.44 1 21 1 19 7750 Huge 2 BR Upper East Cental Park 17985 Sing Manhattan East Harlem 40.79685 -73.94872 Entire home/apt 190 7 0 NaN NaN 2 249 0 20 7801 Sweet and Spacious Brooklyn Loft 21207 Chaya Brooklyn Williamsburg 40.71842 -73.95718 Entire home/apt 299 3 9 2011-12-28 0.07 1 0 0 21 8024 CBG CtyBGd HelpsHaiti rm#1:1-4 22486 Lisel Brooklyn Park Slope 40.68069 -73.97706 Private room 130 2 130 2019-07-01 1.09 6 347 1 22 8025 CBG Helps Haiti Room#2.5 22486 Lisel Brooklyn Park Slope 40.67989 -73.97798 Private room 80 1 39 2019-01-01 0.37 6 364 1 23 8110 CBG Helps Haiti Rm #2 22486 Lisel Brooklyn Park Slope 40.68001 -73.97865 Private room 110 2 71 2019-07-02 0.61 6 304 1 24 8490 MAISON DES SIRENES1,bohemian apartment 25183 Nathalie Brooklyn Bedford-Stuyvesant 40.68371 -73.94028 Entire home/apt 120 2 88 2019-06-19 0.73 2 233 1 25 8505 Sunny Bedroom Across Prospect Park 25326 Gregory Brooklyn Windsor Terrace 40.65599 -73.97519 Private room 60 1 19 2019-06-23 1.37 2 85 1 26 8700 Magnifique Suite au N de Manhattan - vue Cloitres 26394 Claude & Sophie Manhattan Inwood 40.86754 -73.92639 Private room 80 4 0 NaN NaN 1 0 1 27 9357 Midtown Pied-a-terre 30193 Tommi Manhattan Hell's Kitchen 40.76715 -73.98533 Entire home/apt 150 10 58 2017-08-13 0.49 1 75 0 28 9518 SPACIOUS, LOVELY FURNISHED MANHATTAN BEDROOM 31374 Shon Manhattan Inwood 40.86482 -73.92106 Private room 44 3 108 2019-06-15 1.11 3 311 1 29 9657 Modern 1 BR / NYC / EAST VILLAGE 21904 Dana Manhattan East Village 40.72920 -73.98542 Entire home/apt 180 14 29 2019-04-19 0.24 1 67 0 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 48865 36472171 1 bedroom in sunlit apartment 99144947 Brenda Manhattan Inwood 40.86845 -73.92449 Private room 80 1 0 NaN NaN 1 79 1 48866 36472710 CozyHideAway Suite 274225617 Alberth Queens Briarwood 40.70786 -73.81448 Entire home/apt 58 1 0 NaN NaN 1 159 1 48867 36473044 The place you were dreaming for.(only for guys) 261338177 Diana Brooklyn Gravesend 40.59080 -73.97116 Shared room 25 1 0 NaN NaN 6 338 1 48868 36473253 Heaven for you(only for guy) 261338177 Diana Brooklyn Gravesend 40.59118 -73.97119 Shared room 25 7 0 NaN NaN 6 365 1 48869 36474023 Cozy, Sunny Brooklyn Escape 1550580 Julia Brooklyn Bedford-Stuyvesant 40.68759 -73.95705 Private room 45 4 0 NaN NaN 1 7 1 48870 36474911 Cozy, clean Williamsburg 1- bedroom apartment 1273444 Tanja Brooklyn Williamsburg 40.71197 -73.94946 Entire home/apt 99 4 0 NaN NaN 1 22 1 48871 36475746 A LARGE ROOM - 1 MONTH MINIMUM - WASHER&DRYER 144008701 Ozzy Ciao Manhattan Harlem 40.82233 -73.94687 Private room 35 29 0 NaN NaN 2 31 1 48872 36476675 Nycity-MyHome 8636072 Ben Manhattan Hell's Kitchen 40.76236 -73.99255 Entire home/apt 260 3 0 NaN NaN 1 9 0 48873 36477307 Brooklyn paradise 241945355 Clement & Rose Brooklyn Flatlands 40.63116 -73.92616 Entire home/apt 170 1 0 NaN NaN 2 363 0 48874 36477588 Short Term Rental in East Harlem 214535893 Jeffrey Manhattan East Harlem 40.79760 -73.93947 Private room 50 7 0 NaN NaN 1 22 1 48875 36478343 Welcome all as family 274273284 Anastasia Manhattan East Harlem 40.78749 -73.94749 Private room 140 1 0 NaN NaN 1 180 1 48876 36478357 Cozy, Air-Conditioned Private Bedroom in Harlem 177932088 Joseph Manhattan Harlem 40.80953 -73.95410 Private room 60 1 0 NaN NaN 1 26 1 48877 36479230 Studio sized room with beautiful light 65767720 Melanie Brooklyn Bushwick 40.70418 -73.91471 Private room 42 7 0 NaN NaN 1 16 1 48878 36479723 Room for rest 41326856 Jeerathinan Queens Elmhurst 40.74477 -73.87727 Private room 45 1 0 NaN NaN 5 172 1 48879 36480292 Gorgeous 1.5 Bdr with a private yard- Williams... 540335 Lee Brooklyn Williamsburg 40.71728 -73.94394 Entire home/apt 120 20 0 NaN NaN 1 22 1 48880 36481315 The Raccoon Artist Studio in Williamsburg New ... 208514239 Melki Brooklyn Williamsburg 40.71232 -73.94220 Entire home/apt 120 1 0 NaN NaN 3 365 1 48881 36481615 Peaceful space in Greenpoint, BK 274298453 Adrien Brooklyn Greenpoint 40.72585 -73.94001 Private room 54 6 0 NaN NaN 1 15 1 48882 36482231 Bushwick _ Myrtle-Wyckoff 66058896 Luisa Brooklyn Bushwick 40.69652 -73.91079 Private room 40 20 0 NaN NaN 1 31 1 48883 36482416 Sunny Bedroom NYC! Walking to Central Park!! 131529729 Kendall Manhattan East Harlem 40.79755 -73.93614 Private room 75 2 0 NaN NaN 2 364 1 48884 36482783 Brooklyn Oasis in the heart of Williamsburg 274307600 Jonathan Brooklyn Williamsburg 40.71790 -73.96238 Private room 190 7 0 NaN NaN 1 341 0 48885 36482809 Stunning Bedroom NYC! Walking to Central Park!! 131529729 Kendall Manhattan East Harlem 40.79633 -73.93605 Private room 75 2 0 NaN NaN 2 353 1 48886 36483010 Comfy 1 Bedroom in Midtown East 274311461 Scott Manhattan Midtown 40.75561 -73.96723 Entire home/apt 200 6 0 NaN NaN 1 176 0 48887 36483152 Garden Jewel Apartment in Williamsburg New York 208514239 Melki Brooklyn Williamsburg 40.71232 -73.94220 Entire home/apt 170 1 0 NaN NaN 3 365 0 48888 36484087 Spacious Room w/ Private Rooftop, Central loca... 274321313 Kat Manhattan Hell's Kitchen 40.76392 -73.99183 Private room 125 4 0 NaN NaN 1 31 1 48889 36484363 QUIT PRIVATE HOUSE 107716952 Michael Queens Jamaica 40.69137 -73.80844 Private room 65 1 0 NaN NaN 2 163 1 48890 36484665 Charming one bedroom - newly renovated rowhouse 8232441 Sabrina Brooklyn Bedford-Stuyvesant 40.67853 -73.94995 Private room 70 2 0 NaN NaN 2 9 1 48891 36485057 Affordable room in Bushwick/East Williamsburg 6570630 Marisol Brooklyn Bushwick 40.70184 -73.93317 Private room 40 4 0 NaN NaN 2 36 1 48892 36485431 Sunny Studio at Historical Neighborhood 23492952 Ilgar & Aysel Manhattan Harlem 40.81475 -73.94867 Entire home/apt 115 10 0 NaN NaN 1 27 1 48893 36485609 43rd St. Time Square-cozy single bed 30985759 Taz Manhattan Hell's Kitchen 40.75751 -73.99112 Shared room 55 1 0 NaN NaN 6 2 1 48894 36487245 Trendy duplex in the very heart of Hell's Kitchen 68119814 Christophe Manhattan Hell's Kitchen 40.76404 -73.98933 Private room 90 7 0 NaN NaN 1 23 1 48895 rows × 17 columns Without looking at the full data yet, let's just ensure our prices are within valid ranges: In [6]: df [ 'price' ] . describe () Out[6]: count 48895.000000 mean 152.720687 std 240.154170 min 0.000000 25% 69.000000 50% 106.000000 75% 175.000000 max 10000.000000 Name: price, dtype: float64 Uh-oh. We see that price has a minimum value of \\$0. I highly doubt any unit in NYC is free. These data instances are garbage, so let's go ahead and remove any instance that has a price of \\\\$0. In [7]: print ( \"original training size:\" , df . shape ) df = df . loc [ df [ 'price' ] != 0 ] print ( \"new training size:\" , df . shape ) original training size: (48895, 17) new training size: (48884, 17) Now, let's split the data while ensuring that our test set has a fair distribution of affordable units, then further split our training set so as to create the development set: In [8]: df_train , df_test = train_test_split ( df , test_size = 0.2 , random_state = 42 , stratify = df [ 'affordable' ]) df_train , df_dev = train_test_split ( df_train , test_size = 0.25 , random_state = 99 ) #stratify=df_train['affordable']) # ensure our dataset splits are of the % sizes we want total_size = len ( df_train ) + len ( df_dev ) + len ( df_test ) print ( \"train:\" , len ( df_train ), \"=>\" , len ( df_train ) / total_size ) print ( \"dev:\" , len ( df_dev ), \" =>\" , len ( df_dev ) / total_size ) print ( \"test:\" , len ( df_test ), \"=>\" , len ( df_test ) / total_size ) train: 29330 => 0.5999918173635546 dev: 9777 => 0.20000409131822272 test: 9777 => 0.20000409131822272 Let's remove the target value (i.e., affordable ) from our current dataframes and create it as separate prediction dataframes. In [9]: # training x_train = df_train . drop ([ 'price' , 'affordable' ], axis = 1 ) y_train = pd . DataFrame ( data = df_train [ 'affordable' ], columns = [ \"affordable\" ]) # dev x_dev = df_dev . drop ([ 'price' , 'affordable' ], axis = 1 ) y_dev = pd . DataFrame ( data = df_dev [ 'affordable' ], columns = [ \"affordable\" ]) # test x_test = df_test . drop ([ 'price' , 'affordable' ], axis = 1 ) y_test = pd . DataFrame ( data = df_test [ 'affordable' ], columns = [ \"affordable\" ]) From now onwards, we will do EDA and cleaning based on the training set, x_train . In [10]: for col in x_train . columns : print ( col , \":\" , np . sum ([ x_train [ col ] . isnull ()])) id : 0 name : 12 host_id : 0 host_name : 12 borough : 0 neighbourhood : 0 latitude : 0 longitude : 0 room_type : 0 minimum_nights : 0 number_of_reviews : 0 last_review : 6065 reviews_per_month : 6065 calculated_host_listings_count : 0 availability_365 : 0 Oh dear. It appears ~6k of the rows have missing values concerning the reviews. It seems impossible to impute the last_review feature with reasonable values, as this is very specific to each unit. At best, we could guess the date based on the reviews_per_month , but that feature is missing for the same rows. Further, it might be difficult to replace reviews_per_month with reasonable values -- sure, we could fill in values to be the median value, but that seems wrong to generalize so heavily, especially for over 20% of our data. Consequently, let's just ignore these two columns. In [11]: x_train = x_train . drop ([ 'last_review' , 'reviews_per_month' ], axis = 1 ) x_dev = x_dev . drop ([ 'last_review' , 'reviews_per_month' ], axis = 1 ) x_test = x_test . drop ([ 'last_review' , 'reviews_per_month' ], axis = 1 ) Let's look at the summary statistics of the data: In [12]: x_train . describe () Out[12]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id host_id latitude longitude minimum_nights number_of_reviews calculated_host_listings_count availability_365 count 2.933000e+04 2.933000e+04 29330.000000 29330.000000 29330.000000 29330.000000 29330.000000 29330.000000 mean 1.899091e+07 6.746725e+07 40.729049 -73.952129 6.891647 23.490829 7.111081 113.047017 std 1.102972e+07 7.863754e+07 0.054446 0.046320 19.236816 45.324235 32.904893 131.845296 min 2.539000e+03 2.438000e+03 40.499790 -74.242850 1.000000 0.000000 1.000000 0.000000 25% 9.380684e+06 7.794212e+06 40.690423 -73.983130 1.000000 1.000000 1.000000 0.000000 50% 1.960499e+07 3.049924e+07 40.723090 -73.955630 3.000000 5.000000 1.000000 44.000000 75% 2.921518e+07 1.074344e+08 40.763067 -73.936100 5.000000 24.000000 2.000000 228.000000 max 3.648561e+07 2.743213e+08 40.913060 -73.712990 1000.000000 629.000000 327.000000 365.000000 Next, we see that the minimum_nights feature has a maximum value of 1,250. That's almost 3.5 years, which is probably longer than the duration that most people rent an apartment. This seems anomalous and wrong. Let's discard it and other units that are outrageous. Well, what constitutes 'outrageous'? We see that the standard deviation for minimum_nights is 21.24. If we assume our distribution of values are normally distributed, then only using values that are within 2 standard deviations of the mean would yield us with ~95% of the original data. However, we have no reason to believe our data is actually normally distributed, especially since our mean is 7. To have a better idea of our actual values, let's plot it as a histogram. In [13]: fig , ax = plt . subplots ( 1 , 1 ) ax . hist ( x_train [ 'minimum_nights' ], 25 , log = True ) plt . xlabel ( 'minimum_nights' ) plt . ylabel ( 'count' ) Out[13]: Text(0, 0.5, 'count') Yea, that instance was a strong outlier, and the host was being ridiculously greedy. That's a clever way to get out a multi-year lease. Notice that we are using log-scale. Clearly, a lot of our mass is from units less than 365 days. To get a better sense of that subset, let's re-plot only units with minumum_nights < 365 days. In [14]: subset = x_train [ 'minimum_nights' ] < 365 fig , ax = plt . subplots ( 1 , 1 ) ax . hist ( x_train [ 'minimum_nights' ][ subset ], 30 , log = True ) plt . xlabel ( 'minimum_nights' ) plt . ylabel ( 'count' ) Out[14]: Text(0, 0.5, 'count') Ok, that doesn't look too bad, as most units require < 30 nights. It's surprising that some hosts list an unreasonable requirement for the minimum number of nights. There is a risk that any host that lists such an unreasonable value might also have other incorrect information. Personally, I think anything beyond 30 days could be suspicious. If we were to exclude any unit that requires more than 30 days, how many instances would we be ignoring? In [15]: len ( x_train . loc [ x_train [ 'minimum_nights' ] > 30 ]) Out[15]: 436 Alright, we'd be throwing away 436 out of our ~30k entries. That's roughly 1.5\\% of our data. While we generally want to keep and use as much data as we can, I think this is an okay amount to discard, especially considering (1) we have a decently large amount of data remaining, and (2) the entries beyond a 30-day-min could be unrealiable. In [16]: good_subset = x_train [ 'minimum_nights' ] <= 30 x_train = x_train . loc [ good_subset ] y_train = y_train . loc [ good_subset ] Notice that we only trimmed our training data, not our development or testing data. I am making this choice because in real scenarios, we would not know the nature of the testing data values. We pre-processed our data to ignore all data that has a price of $0, and to ignore certain columns (even if it's in the testing set), but that was fair because those columns proved to be obvious, bogus element of the dataset. However, it would be unfair to inspect the values of the training set and then to further trim the development and testing set accordingly, conditioned on certain data values. The remaining columns of our training data all have reasonable summary statistics. None of the min's or max's are cause for concern, and we have no reason to assert a certain distribution of values. Since all the feature values are within reasonable ranges, and there are no missing values (NaNs) remaining, we can confidently move foward. To recap, our remaining columns are now: In [17]: [ col for col in x_train . columns ] # easier to read vertically than horizontally Out[17]: ['id', 'name', 'host_id', 'host_name', 'borough', 'neighbourhood', 'latitude', 'longitude', 'room_type', 'minimum_nights', 'number_of_reviews', 'calculated_host_listings_count', 'availability_365'] We don't have a terribly large number of features. This allows us to inspect every pairwise interaction. A scatterplot is great for this, as it provides us with a high-level picture of how every pair of features correlates. If any subplot of features depicts a linear relationship (i.e., a clear, concise path with mass concentrated together), then we can assume there exists some collinearity -- that the two features overlap in what they are capturing and that they are not independent from each other. In [18]: scatter_matrix ( x_train , figsize = ( 30 , 20 )); Part 2: Predicting with MLE Maximum-likelihood estimation (MLE) is a very simple model which does not require learning any weight/coefficient parameters. Specifically, MLE selects the parameter value ($y$) that makes the observed data most probable, so as to maximize the likelihood function. This choice of $y$ is completely independent of $x$. That is, a MLE model returns the $y$-value that was probable in the data its seen. Exercise 1: Using the training data, select the MLE for $y$, where $y \\in \\{0,1\\}$. Using the development to evaluate your MLE model, what is the accuracy (the % correct)? In [19]: # [SOLUTION: REMOVE] mle_y = y_train [ 'affordable' ] . value_counts () . idxmax () dev_accuracy = y_dev [ 'affordable' ] . value_counts ()[ mle_y ] / len ( y_dev [ 'affordable' ]) dev_accuracy Out[19]: 0.650301728546589 Part 3: Predicting with Linear Regression Now, let's actually use our features to make more informed predictions. Since our model needs to use numeric values, not textual ones, let's use ONLY the following features for our linear model: borough , using 1-hot encodings. There are 5 distinct boroughs, so represent them via 4 unique columns. latitude longitude room_type , using 1-hot encodings. There are 3 distinct room_types, so represent them via 2 unique columns. minimum_nights number_of_reviews calculated_host_listings_count availability_365 Exercise 2: Convert `x_train` to have only the columns listed above. The shape should be 28,894 x 12 In [20]: # [SOLUTION: remove!!] x_train = pd . get_dummies ( x_train , columns = [ 'borough' , 'room_type' ], drop_first = True ) x_train = x_train . drop ([ 'id' , 'name' , 'host_id' , 'host_name' , 'neighbourhood' ], axis = 1 ) x_dev = pd . get_dummies ( x_dev , columns = [ 'borough' , 'room_type' ], drop_first = True ) x_dev = x_dev . drop ([ 'id' , 'name' , 'host_id' , 'host_name' , 'neighbourhood' ], axis = 1 ) x_test = pd . get_dummies ( x_test , columns = [ 'borough' , 'room_type' ], drop_first = True ) x_test = x_test . drop ([ 'id' , 'name' , 'host_id' , 'host_name' , 'neighbourhood' ], axis = 1 ) Exercise 3: For this exercise, perform multi-linear regression and evaluate it on the development set. Do not introduce any polynomial terms or any other new features. Any prediction that is >= 0.5 should be treated as being an 'affordable' prediction. Anything below 0.5 should be 'unaffordable'. What is your accuracy %? (). Is this what you expected? Is this reasonable, and if not, what do you think are the issues? In [21]: # [SOLUTION HERE] # training set x_train_padded = sm . add_constant ( x_train ) # to allow for beta_0 y_train_lr = y_train [ 'affordable' ] . values . reshape ( - 1 , 1 ) # development set x_dev_padded = sm . add_constant ( x_dev ) y_dev_lr = y_dev [ 'affordable' ] . values . reshape ( - 1 , 1 ) /usr/local/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead. return ptp(axis=axis, out=out, **kwargs) In [22]: model = OLS ( y_train_lr , x_train_padded ) results = model . fit () results . summary () Out[22]: OLS Regression Results Dep. Variable: y R-squared: 0.371 Model: OLS Adj. R-squared: 0.371 Method: Least Squares F-statistic: 1422. Date: Sun, 13 Oct 2019 Prob (F-statistic): 0.00 Time: 15:07:15 Log-Likelihood: -12826. No. Observations: 28894 AIC: 2.568e+04 Df Residuals: 28881 BIC: 2.579e+04 Df Model: 12 Covariance Type: nonrobust coef std err t P>|t| [0.025 0.975] const 96.8761 6.899 14.042 0.000 83.354 110.398 latitude 0.5947 0.067 8.825 0.000 0.463 0.727 longitude 1.6313 0.077 21.062 0.000 1.480 1.783 minimum_nights 0.0052 0.000 17.194 0.000 0.005 0.006 number_of_reviews 0.0008 5.08e-05 14.877 0.000 0.001 0.001 calculated_host_listings_count -0.0007 7.39e-05 -9.368 0.000 -0.001 -0.001 availability_365 -0.0004 1.85e-05 -23.768 0.000 -0.000 -0.000 borough_Brooklyn 0.0728 0.019 3.828 0.000 0.036 0.110 borough_Manhattan -0.1229 0.017 -7.107 0.000 -0.157 -0.089 borough_Queens -0.0038 0.018 -0.209 0.835 -0.040 0.032 borough_Staten Island 0.4936 0.036 13.864 0.000 0.424 0.563 room_type_Private room 0.4636 0.005 99.360 0.000 0.454 0.473 room_type_Shared room 0.5049 0.015 34.059 0.000 0.476 0.534 Omnibus: 565.926 Durbin-Watson: 2.004 Prob(Omnibus): 0.000 Jarque-Bera (JB): 331.005 Skew: -0.093 Prob(JB): 1.33e-72 Kurtosis: 2.510 Cond. No. 5.73e+05 Warnings: [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. [2] The condition number is large, 5.73e+05. This might indicate that there are strong multicollinearity or other numerical problems. In [23]: # your code here y_hat_dev = results . predict ( exog = x_dev_padded ) # calculating and reporting the requested values, particularly the Test R&#94;2 print ( 'Train R&#94;2 = {:.4} ' . format ( results . rsquared )) print ( 'Test R&#94;2 = {:.4} ' . format ( r2_score ( y_dev_lr , y_hat_dev ))) # i'm using numpy's round() function, instead of manually checking for values above 0.5 accuracy_score ( y_dev , np . round ( y_hat_dev )) Train R&#94;2 = 0.3714 Test R&#94;2 = 0.3 Out[23]: 0.7751866625754321 Exercise 4: Akin to what you did in Homework 3, regularize your model via Ridge regression and Lasso regression. Specifically, report the model's accuracy on the development set (as you did in Exercise 2); do so while varying the alpha (aka lambda) parameter to be each of these values: [.001, .01, .05, .1, .5, 1, 5, 10, 50, 100, 500]). What is your best result? In [32]: # [SOLUTION HERE] best_accuracy = - 1 best_model = None for cur_alpha in [ 0.001 , . 01 , . 05 , . 1 , . 5 , 1 , 5 , 10 , 50 , 100 , 500 ]: # fit (using Ridge Regression), predict, and score fitted_ridge = Ridge ( alpha = cur_alpha ) . fit ( x_train , y_train_lr ) y_hat_dev = fitted_ridge . predict ( x_dev ) . reshape ( 1 , - 1 )[ 0 ] cur_accuracy = accuracy_score ( y_dev [ 'affordable' ] . to_numpy (), np . round ( y_hat_dev )) if cur_accuracy > best_accuracy : best_accuracy = cur_accuracy best_model = fitted_ridge # fit (using Lasso Regression), predict, and score fitted_lasso = Lasso ( alpha = cur_alpha ) . fit ( x_train , y_train_lr ) y_hat_dev = fitted_lasso . predict ( x_dev ) . reshape ( 1 , - 1 )[ 0 ] cur_accuracy = accuracy_score ( y_dev [ 'affordable' ] . to_numpy (), np . round ( y_hat_dev )) if cur_accuracy > best_accuracy : best_accuracy = cur_accuracy best_model = fitted_lasso print ( \"best_model:\" , best_model , \"yielded accuracy of:\" , best_accuracy ) best_model: Ridge(alpha=100, copy_X=True, fit_intercept=True, max_iter=None, normalize=False, random_state=None, solver='auto', tol=0.001) yielded accuracy of: 0.7777436841566943 Note, we did not perform cross-validation, so perhaps our model could have performed even better, had we done so. Exercise 5: Plot two histograms of the residuals from your best performing linear regression model (having trained on the training set, one plot should show the distribution of training set residuals and another plot for the distribution of development set residuals). Does this adhere to the assumptions of a linear model? In [36]: # [SOLUTION HERE] # construct training residuals y_hat_train = best_model . predict ( x_train ) training_residuals = y_train_lr [:, 0 ] - y_hat_train [:, 0 ] # construct dev residuals y_hat_dev = best_model . predict ( x_dev ) . reshape ( 1 , - 1 )[ 0 ] dev_residuals = y_dev [ 'affordable' ] . to_numpy () - y_hat_dev # make plot of training residuals fig , axes = plt . subplots ( 1 , 2 , figsize = ( 15 , 5 )) axes [ 0 ] . set_title ( 'Histogram of Training Residuals' ) axes [ 0 ] . hist ( training_residuals , alpha = 0.8 , bins = 20 ) axes [ 0 ] . axhline ( 0 , c = 'black' , lw = 2 ) axes [ 0 ] . set_xlabel ( r 'residuals' ) # make plot of dev residuals axes [ 1 ] . set_title ( 'Histogram of Development Residuals' ) axes [ 1 ] . hist ( dev_residuals , alpha = 0.4 , bins = 20 ) axes [ 1 ] . axhline ( 0 , c = 'black' , lw = 2 ) axes [ 1 ] . set_xlabel ( r 'residuals' ) plt . show () print ( \"min residual:\" , min ( dev_residuals )) min residual: -6.374920636446401 The above plots suggest that the training data is not too conducive to being modelled by a linear regression model, for the residuals seem to be bimodal -- there isn't a single normal distrubion of residual values. Also, just for fun, we plotted the errors/residuals from having evaluated on the unseen development set. Doing so would provide no information about the assumptions of linear model being appropriate for our training data (as the unseen data could be completely dissimiliar from anything we saw during training). Yet, we hope that the development set residuals would be minimal, and it's nice that the errors seem to follow a normal distrubtion -- although, there's some outliers that we perform badly on, but this can happen. Part 4: Binary Logistic Regression Linear regression is usually a good baseline model, but since the outcome we're trying to predict only takes values 0 and 1 we'll want to use logistic regression instead of basic linear regression. We will use sklearn for now, but statsmodels also provides LogisticRegression, along with nifty features like confidence intervals. First, let's import the necessary classes: In [37]: from sklearn.linear_model import LogisticRegression Next, let's instantiate a new LogisticRegression model: In [38]: lr = LogisticRegression () Now, we can fit our model with just 1 line! In [39]: lr . fit ( x_train , y_train [ 'affordable' ]) /usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning. FutureWarning) Out[39]: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='warn', n_jobs=None, penalty='l2', random_state=None, solver='warn', tol=0.0001, verbose=0, warm_start=False) Exercise 6: Using .predict(), make predictions on the development set See .predict() documentation here. NOTE: regularization is applied by default. Especially pay attention to the following arguments/parameters: C penalty, which we discussed in class. Experiment with varying values from 0 to 100 million! max_iterations : experiment with values from 5 to 5000. Do you expect more iterations to always perform better? Why or why not? penalty : for designating L1 (Lasso) or L2 (Ridge) loss; default is L2 solver : especially for the multi-class setting After fitting the model, you can print the .coef_ value to see its coefficient. In [40]: y_hat_dev = lr . predict ( x_dev ) initial_score = accuracy_score ( y_dev [ 'affordable' ] . to_numpy (), y_hat_dev ) print ( \"our initial logistic regression model yielded accuracy score of:\" , initial_score ) best_accuracy = - 1 best_model = None # experiment with different values c_vals = [ 1 , 10 , 100 , 1000 , 10000 , 100000 , 1000000 , 10000000 ] num_iters = [ 5 , 10 , 100 , 1000 , 5000 ] for c_val in c_vals : for num_iter in num_iters : lr = LogisticRegression ( C = c_val , solver = 'liblinear' , max_iter = num_iter ) lr . fit ( x_train , y_train [ 'affordable' ]) y_hat_dev = lr . predict ( x_dev ) cur_accuracy = accuracy_score ( y_dev [ 'affordable' ] . to_numpy (), y_hat_dev ) if cur_accuracy > best_accuracy : best_accuracy = cur_accuracy best_model = lr print ( \"best logistic regression model:\" , lr , \"yielded an accuracy score:\" , best_accuracy ) print ( \"its learned coefficients:\" , len ( best_model . coef_ [ 0 ])) print ( \"the coefficients align with our features:\" , x_dev . shape ) our initial logistic regression model yielded accuracy score of: 0.7737547304899254 /usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. \"the number of iterations.\", ConvergenceWarning) /usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. \"the number of iterations.\", ConvergenceWarning) /usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. \"the number of iterations.\", ConvergenceWarning) /usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. \"the number of iterations.\", ConvergenceWarning) /usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. \"the number of iterations.\", ConvergenceWarning) /usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. \"the number of iterations.\", ConvergenceWarning) /usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. \"the number of iterations.\", ConvergenceWarning) /usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. \"the number of iterations.\", ConvergenceWarning) /usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. \"the number of iterations.\", ConvergenceWarning) /usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. \"the number of iterations.\", ConvergenceWarning) /usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. \"the number of iterations.\", ConvergenceWarning) /usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. \"the number of iterations.\", ConvergenceWarning) /usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. \"the number of iterations.\", ConvergenceWarning) /usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. \"the number of iterations.\", ConvergenceWarning) /usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. \"the number of iterations.\", ConvergenceWarning) /usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. \"the number of iterations.\", ConvergenceWarning) best logistic regression model: LogisticRegression(C=10000000, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=5000, multi_class='warn', n_jobs=None, penalty='l2', random_state=None, solver='liblinear', tol=0.0001, verbose=0, warm_start=False) yielded an accuracy score: 0.7737547304899254 its learned coefficients: 12 the coefficients align with our features: (9777, 12) The results here should show that for this dataset, logistic regression offered effectively identical performance as linear regression. There are two main takeaways from this: logistic regression should not be viewed as being superior to linear regression; it should be viewed as a solution to a different type of problem -- classification (predicting categorical outputs), not regression (predicting continuous-valued outputs). In our situation, our two categories/classes (affordable or not) had an ordinal nature. That is, the continuum of prices directly aligned with the structure of our two classes. Alternatively, you could imagine other scenarios where our two categories are nominal and thus un-rankable (e.g., predicting cancer or not, or predicting which NYC borough an AirBnB is in based on its property features). Part 5 (The Real Challenge): Multiclass Classification Before we move on, let's consider a more common use case of logistic regression: predicting not just a binary variable, but what level a categorical variable will take. Instead of breaking the price variable into two classes (affordable being true or false), we may care for more fine-level granularity. For this exercise, go back to the original df dataframe and construct 5 classes of pricing: budget: < 80 affordable: 80 < x < 120 average: 120 < x < 180 expensive: 180 < x < 240 very expensive: 240 < x The cut function obviously stores a lot of extra information for us. It's a very useful tool for discretizing an existing variable. Exercise 8: After making the new categories, perform the same predictions as above. Compare your results. What improvements could we make? (not just w/ the parameters, but with possibly expanding and using other features from our original dataset!) In [41]: # creates multi-class labels for training x_train_multiclass = x_train . copy () x_train_multiclass [ 'price_level' ] = pd . cut ( df_train [ 'price' ],[ 0 , 80 , 120 , 180 , 240 , float ( 'inf' )], labels = [ 0 , 1 , 2 , 3 , 4 ]) y_train_multiclass = pd . DataFrame ( data = x_train_multiclass [ 'price_level' ], columns = [ \"price_level\" ]) x_train_multiclass = x_train_multiclass . drop ([ 'price_level' ], axis = 1 ) # creats multi-class labels for dev x_dev_multiclass = x_dev . copy () x_dev_multiclass [ 'price_level' ] = pd . cut ( df_dev [ 'price' ],[ 0 , 80 , 120 , 180 , 240 , float ( 'inf' )], labels = [ 0 , 1 , 2 , 3 , 4 ]) y_dev_multiclass = pd . DataFrame ( data = x_dev_multiclass [ 'price_level' ], columns = [ \"price_level\" ]) x_dev_multiclass = x_dev_multiclass . drop ([ 'price_level' ], axis = 1 ) In [42]: best_accuracy = - 1 best_model = None # experiment with different values c_vals = [ 1 , 10 , 100 , 1000 , 10000 ] num_iters = [ 10 , 100 , 1000 , 5000 ] for c_val in c_vals : for num_iter in num_iters : lr = LogisticRegression ( solver = \"lbfgs\" , max_iter = 10000 ) lr . fit ( x_train_multiclass , y_train_multiclass [ 'price_level' ]) y_hat_dev = lr . predict ( x_dev_multiclass ) cur_accuracy = accuracy_score ( y_dev_multiclass [ 'price_level' ] . to_numpy (), y_hat_dev ) print ( cur_accuracy ) if cur_accuracy > best_accuracy : best_accuracy = cur_accuracy best_model = lr /usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning. \"this warning.\", FutureWarning) 0.5048583410043981 /usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning. \"this warning.\", FutureWarning) 0.5048583410043981 /usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning. \"this warning.\", FutureWarning) 0.5048583410043981 /usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning. \"this warning.\", FutureWarning) 0.5048583410043981 /usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning. \"this warning.\", FutureWarning) 0.5048583410043981 /usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning. \"this warning.\", FutureWarning) 0.5048583410043981 /usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning. \"this warning.\", FutureWarning) 0.5048583410043981 /usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning. \"this warning.\", FutureWarning) 0.5048583410043981 /usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning. \"this warning.\", FutureWarning) 0.5048583410043981 /usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning. \"this warning.\", FutureWarning) 0.5048583410043981 /usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning. \"this warning.\", FutureWarning) 0.5048583410043981 /usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning. \"this warning.\", FutureWarning) 0.5048583410043981 /usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning. \"this warning.\", FutureWarning) 0.5048583410043981 /usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning. \"this warning.\", FutureWarning) 0.5048583410043981 /usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning. \"this warning.\", FutureWarning) 0.5048583410043981 /usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning. \"this warning.\", FutureWarning) 0.5048583410043981 /usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning. \"this warning.\", FutureWarning) 0.5048583410043981 /usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning. \"this warning.\", FutureWarning) 0.5048583410043981 /usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning. \"this warning.\", FutureWarning) 0.5048583410043981 /usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning. \"this warning.\", FutureWarning) 0.5048583410043981 In [43]: print ( \"best logistic regression model:\" , lr , \"yielded an accuracy score:\" , best_accuracy ) print ( \"its learned coefficients:\" , len ( best_model . coef_ [ 0 ])) print ( \"the coefficients align with our features:\" , x_dev . shape ) for i in range ( len ( x_dev . columns )): print ( \"feature:\" , x_dev . columns [ i ], \"; coef:\" , best_model . coef_ [ 0 ][ i ]) best logistic regression model: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=10000, multi_class='warn', n_jobs=None, penalty='l2', random_state=None, solver='lbfgs', tol=0.0001, verbose=0, warm_start=False) yielded an accuracy score: 0.5048583410043981 its learned coefficients: 12 the coefficients align with our features: (9777, 12) feature: latitude ; coef: 7.312415440262378 feature: longitude ; coef: 4.059059803768657 feature: minimum_nights ; coef: 0.044388062697350704 feature: number_of_reviews ; coef: 0.0013794514234422481 feature: calculated_host_listings_count ; coef: -0.0034845157546768537 feature: availability_365 ; coef: -0.0021468646692259148 feature: borough_Brooklyn ; coef: 0.19507151988381405 feature: borough_Manhattan ; coef: -1.7898799616161736 feature: borough_Queens ; coef: 0.06310066394457561 feature: borough_Staten Island ; coef: 2.4381414950649947 feature: room_type_Private room ; coef: 3.4513468035217554 feature: room_type_Shared room ; coef: 4.686077440118879 Despite having 5 distinct price categories now, our performance isn't too bad! To increase performance further, we could first use cross-validation. Then, we could look at our original data and try to better use its features. For example, perhaps it would be useful to expand out our 'neighbourhood' feature into one-hot encodings? I imagine the fine-level, granular information of 'neighbourhood' correlates well with price. The only concern and question to ask ourselves is how much data do we have for each neighbourhood? (We'd aim to have plenty of representative data). Related, the longitude and latitude features provide fine-level information, but perhaps it's hard for the model to use it since the range is so small. If we were to scale the lat and long values to be between 0 and 1, it might allow for the model to better distinguish between the nuanced values. For this exercise, we uniformly care about each price level and prediction thereof. However, in some scenarios, our classification accuracy for some categories is much more important than others (e.g., predicting cancer or not). That is, our false negatives (misses) are way more serious and potentially deadly. For situations like this, it is better to error on the side of caution and allow for false positives (aka false alarms) moreso than false negatives (misses). To handle this, one could weight each class, and specify such during training/ fitting our model. As we learned in class, we can plot the performance as we vary the prediction threshold, while paying attention to how that affects the number of false negatives and false positives. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab06-solutions/"},{"title":"Advanced Section 3: Generalized Linear Models","text":"Notes Advanced Section: Generalized Linear Models: Notes [pdf] Slides Advanced Section: Generalized Linear Models [pdf] Advanced Section: Generalized Linear Models [pptx] Notebook Advanced Section: Generalized Linear Models: Demo Notebook [ipynb] Advanced Section: Generalized Linear Models: Demo Data [ipynb]","tags":"A-section","url":"a-section/a-section3/"},{"title":"Advanced Section 3: Generalized Linear Models","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } Fisher Scoring Demo for Advanced Section 3: GLM's Nick Stern | AC209a | October 9th, 2019 The following code implements the Fisher Scoring algorithm to solve for the optimal parameters in a simple logistic regression. The data we are using are the O-ring measurements that were taken leading up to the Challenger disaster in 1986. The space shuttle burned up on the launch pad because one of the O-rings failed due to the cold temperatures. We're going to regress temperature on O-ring failure to see if we can find a correlation. The data were obtained here . This example is originally found here . In [2]: ## Imports import numpy as np import pandas as pd import matplotlib.pyplot as plt import time from IPython import display import seaborn as sns sns . set ( style = 'white' ) In [3]: ## Implementation of Fisher Scoring algorithm for simple logistic regression df = pd . read_csv ( 'Challenger.csv' ) df [ 'INTERCEPT' ] = 1 df . head () Out[3]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } FLIGHT TEMPERATURE PRESSURE O_RING_FAILURE INTERCEPT 0 1 66 50 0 1 1 2 70 50 1 1 2 3 69 50 0 1 3 4 68 50 0 1 4 5 67 50 0 1 In [4]: ## Setup X and y X = df [[ 'INTERCEPT' , 'TEMPERATURE' ]] . values y = df [ 'O_RING_FAILURE' ] . values In [5]: def fisher_scoring ( design_matrix , response_vector , epsilon =. 001 ): \"\"\" Determine Logistic Regression coefficents using Fisher Scoring algorithm. Iteration ceases once changes between elements in coefficent matrix across consecutive iterations is less than epsilon. # ========================================================================= # design_matrix `X` => n-by-(p+1) | # response_vector `y` => n-by-1 | # probability_vector `p` => n-by-1 | # weights_matrix `W` => n-by-n | # epsilon => threshold above which iteration continues | # ========================================================================= # n => # of observations | # (p + 1) => # of parameterss, +1 for intercept term | # ========================================================================= # U => First derivative of Log-Likelihood with respect to | # each beta_i, i.e. `Score Function`: X_transpose * (y - p) | # | # I => Second derivative of Log-Likelihood with respect to | # each beta_i. The `Information Matrix`: (X_transpose * W * X) | # | # X&#94;T*W*X results in a (p+1)-by-(p+1) matrix | # X&#94;T(y - p) results in a (p+1)-by-1 matrix | # (X&#94;T*W*X)&#94;-1 * X&#94;T(y - p) results in a (p+1)-by-1 matrix | # ========================================================================| \"\"\" X = np . matrix ( design_matrix ) y = np . matrix ( response_vector ) . T # initialize logistic function used for Scoring calculations => def pi_i ( v ): return ( np . exp ( v ) / ( 1 + np . exp ( v ))) # initialize beta_0, p_0, W_0, I_0 & U_0 => beta_0 = np . matrix ( np . zeros ( X . shape [ 1 ])) . T p_0 = pi_i ( X @ beta_0 ) W_pre = ( np . array ( p_0 ) * np . array ( 1 - p_0 )) W_0 = np . matrix ( np . diag ( W_pre [:, 0 ])) I_0 = X . T @ W_0 @ X U_0 = X . T @ ( y - p_0 ) # initialize variables for iteration => beta_old = beta_0 iter_I = I_0 iter_U = U_0 iter_p = p_0 iter_W = W_0 fisher_scoring_iterations = 0 # iterate until abs(beta_new - beta_old) < epsilon => coeffs = [ np . array ( beta_old ) . flatten ()] while True : # Fisher Scoring Update Step => fisher_scoring_iterations += 1 beta_new = beta_old + iter_I . I * iter_U coeffs . append ( np . array ( beta_new ) . flatten ()) if np . all ( np . abs ( np . array ( beta_new ) - np . array ( beta_old )) < epsilon ): break else : iter_p = pi_i ( X * beta_new ) iter_W_pre = ( np . array ( iter_p ) * np . array ( 1 - iter_p )) iter_W = np . matrix ( np . diag ( iter_W_pre [:, 0 ])) iter_I = X . T * iter_W * X iter_U = X . T * ( y - iter_p ) beta_old = beta_new return coeffs In [6]: betas = fisher_scoring ( X , y ) In [7]: def log_likelihood ( X , y , betas ): ''' Calculates log-likelihood for logistic regression Input shapes: X - n x (p + 1) y - n x 1 betas - (p + 1) x 1 ''' return np . sum ( y * np . log ( np . exp ( X @ betas ) / ( 1 + np . exp ( X @ betas ))) + ( 1 - y ) * np . log ( 1 / ( 1 + np . exp ( X @ betas )))) In [8]: def animate (): ''' Animates parameter estimate convergence ''' b1s = [ x [ 1 ] for x in betas ] xs = np . linspace ( np . min ( b1s ) -. 2 , np . max ( b1s ), 100 ) ys = [ log_likelihood ( X , y , [ betas [ - 1 ][ 0 ], b ]) for b in xs ] fig , ax = plt . subplots ( figsize = ( 10 , 6 )) ax . plot ( xs , ys ) for i , b in enumerate ( b1s ): ax . scatter ( b , log_likelihood ( X , y , [ betas [ - 1 ][ 0 ], b ]), c = 'r' ) ax . plot ([ b ] * 100 , np . linspace ( np . min ( ys ), log_likelihood ( X , y , [ betas [ - 1 ][ 0 ], b ]), 100 ), 'r--' ) ax . set_ylabel ( 'Log-Likelihood' , fontsize = 15 ) ax . set_xlabel ( 'beta1' , fontsize = 15 ) ax . set_title ( f 'Fisher Scoring Algorithm: Iteration {i+1}' , fontsize = 20 ) display . clear_output ( wait = True ) display . display ( fig ) time . sleep ( . 4 ) display . clear_output ( wait = True ) In [10]: animate () if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"a-section","url":"a-section/a-section3/notebook/"},{"title":"Lecture 11: Logistic Regression 2","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109A Introduction to Data Science Lecture 11 (Logistic Regression #2) Harvard University Fall 2019 Instructors: Pavlos Protopapas, Kevin Rader, and Chris Tanner In [ ]: % matplotlib inline import sys import numpy as np import pylab as pl import pandas as pd import statsmodels.api as sm import matplotlib.pyplot as plt import matplotlib import sklearn as sk from sklearn.linear_model import LogisticRegression from sklearn.linear_model import LogisticRegressionCV import sklearn.metrics as met In [ ]: df_heart = pd . read_csv ( 'data/Heart.csv' ) df_heart [ 'AHD' ] = 1 * ( df_heart [ 'AHD' ] == \"Yes\" ) df_heart [ 'Interaction' ] = df_heart [ 'MaxHR' ] * df_heart [ 'Sex' ] df_heart . head () In [ ]: plt . plot ( df_heart . MaxHR , df_heart . AHD , 'o' , alpha = 0.4 ) plt . ylim ( - 0.1 , 1.1 ) plt . show () Regularization in Logistic Regression In [ ]: beta1_l1 = [] beta1_l2 = [] Cs = [] data_x = df_heart [[ 'MaxHR' , 'Sex' , 'Interaction' ]] data_y = df_heart [ 'AHD' ] for i in range ( 1 , 50 ): C = i / 10 logitm_l1 = LogisticRegression ( C = C , penalty = \"l1\" , solver = 'liblinear' , max_iter = 200 ) logitm_l1 . fit ( data_x , data_y ) logitm_l2 = LogisticRegression ( C = C , penalty = \"l2\" , solver = 'lbfgs' ) logitm_l2 . fit ( data_x , data_y ) beta1_l1 . append ( logitm_l1 . coef_ [ 0 ]) beta1_l2 . append ( logitm_l2 . coef_ [ 0 ]) Cs . append ( C ) plt . plot ( np . array ( Cs ), beta1_l1 , color = 'black' , lw = 3 ) plt . plot ( np . array ( Cs ), beta1_l2 , color = 'blue' , lw = 3 ) plt . xlabel ( \"lambda = C\" ) plt . ylabel ( \"beta1\" ) plt . show () Multi-Class Logistic Regression (Multinomial) In [ ]: # Response for Multinomial Logistic Regression Example print ( df_heart . RestECG . values ) plt . hist ( df_heart . RestECG . values ) plt . show () In [ ]: # 'Multinomial' Logistic Regression Example data_x = df_heart [[ 'Sex' ]] # 0 = normal; 1 = having ST-T; 2 = hypertrophy data_y = df_heart [ 'RestECG' ] logitm = LogisticRegression ( C = 10000000 , solver = 'lbfgs' , multi_class = 'ovr' ) logitm . fit ( data_x , data_y ) # The coefficients print ( 'Estimated beta1: \\n ' , logitm . coef_ ) print ( 'Estimated beta0: \\n ' , logitm . intercept_ ) In [ ]: logitm2 = LogisticRegression ( C = 10000000 , solver = 'lbfgs' , multi_class = 'multinomial' ) logitm2 . fit ( data_x , data_y ) # The coefficients print ( 'Estimated beta1: \\n ' , logitm2 . coef_ ) print ( 'Estimated beta0: \\n ' , logitm2 . intercept_ ) In [ ]: logitm3 = LogisticRegression ( C = 10000000 , solver = 'lbfgs' , multi_class = 'ovr' ) logitm3 . fit ( df_heart [[ 'Sex' , 'MaxHR' , 'Interaction' ]], df_heart [ 'RestECG' ]) # The coefficients print ( 'Estimated beta1: \\n ' , logitm3 . coef_ ) print ( 'Estimated beta0: \\n ' , logitm3 . intercept_ ) In [ ]: X = np . arange ( 0 , 2 ) print ( \"For OVR Logistic Regression:\" ) print ( logitm . predict_proba ( X . reshape ( - 1 , 1 ))) print ( logitm . predict ( X . reshape ( - 1 , 1 ))) print ( \"For Multinomial Logistic Regression:\" ) print ( logitm2 . predict_proba ( X . reshape ( - 1 , 1 ))) print ( logitm2 . predict ( X . reshape ( - 1 , 1 ))) Confusion Matrices and ROC Curves In [ ]: logitm . fit ( df_heart [[ 'Sex' , 'MaxHR' , 'Interaction' ]], df_heart [ 'AHD' ]); # The coefficients print ( 'Estimated beta1: \\n ' , logitm . coef_ ) print ( 'Estimated beta0: \\n ' , logitm . intercept_ ) In [ ]: #calculating confusion matrices yhat = logitm . predict_proba ( df_heart [[ 'Sex' , 'MaxHR' , 'Interaction' ]])[:, 1 ] print ( 'The average predicted probability is' , np . mean ( yhat )) print ( 'The confusion matrix when cut-off is 0.5: \\n ' , met . confusion_matrix ( df_heart [ 'AHD' ], yhat > 0.5 )) print ( 'The confusion matrix when cut-off is' , np . mean ( yhat ), ' \\n ' , met . confusion_matrix ( df_heart [ 'AHD' ], yhat > np . mean ( yhat ))) print ( 'The confusion matrix when cut-off is 0.75: \\n ' , met . confusion_matrix ( df_heart [ 'AHD' ], yhat > 0.72 )) In [ ]: #ROC curve on the train set fpr , tpr , thresholds = met . roc_curve ( df_heart [ 'AHD' ], yhat ) x = np . arange ( 0 , 100 ) / 100 plt . plot ( x , x , '--' , color = \"gray\" , alpha = 0.3 ) plt . plot ( fpr , tpr ) plt . ylabel ( \"True Positive Rate\" ) plt . xlabel ( \"False Positive Rate\" ) plt . title ( \"ROC Curve for Predicting AHD in a Logistic Regression Model\" ) plt . show () Regularization Example In [ ]: df_toy2 = pd . read_csv ( 'data/toy_example2.csv' ) df_toy2 . head () In [ ]: from sklearn.linear_model import LogisticRegression logreg = LogisticRegression ( C = 100000 , solver = 'lbfgs' ) logreg . fit ( df_toy2 [[ 'x1' , 'x2' ]], df_toy2 [ 'y' ]) beta = logreg . coef_ beta0 = logreg . intercept_ print ( 'Estimated beta1: \\n ' , beta ) print ( 'Estimated beta0: \\n ' , beta0 ) In [ ]: plt . scatter ( df_toy2 [ 'x1' ][ df_toy2 [ 'y' ] == 0 ], df_toy2 [ 'x2' ][ df_toy2 [ 'y' ] == 0 ]) plt . scatter ( df_toy2 [ 'x1' ][ df_toy2 [ 'y' ] == 1 ], df_toy2 [ 'x2' ][ df_toy2 [ 'y' ] == 1 ]) dummy_x1 = np . arange ( 0 , 1 , 0.01 ) dummy_x2 = ( beta [ 0 , 0 ] * dummy_x1 + beta0 ) /- beta [ 0 , 1 ] plt . plot ( dummy_x1 , dummy_x2 , '--' , c = \"black\" , lw = 5 ) plt . show () In [ ]: X = df_toy2 [[ 'x1' , 'x2' ]] logreg2 = LogisticRegression ( C = 100000 , solver = 'liblinear' ) poly = sk . preprocessing . PolynomialFeatures ( 10 ) X_poly = poly . fit_transform ( X ) logreg2 . fit ( X_poly , df_toy2 [ 'y' ]) logreg2 . coef_ In [ ]: dummy_x1 = np . arange ( 0 , 1.001 , 0.001 ) def find_boundary ( dummy_x , model , poly ): yhat = [] for x_i in dummy_x : dummy_x1 = np . repeat ( x_i , dummy_x . size ) df_X = pd . DataFrame ( np . array ([ dummy_x1 , dummy_x ]) . transpose ()) df_X2 = poly . fit_transform ( df_X ) yhat . append ( dummy_x [ np . sum ( model . predict ( df_X2 ))]) return yhat dummy_x2 = find_boundary ( dummy_x1 , logreg2 , poly ) In [ ]: plt . scatter ( df_toy2 [ 'x1' ][ df_toy2 [ 'y' ] == 0 ], df_toy2 [ 'x2' ][ df_toy2 [ 'y' ] == 0 ]) plt . scatter ( df_toy2 [ 'x1' ][ df_toy2 [ 'y' ] == 1 ], df_toy2 [ 'x2' ][ df_toy2 [ 'y' ] == 1 ]) plt . plot ( dummy_x1 , dummy_x2 , '--' , c = \"black\" , lw = 3 ) plt . show () In [ ]: Cs = 10.0 ** np . arange ( - 5 , 5 ) logregCV = LogisticRegressionCV ( Cs = Cs , cv = 5 , solver = 'liblinear' , penalty = 'l1' ) logregCV . fit ( X_poly , df_toy2 [ 'y' ]); In [ ]: print ( logregCV . coef_ ) #print(logregCV.scores_) #print(logregCV.coefs_paths_) In [ ]: dummy_x2 = ( beta [ 0 , 0 ] * dummy_x1 + beta0 ) /- beta [ 0 , 1 ] dummy_x2poly = find_boundary ( dummy_x1 , logreg2 , poly ) dummy_x2CV = find_boundary ( dummy_x1 , logregCV , poly ) In [ ]: plt . scatter ( df_toy2 [ 'x1' ][ df_toy2 [ 'y' ] == 0 ], df_toy2 [ 'x2' ][ df_toy2 [ 'y' ] == 0 ]) plt . scatter ( df_toy2 [ 'x1' ][ df_toy2 [ 'y' ] == 1 ], df_toy2 [ 'x2' ][ df_toy2 [ 'y' ] == 1 ]) plt . plot ( dummy_x1 , dummy_x2 , c = \"black\" , lw = 3 ) plt . plot ( dummy_x1 , dummy_x2poly , '--' , c = \"red\" , lw = 3 ) plt . plot ( dummy_x1 , dummy_x2CV , '-.' , c = \"purple\" , lw = 3 ) plt . legend ([ 'logit' , 'poly(10) logit' , 'regularized' , 'y=0' , 'y=1' ]) plt . rcParams [ \"figure.figsize\" ] = [ 10 , 6 ] plt . show () if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"notebooks","url":"notebooks/lecture-11/notebook/"},{"title":"Lecture 11: Logistic Regression 2","text":"Slides Logistic Regression 2 PDF Logistic Regression 2 PPTX Logistic Regression 2 Notebook Data Directory","tags":"lectures","url":"lectures/lecture11/"},{"title":"Lecture 10: Logistic Regression","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109A Introduction to Data Science Lecture 10 (Logistic Regression) Harvard University Fall 2019 Instructors: Pavlos Protopapas, Kevin Rader, and Chris Tanner In [ ]: #from sklearn import datasets import pandas as pd % pylab inline import matplotlib.pylab as plt import numpy as np import sklearn as sk from sklearn.neighbors import NearestNeighbors from sklearn import neighbors from sklearn import linear_model In [ ]: df_heart = pd . read_csv ( 'data/Heart.csv' ) In [ ]: df_heart . head () In [ ]: df_heart [ 'AHD' ] = 1 * ( df_heart [ 'AHD' ] == \"Yes\" ) df_heart . AHD . head ( 10 ) In [ ]: plt . plot ( df_heart . MaxHR , df_heart . AHD , 'o' , alpha = 0.4 ) plt . ylim ( - 0.1 , 1.1 ) plt . show () #uh-oh, that's not good :( In [ ]: fig = plt . figure () fig . patch . set_alpha ( 0.0 ) plt . xkcd ( scale = 0.1 , length = 0.0 ) plt . gcf () . subplots_adjust ( bottom = 0.20 , left = 0.16 , right = 0.86 ) host = fig . add_subplot ( 111 ) par1 = host . twinx () host . set_xlabel ( \"MaxHR\" ) host . set_ylabel ( \"Probability\" ) par1 . set_ylabel ( \"AHD\" ) color1 = plt . cm . viridis ( 0 ) data_x = df_heart [ 'MaxHR' ] data_y = df_heart [ 'AHD' ] regr = sk . linear_model . LinearRegression ( fit_intercept = True ) regr . fit ( data_x . values . reshape ( - 1 , 1 ), data_y ) # Make predictions using the testing set x = np . linspace ( np . min ( data_x ) - 10 , np . max ( data_x ) + 10 ) y_ = regr . predict ( x . reshape ( - 1 , 1 )) host . plot ( data_x , data_y , 'o' , alpha = 0.4 , label = 'Data' ) host . plot ( x , y_ , label = 'LinReg' ) host . legend ( loc = 3 ) labels = [ 'No' , 'Yes' ] # You can specify a rotation for the tick labels in degrees or with keywords. par1 . set_yticks ( [ 0.061 , 0.83 ]) par1 . set_yticklabels ( labels ) plt . show () #plt.savefig('fig/FittingLR.png', dpi=300, transparent=True) Plot for linear regression -> Log Regression In [ ]: fig , ax1 = plt . subplots () fig . patch . set_alpha ( 0.0 ) plt . xkcd ( scale = 0.1 , length = 0.0 ) plt . gcf () . subplots_adjust ( bottom = 0.20 , left = 0.16 , right = 0.86 ) x = np . linspace ( - 100 , 100 , 100 ) y = x yl = 1 / ( 1 + np . exp ( - y )) ax1 . plot ( x , y , label = 'Y=X' ) ax1 . set_xlabel ( 'X' ) ax1 . set_ylabel ( 'Y' ) ax1 . legend () #plt.savefig('fig/LinR.png', dpi=300, transparent=True) In [ ]: fig = plt . figure () fig . patch . set_alpha ( 0.0 ) plt . xkcd ( scale = 0.1 , length = 0.0 ) plt . gcf () . subplots_adjust ( bottom = 0.20 , left = 0.16 , right = 0.86 ) plt . plot ( x , yl , label = 'Y=f(x)' ) plt . xlabel ( 'X' ) plt . ylabel ( 'Y' ) plt . legend () plt . grid () #plt.savefig('fig/LogR.png', dpi=300, transparent=True) In [ ]: from matplotlib.animation import FuncAnimation fig , ax = plt . subplots () fig . patch . set_alpha ( 1.0 ) plt . xkcd ( scale = 0.1 , length = 0.0 ) plt . gcf () . subplots_adjust ( bottom = 0.20 , left = 0.16 , right = 0.86 ) line , = ax . plot ( x , yl , label = r '$Y=\\frac {1} {1+e&#94;{-(X+\\beta_0) }}$' ) plt . xlabel ( 'X' ) plt . ylabel ( 'Y' ) #plt.legend(loc=5) def update ( i ): b0 = 2 * i label = r '$\\beta_0=$ {0} ' . format ( b0 ) print ( label ) # Update the line and the axes (with a new xlabel). Return a tuple of # \"artists\" that have to be redrawn for this frame. line . set_ydata ( 1 / ( 1 + np . exp ( - x + b0 ))) ax . set_title ( label ) return line , ax # FuncAnimation will call the 'update' function for each frame; here # animating over 10 frames, with an interval of 200ms between frames. anim = FuncAnimation ( fig , update , frames = np . arange ( - 20 , 20 , 2 ), interval = 300 , blit = False ) #anim.save('fig/LogBeta0.gif', dpi=120, writer='imagemagick', savefig_kwargs={'transparent': True, 'facecolor': '#F9F9F9'}) #plt.savefig('fig/LogRBeta.png', dpi=300, transparent=True) In [ ]: from matplotlib.animation import FuncAnimation fig , ax = plt . subplots () fig . patch . set_alpha ( 1.0 ) plt . xkcd ( scale = 0.1 , length = 0.0 ) plt . gcf () . subplots_adjust ( bottom = 0.20 , left = 0.16 , right = 0.86 ) line , = ax . plot ( x , yl , label = r '$Y=\\frac {1} {1+e&#94;{-(X+\\beta_0) }}$' ) plt . xlabel ( 'X' ) plt . ylabel ( 'Y' ) #plt.legend(loc=5) def update ( i ): b1 = 2 * i label = r '$\\beta_1=$ {0} ' . format ( np . round ( b1 , decimals = 2 )) print ( label ) # Update the line and the axes (with a new xlabel). Return a tuple of # \"artists\" that have to be redrawn for this frame. line . set_ydata ( 1 / ( 1 + np . exp ( - b1 * x ))) ax . set_title ( label ) return line , ax # FuncAnimation will call the 'update' function for each frame; here # animating over 10 frames, with an interval of 200ms between frames. anim = FuncAnimation ( fig , update , frames = np . arange ( . 2 , -. 2 , -. 03 ), interval = 200 , blit = False ) anim . save ( 'fig/LogBeta1.gif' , dpi = 120 , writer = 'imagemagick' , savefig_kwargs = { 'transparent' : True , 'facecolor' : '#F9F9F9' }) #plt.savefig('fig/LogRBeta.png', dpi=300, transparent=True) Likelihood function In [ ]: fig = plt . figure () fig . patch . set_alpha ( 0.0 ) plt . xkcd ( scale = 0.1 , length = 0.0 ) plt . gcf () . subplots_adjust ( bottom = 0.20 , left = 0.16 , right = 0.86 ) x = np . linspace ( - 10 , 10 , 100 ) y = x yl = 1 / ( 1 + np . exp ( - 0.5 * y )) #plt.plot(x,yl, label=r'$P(Y=1)=\\frac{1}{1+e&#94;{-X\\beta}}$') plt . plot ( x , yl ) plt . xlabel ( 'X' ) plt . ylabel ( 'P(Y=1)' ) plt . legend () plt . ylim (( - 0.2 , 1.1 )) #plt.savefig('fig/Likelihood1.png', dpi=300, transparent=True) ### FRAME 2 plt . axvline ( x = 3 , color = '#A2A2A2' , ls = '-.' ) #plt.savefig('fig/Likelihood2.png', dpi=300, transparent=True) ### FRAME 3 plt . annotate ( r ' $P(y=1|x=3)$' , xy = ( 3 , . 83 ), \\ xytext = ( - 8 , . 81 ), arrowprops = dict ( facecolor = 'black' , shrink = 0.05 ), ) plt . savefig ( 'fig/Likelihood3.png' , dpi = 300 , transparent = True ) ### FRAME 4 plt . annotate ( r ' $p=P(y=1|x=3)$' , xy = ( 3 , . 83 ), \\ xytext = ( - 10 , . 81 ), arrowprops = dict ( facecolor = 'black' , shrink = 0.05 ), ) plt . savefig ( 'fig/Likelihood4.png' , dpi = 300 , transparent = True ) ### FRAME 5 plt . clf () plt . ylim (( - 0.2 , 1.1 )) plt . plot ( x , yl ) plt . xlabel ( 'X' ) plt . ylabel ( 'P(Y=1)' ) plt . axvline ( x = 3 , color = '#A2A2A2' , ls = '-.' ) coinf = np . random . binomial ( 1 , 0.7 , size = 1 ) plt . plot ( [ 3 ], [ 0 ], 'ko' ) plt . plot ( [ 3 ], [ 1 ], 'ko' ) plt . annotate ( r ' $p$' , xy = ( 2.7 , 1 ), \\ xytext = ( - 3 , 0.98 ), arrowprops = dict ( facecolor = 'white' , shrink = 0.0 ), ) plt . annotate ( r ' $1-p$' , xy = ( 2.8 , . 00 ), \\ xytext = ( - 4 , -. 02 ), arrowprops = dict ( facecolor = 'white' , shrink = 0.05 ), ) plt . savefig ( 'fig/Likelihood5.png' , dpi = 300 , transparent = True ) plt . show () Plots for simple model In [ ]: from sklearn import linear_model fig = plt . figure () fig . patch . set_alpha ( 0.0 ) plt . xkcd ( scale = 0.1 , length = 0.0 ) plt . gcf () . subplots_adjust ( bottom = 0.20 , left = 0.16 , right = 0.86 ) plt . ylim (( - 0.1 , 1.1 )) plt . xlabel ( \"MaxHR\" ) plt . ylabel ( \"Heart disease (AHD)\" ) data_x = df_heart [ 'MaxHR' ] data_y = df_heart [ 'AHD' ] plt . plot ( data_x , data_y , 'o' , alpha = 0.4 , label = 'Data' ) plt . show () #plt.legend(loc=3) #plt.savefig('fig/FittingLogR1.png', dpi=300, transparent=True) In [ ]: from sklearn.linear_model import LogisticRegression logreg = LogisticRegression ( C = 100000 , fit_intercept = True , solver = 'lbfgs' ) logreg . fit ( data_x . values . reshape ( - 1 , 1 ), data_y ); print ( 'Estimated beta1: \\n ' , logreg . coef_ ) print ( 'Estimated beta0: \\n ' , logreg . intercept_ ) In [ ]: fig = plt . figure () fig . patch . set_alpha ( 0.0 ) plt . xkcd ( scale = 0.1 , length = 0.0 ) plt . gcf () . subplots_adjust ( bottom = 0.20 , left = 0.16 , right = 0.86 ) x = np . linspace ( np . min ( data_x ), np . max ( data_x )) yhat = logreg . predict_proba ( x . reshape ( - 1 , 1 ))[:, 1 ] plt . plot ( data_x , data_y , 'o' , alpha = 0.4 , label = 'Data' ) plt . plot ( x , yhat , label = 'Model' ) plt . legend () plt . xlabel ( \"MaxHR\" ) plt . ylabel ( \"Heart disease (AHD)\" ) plt . savefig ( 'fig/FittingLogR2.png' , dpi = 300 , transparent = True ) Categorical predictors In [ ]: data_x = df_heart [ 'Sex' ] data_y = df_heart [ 'AHD' ] idx0 = np . where ( data_x . values == 0 ) idx1 = np . where ( data_x . values == 1 ) print ( \"percentage of females with HD\" , data_y . values [ idx0 ] . sum () / idx0 [ 0 ] . shape ) print ( \"percentage of males with HD\" , data_y . values [ idx1 ] . sum () / idx1 [ 0 ] . shape ) pd . crosstab ( df_heart [ 'Sex' ], df_heart [ 'AHD' ]) In [ ]: fig = plt . figure () fig . patch . set_alpha ( 0.0 ) plt . xkcd ( scale = 0.1 , length = 0.0 ) plt . gcf () . subplots_adjust ( bottom = 0.20 , left = 0.16 , right = 0.86 ) plt . ylim (( - 0.1 , 1.1 )) plt . xlabel ( \"Sex\" ) plt . ylabel ( \"Heart disease (AHD)\" ) data_x = df_heart [ 'Sex' ] data_y = df_heart [ 'AHD' ] logreg . fit ( data_x . values . reshape ( - 1 , 1 ), data_y ); x = np . linspace ( np . min ( data_x ), np . max ( data_x )) yhat = logreg . predict_proba ( x . reshape ( - 1 , 1 ))[:, 1 ] plt . plot ( data_x , data_y , 'o' , alpha = 0.4 , label = 'Data' ) plt . plot ( x , yhat , label = 'Model' ) plt . show () In [ ]: print ( 'Estimated beta1: \\n ' , logreg . coef_ ) print ( 'Estimated beta0: \\n ' , logreg . intercept_ ) Probit In [ ]: from scipy.stats import logistic from scipy.stats import norm fig = plt . figure () fig . patch . set_alpha ( 0.0 ) plt . xkcd ( scale = 0.1 , length = 0.0 ) plt . gcf () . subplots_adjust ( bottom = 0.20 , left = 0.16 , right = 0.86 ) x = np . linspace ( logistic . ppf ( 0.01 ), logistic . ppf ( 0.99 ), 100 ) plt . plot ( x , logistic . pdf ( x , loc = 0 , scale = 1 ), 'r-' , lw = 5 , alpha = 0.6 , label = 'logistic pdf' ) plt . plot ( x , norm . pdf ( x , loc = 0 , scale = 1 ), 'b-' , lw = 5 , alpha = 0.6 , label = 'normal pdf' ) plt . xlabel ( 'X' ) plt . ylabel ( 'Probability' ) plt . legend () plt . savefig ( 'fig/NormVsLog.png' , dpi = 300 , transparent = True ) Multiple Logistic Regression In [ ]: data_x = df_heart [[ 'MaxHR' , 'Sex' ]] data_y = df_heart [ 'AHD' ] logreg . fit ( data_x , data_y ); print ( 'Estimated beta1, beta2: \\n ' , logreg . coef_ ) print ( 'Estimated beta0: \\n ' , logreg . intercept_ ) In [ ]: df_heart [ 'Interaction' ] = df_heart . MaxHR * df_heart . Sex data_x = df_heart [[ 'MaxHR' , 'Sex' , 'Interaction' ]] data_y = df_heart [ 'AHD' ] logreg = LogisticRegression ( C = 100000 , fit_intercept = True , solver = 'lbfgs' ) logreg . fit ( data_x , data_y ); print ( 'Estimated beta1, beta2, beta3: \\n ' , logreg . coef_ ) print ( 'Estimated beta0: \\n ' , logreg . intercept_ ) Multi-Class (Multinomial) In [ ]: # Response for Multinomial Logistic Regression Example print ( df_heart . RestECG . values ) plt . hist ( df_heart . RestECG . values ) plt . show () In [ ]: # Multinomial Logistic Regression Example data_x = df_heart [[ 'Sex' ]] data_y = df_heart [ 'RestECG' ] logitm = LogisticRegression ( C = 10000000 , solver = 'lbfgs' ) logitm . fit ( data_x , data_y ) # The coefficients print ( 'Estimated beta1: \\n ' , logitm . coef_ ) print ( 'Estimated beta0: \\n ' , logitm . intercept_ ) In [ ]: logitm = LogisticRegression ( C = 10000000 , solver = 'lbfgs' , multi_class = 'ovr' ) logitm . fit ( data_x , data_y ) # The coefficients print ( 'Estimated beta1: \\n ' , logitm . coef_ ) print ( 'Estimated beta0: \\n ' , logitm . intercept_ ) In [ ]: logitm = LogisticRegression ( C = 10000000 , solver = 'lbfgs' , multi_class = 'multinomial' ) logitm . fit ( data_x , data_y ) # The coefficients print ( 'Estimated beta1: \\n ' , logitm . coef_ ) print ( 'Estimated beta0: \\n ' , logitm . intercept_ ) In [ ]: logitm = LogisticRegression ( C = 10000000 , solver = 'lbfgs' ) logitm . fit ( df_heart [[ 'Sex' , 'MaxHR' , 'Interaction' ]], df_heart [ 'RestECG' ]) # The coefficients print ( 'Estimated beta1: \\n ' , logitm . coef_ ) print ( 'Estimated beta0: \\n ' , logitm . intercept_ ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"notebooks","url":"notebooks/lecture-10/notebook/"},{"title":"Lecture 10: Logistic Regression","text":"Slides Logistic Regression PDF Logistic Regression PPTX Logistic Regression Notebook Data Directory","tags":"lectures","url":"lectures/lecture10/"},{"title":"S-Section 04: Regularization and Model Selection","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109A Introduction to Data Science Standard Section 4: Regularization and Model Selection Harvard University Fall 2019 Instructors : Pavlos Protopapas, Kevin Rader, and Chris Tanner Section Leaders : Marios Mattheakis, Abhimanyu (Abhi) Vasishth, Robbert (Rob) Struyven In [1]: #RUN THIS CELL import requests from IPython.core.display import HTML styles = requests . get ( \"http://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } span.sub-q { font-weight: bold; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } For this section, our goal is to get you familiarized with Regularization in Multiple Linear Regression and to start thinking about Model and Hyper-Parameter Selection. Specifically, we will: Load in the King County House Price Dataset Perform some basic EDA Split the data up into a training, validation , and test set (we'll see why we need a validation set) Scale the variables (by standardizing them) and seeing why we need to do this Make our multiple & polynomial regression models (like we did in the previous section) Learn what regularization is and how it can help Understand ridge and lasso regression Get an introduction to cross-validation using RidgeCV and LassoCV In [2]: # Data and Stats packages import numpy as np import pandas as pd pd . set_option ( 'max_columns' , 200 ) # Visualization packages import matplotlib.pyplot as plt import seaborn as sns sns . set () import warnings warnings . filterwarnings ( \"ignore\" ) EDA: House Prices Data From Kaggle For our dataset, we'll be using the house price dataset from King County, WA . The dataset is from Kaggle . The task is to build a regression model to predict the price , based on different attributes. First, let's do some EDA. In [3]: # Load the dataset house_df = pd . read_csv ( '../data/kc_house_data.csv' ) house_df = house_df . sample ( frac = 1 , random_state = 42 )[ 0 : 4000 ] print ( house_df . shape ) print ( house_df . dtypes ) house_df . head () (4000, 21) id int64 date object price float64 bedrooms int64 bathrooms float64 sqft_living int64 sqft_lot int64 floors float64 waterfront int64 view int64 condition int64 grade int64 sqft_above int64 sqft_basement int64 yr_built int64 yr_renovated int64 zipcode int64 lat float64 long float64 sqft_living15 int64 sqft_lot15 int64 dtype: object Out[3]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id date price bedrooms bathrooms sqft_living sqft_lot floors waterfront view condition grade sqft_above sqft_basement yr_built yr_renovated zipcode lat long sqft_living15 sqft_lot15 735 2591820310 20141006T000000 365000.0 4 2.25 2070 8893 2.0 0 0 4 8 2070 0 1986 0 98058 47.4388 -122.162 2390 7700 2830 7974200820 20140821T000000 865000.0 5 3.00 2900 6730 1.0 0 0 5 8 1830 1070 1977 0 98115 47.6784 -122.285 2370 6283 4106 7701450110 20140815T000000 1038000.0 4 2.50 3770 10893 2.0 0 2 3 11 3770 0 1997 0 98006 47.5646 -122.129 3710 9685 16218 9522300010 20150331T000000 1490000.0 3 3.50 4560 14608 2.0 0 2 3 12 4560 0 1990 0 98034 47.6995 -122.228 4050 14226 19964 9510861140 20140714T000000 711000.0 3 2.50 2550 5376 2.0 0 0 3 9 2550 0 2004 0 98052 47.6647 -122.083 2250 4050 Now let's check for null values and look at the datatypes within the dataset. In [4]: house_df . info () Int64Index: 4000 entries, 735 to 3455 Data columns (total 21 columns): id 4000 non-null int64 date 4000 non-null object price 4000 non-null float64 bedrooms 4000 non-null int64 bathrooms 4000 non-null float64 sqft_living 4000 non-null int64 sqft_lot 4000 non-null int64 floors 4000 non-null float64 waterfront 4000 non-null int64 view 4000 non-null int64 condition 4000 non-null int64 grade 4000 non-null int64 sqft_above 4000 non-null int64 sqft_basement 4000 non-null int64 yr_built 4000 non-null int64 yr_renovated 4000 non-null int64 zipcode 4000 non-null int64 lat 4000 non-null float64 long 4000 non-null float64 sqft_living15 4000 non-null int64 sqft_lot15 4000 non-null int64 dtypes: float64(5), int64(15), object(1) memory usage: 687.5+ KB In [5]: house_df . describe () Out[5]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id price bedrooms bathrooms sqft_living sqft_lot floors waterfront view condition grade sqft_above sqft_basement yr_built yr_renovated zipcode lat long sqft_living15 sqft_lot15 count 4.000000e+03 4.000000e+03 4000.000000 4000.000000 4000.000000 4.000000e+03 4000.000000 4000.000000 4000.000000 4000.000000 4000.000000 4000.000000 4000.00000 4000.000000 4000.000000 4000.000000 4000.000000 4000.000000 4000.00000 4000.00000 mean 4.586542e+09 5.497522e+05 3.379250 2.116563 2096.645250 1.616511e+04 1.475000 0.007750 0.232500 3.420750 7.668250 1792.465000 304.18025 1970.564250 89.801500 98078.035500 47.560091 -122.214060 1997.75900 12790.67800 std 2.876700e+09 3.890505e+05 0.922568 0.783175 957.785141 5.120888e+04 0.530279 0.087703 0.768174 0.646393 1.194173 849.986192 455.26354 29.141872 413.760082 54.073374 0.139070 0.141879 701.60987 26085.20301 min 1.000102e+06 8.250000e+04 0.000000 0.000000 384.000000 5.720000e+02 1.000000 0.000000 0.000000 1.000000 4.000000 384.000000 0.00000 1900.000000 0.000000 98001.000000 47.155900 -122.515000 620.00000 659.00000 25% 2.126074e+09 3.249500e+05 3.000000 1.750000 1420.000000 5.200000e+03 1.000000 0.000000 0.000000 3.000000 7.000000 1180.000000 0.00000 1951.000000 0.000000 98033.000000 47.468175 -122.328000 1490.00000 5200.00000 50% 3.889350e+09 4.550000e+05 3.000000 2.250000 1920.000000 7.675000e+03 1.000000 0.000000 0.000000 3.000000 7.000000 1550.000000 0.00000 1974.500000 0.000000 98065.000000 47.573800 -122.231000 1840.00000 7628.00000 75% 7.334526e+09 6.541250e+05 4.000000 2.500000 2570.000000 1.087125e+04 2.000000 0.000000 0.000000 4.000000 8.000000 2250.000000 590.00000 1995.000000 0.000000 98118.000000 47.679100 -122.127000 2370.00000 10240.00000 max 9.842300e+09 5.570000e+06 11.000000 8.000000 13540.000000 1.651359e+06 3.500000 1.000000 4.000000 5.000000 13.000000 9410.000000 4130.00000 2015.000000 2015.000000 98199.000000 47.777500 -121.315000 5790.00000 560617.00000 Let's choose a subset of columns here. NOTE : The way I'm selecting columns here is not principled and is just for convenience. In your homework assignments (and in real life), we expect you to choose columns more rigorously. bedrooms bathrooms sqft_living sqft_lot floors sqft_above sqft_basement lat long price : Our response variable In [6]: cols_of_interest = [ 'bedrooms' , 'bathrooms' , 'sqft_living' , 'sqft_lot' , 'floors' , 'sqft_above' , 'sqft_basement' , 'lat' , 'long' , 'price' ] house_df = house_df [ cols_of_interest ] # Convert house price to 1000s of dollars house_df [ 'price' ] = house_df [ 'price' ] / 1000 Let's see how the response variable ( price ) is distributed In [7]: fig , ax = plt . subplots ( figsize = ( 12 , 5 )) ax . hist ( house_df [ 'price' ], bins = 100 ) ax . set_title ( 'Histogram of house price (in 1000s of dollars)' ); In [8]: # This takes a bit of time but is worth it!! # sns.pairplot(house_df); Train-Validation-Test Split Up until this point, we have only had a train-test split. Why are we introducing a validation set? What's the point? This is the general idea: Training Set : Data you have seen. You train different types of models with various different hyper-parameters and regularization parameters on this data. Validation Set : Used to compare different models. We use this step to tune our hyper-parameters i.e. find the optimal set of hyper-parameters (such as $k$ for k-NN or our $\\beta_i$ values or number of degrees of our polynomial for linear regression). Pick your best model here. Test Set : Using the best model from the previous step, simply report the score e.g. R&#94;2 score, MSE or any metric that you care about, of that model on your test set. DON'T TUNE YOUR PARAMETERS HERE! . Why, I hear you ask? Because we want to know how our model might do on data it hasn't seen before. We don't have access to this data (because it may not exist yet) but the test set, which we haven't seen or touched so far, is a good way to mimic this new data. Let's do 60% train, 20% validation, 20% test for this dataset. In [9]: from sklearn.model_selection import train_test_split # first split the data into a train-test split and don't touch the test set yet train_df , test_df = train_test_split ( house_df , test_size = 0.2 , random_state = 42 ) # next, split the training set into a train-validation split # the test-size is 0.25 since we are splitting 80% of the data into 20% and 60% overall train_df , val_df = train_test_split ( train_df , test_size = 0.25 , random_state = 42 ) print ( 'Train Set: {0:0.2f} %' . format ( 100 * train_df . size / house_df . size )) print ( 'Validation Set: {0:0.2f} %' . format ( 100 * val_df . size / house_df . size )) print ( 'Test Set: {0:0.2f} %' . format ( 100 * test_df . size / house_df . size )) Train Set: 60.00% Validation Set: 20.00% Test Set: 20.00% Modeling In the last section , we went over the mechanics of Multiple Linear Regression and created models that had interaction terms and polynomial terms. Specifically, we dealt with the following sorts of models. $$ y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_M x_M $$ Let's adopt a similar process here and get a few different models. Creating a Design Matrix From our model setup in the equation in the previous section, we obtain the following: $$ Y = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}, \\quad X = \\begin{bmatrix} x_{1,1} & x_{1,2} & \\dots & x_{1,M} \\\\ x_{2,1} & x_{2,2} & \\dots & x_{2,M} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ x_{n,1} & x_{n,2} & \\dots & x_{n,M} \\\\ \\end{bmatrix}, \\quad \\beta = \\begin{bmatrix} \\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_M \\end{bmatrix}, \\quad \\epsilon = \\begin{bmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{bmatrix}, $$ $X$ is an n$\\times$M matrix: this is our design matrix , $\\beta$ is an M-dimensional vector (an M$\\times$1 matrix), and $Y$ is an n-dimensional vector (an n$\\times$1 matrix). In addition, we know that $\\epsilon$ is an n-dimensional vector (an n$\\times$1 matrix). In [10]: X = train_df [ cols_of_interest ] y = train_df [ 'price' ] print ( X . shape ) print ( y . shape ) (2400, 10) (2400,) Scaling our Design Matrix Warm-Up Exercise Warm-Up Exercise: for which of the following do the units of the predictors matter (e.g., trip length in minutes vs seconds; temperature in F or C)? A similar question would be: for which of these models do the magnitudes of values taken by different predictors matter? (We will go over Ridge and Lasso Regression in greater detail later) k-NN (Nearest Neighbors regression) Linear regression Lasso regression Ridge regression Solutions kNN: yes . Scaling affects distance metric, which determines what \"neighbor\" means Linear regression: no . Multiply predictor by $c$ -> divide coef by $c$. Lasso: yes : If we divided coef by $c$, then corresponding penalty term is also divided by $c$. Ridge: yes : Same as Lasso, except penalty divided by $c&#94;2$. Standard Scaler (Standardization) Here's the scikit-learn implementation of the standard scaler. What is it doing though? Hint: you may have seen this in STAT 110 or another statistics course multiple times. $$ z = \\frac{x-\\mu}{\\sigma} $$ In the above setup: $z$ is the standardized variable $x$ is the variable before standardization $\\mu$ is the mean of the variable before standardization $\\sigma$ is the standard deviation of the variable before standardization Let's see an example of how this works: In [11]: from sklearn.preprocessing import StandardScaler x = house_df [ 'sqft_living' ] mu = x . mean () sigma = x . std () z = ( x - mu ) / sigma # reshaping x to be a n by 1 matrix since that's how scikit learn likes data for standardization x_reshaped = np . array ( x ) . reshape ( - 1 , 1 ) z_sklearn = StandardScaler () . fit_transform ( x_reshaped ) # Plotting the histogram of the variable before standardization fig , ax = plt . subplots ( nrows = 1 , ncols = 3 , figsize = ( 24 , 5 )) ax = ax . ravel () ax [ 0 ] . hist ( x , bins = 100 ) ax [ 0 ] . set_title ( 'Histogram of sqft_living before standardization' ) ax [ 1 ] . hist ( z , bins = 100 ) ax [ 1 ] . set_title ( 'Manually standardizing sqft_living' ) ax [ 2 ] . hist ( z_sklearn , bins = 100 ) ax [ 2 ] . set_title ( 'Standardizing sqft_living using scikit learn' ); # making things a dataframe to check if they work pd . DataFrame ({ 'x' : x , 'z_manual' : z , 'z_sklearn' : z_sklearn . flatten ()}) . describe () Out[11]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x z_manual z_sklearn count 4000.000000 4.000000e+03 4.000000e+03 mean 2096.645250 -2.775558e-17 -4.096723e-17 std 957.785141 1.000000e+00 1.000125e+00 min 384.000000 -1.788131e+00 -1.788355e+00 25% 1420.000000 -7.064687e-01 -7.065571e-01 50% 1920.000000 -1.844310e-01 -1.844540e-01 75% 2570.000000 4.942181e-01 4.942799e-01 max 13540.000000 1.194773e+01 1.194922e+01 Min-Max Scaler (Normalization) Here's the scikit-learn implementation of the standard scaler. What is it doing though? $$ x_{new} = \\frac{x-x_{min}}{x_{max}-x_{min}} $$ In the above setup: $x_{new}$ is the normalized variable $x$ is the variable before normalized $x_{max}$ is the max value of the variable before normalization $x_{min}$ is the min value of the variable before normalization Let's see an example of how this works: In [12]: from sklearn.preprocessing import MinMaxScaler x = house_df [ 'sqft_living' ] x_new = ( x - x . min ()) / ( x . max () - x . min ()) # reshaping x to be a n by 1 matrix since that's how scikit learn likes data for normalization x_reshaped = np . array ( x ) . reshape ( - 1 , 1 ) x_new_sklearn = MinMaxScaler () . fit_transform ( x_reshaped ) # Plotting the histogram of the variable before normalization fig , ax = plt . subplots ( nrows = 1 , ncols = 3 , figsize = ( 24 , 5 )) ax = ax . ravel () ax [ 0 ] . hist ( x , bins = 100 ) ax [ 0 ] . set_title ( 'Histogram of sqft_living before normalization' ) ax [ 1 ] . hist ( x_new , bins = 100 ) ax [ 1 ] . set_title ( 'Manually normalizing sqft_living' ) ax [ 2 ] . hist ( x_new_sklearn , bins = 100 ) ax [ 2 ] . set_title ( 'Normalizing sqft_living using scikit learn' ); # making things a dataframe to check if they work pd . DataFrame ({ 'x' : x , 'x_new_manual' : x_new , 'x_new_sklearn' : x_new_sklearn . flatten ()}) . describe () Out[12]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x x_new_manual x_new_sklearn count 4000.000000 4000.000000 4000.000000 mean 2096.645250 0.130180 0.130180 std 957.785141 0.072802 0.072802 min 384.000000 0.000000 0.000000 25% 1420.000000 0.078747 0.078747 50% 1920.000000 0.116753 0.116753 75% 2570.000000 0.166160 0.166160 max 13540.000000 1.000000 1.000000 The million dollar question Should I standardize or normalize my data? This , this and this are useful resources that I highly recommend. But in a nutshell, what they say is the following: Pros of Normalization Normalization (which makes your data go from 0-1) is widely used in image processing and computer vision, where pixel intensities are non-negative and are typically scaled from a 0-255 scale to a 0-1 range for a lot of different algorithms. Normalization is also very useful in neural networks (which we will see later in the course) as it leads to the algorithms converging faster. Normalization is useful when your data does not have a discernible distribution and you are not making assumptions about your data's distribution. Pros of Standardization Standardization maintains outliers (do you see why?) whereas normalization makes outliers less obvious. In applications where outliers are useful, standardization should be done. Standardization is useful when you assume your data comes from a Gaussian distribution (or something that is approximately Gaussian). Some General Advice We learn parameters for standardization ($\\mu$ and $\\sigma$) and for normalization ($x_{min}$ and $x_{max}$). Make sure these parameters are learned on the training set i.e use the training set parameters even when normalizing/standardizing the test set. In sklearn terms, fit your scaler on the training set and use the scaler to transform your test set and validation set ( don't re-fit your scaler on test set data! ). The point of standardization and normalization is to make your variables take on a more manageable scale. You should ideally standardize or normalize all your variables at the same time. Standardization and normalization is not always needed and is not an automatic thing you have to do on any data science homework!! Do so sparingly and try to justify why this is needed. Interpreting Coefficients A great quote from here [Standardization] makes it so the intercept term is interpreted as the expected value of 𝑌𝑖 when the predictor values are set to their means. Otherwise, the intercept is interpreted as the expected value of 𝑌𝑖 when the predictors are set to 0, which may not be a realistic or interpretable situation (e.g. what if the predictors were height and weight?) Standardizing our Design Matrix In [13]: features = [ 'bedrooms' , 'bathrooms' , 'sqft_living' , 'sqft_lot' , 'floors' , 'sqft_above' , 'sqft_basement' , 'lat' , 'long' ] X_train = train_df [ features ] y_train = np . array ( train_df [ 'price' ]) . reshape ( - 1 , 1 ) X_val = val_df [ features ] y_val = np . array ( val_df [ 'price' ]) . reshape ( - 1 , 1 ) X_test = test_df [ features ] y_test = np . array ( test_df [ 'price' ]) . reshape ( - 1 , 1 ) scaler = StandardScaler () . fit ( X_train ) # This converts our matrices into numpy matrices X_train_t = scaler . transform ( X_train ) X_val_t = scaler . transform ( X_val ) X_test_t = scaler . transform ( X_test ) # Making the numpy matrices pandas dataframes X_train_df = pd . DataFrame ( X_train_t , columns = features ) X_val_df = pd . DataFrame ( X_val_t , columns = features ) X_test_df = pd . DataFrame ( X_test_t , columns = features ) display ( X_train_df . describe ()) display ( X_val_df . describe ()) display ( X_test_df . describe ()) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } bedrooms bathrooms sqft_living sqft_lot floors sqft_above sqft_basement lat long count 2.400000e+03 2.400000e+03 2.400000e+03 2.400000e+03 2.400000e+03 2.400000e+03 2.400000e+03 2.400000e+03 2.400000e+03 mean 2.250977e-16 4.503342e-17 1.471971e-16 -2.406640e-17 2.680263e-16 -8.234154e-18 -1.709281e-16 4.928733e-14 4.897231e-14 std 1.000208e+00 1.000208e+00 1.000208e+00 1.000208e+00 1.000208e+00 1.000208e+00 1.000208e+00 1.000208e+00 1.000208e+00 min -3.618993e+00 -2.677207e+00 -1.766429e+00 -3.364203e-01 -8.897850e-01 -1.636285e+00 -6.704685e-01 -2.937091e+00 -2.084576e+00 25% -4.009185e-01 -4.598398e-01 -7.087691e-01 -2.324570e-01 -8.897850e-01 -7.089826e-01 -6.704685e-01 -6.732889e-01 -8.086270e-01 50% -4.009185e-01 1.736938e-01 -1.933403e-01 -1.774091e-01 -8.897850e-01 -2.895998e-01 -6.704685e-01 8.468878e-02 -1.278830e-01 75% 6.717731e-01 4.904606e-01 4.973342e-01 -1.033061e-01 9.975186e-01 5.375162e-01 6.315842e-01 8.607566e-01 6.455277e-01 max 7.107923e+00 7.459330e+00 1.179553e+01 1.945618e+01 3.828474e+00 8.878574e+00 8.291994e+00 1.560846e+00 6.062967e+00 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } bedrooms bathrooms sqft_living sqft_lot floors sqft_above sqft_basement lat long count 800.000000 800.000000 800.000000 800.000000 800.000000 800.000000 800.000000 800.000000 800.000000 mean 0.018772 0.041444 0.024401 0.016506 0.026737 0.044415 -0.031370 -0.056059 0.016900 std 0.982683 0.997594 0.989079 1.074079 0.991645 0.993807 0.999638 1.008010 1.028649 min -2.546302 -1.726907 -1.626232 -0.328715 -0.889785 -1.477851 -0.670469 -2.693960 -2.141602 25% -0.400918 -0.459840 -0.677843 -0.234254 -0.889785 -0.685684 -0.670469 -0.737509 -0.815755 50% -0.400918 0.173694 -0.172723 -0.177521 0.053867 -0.266301 -0.670469 0.031504 -0.088678 75% 0.671773 0.490461 0.487026 -0.113533 0.997519 0.595764 0.550206 0.817340 0.597412 max 8.180614 4.925195 7.321611 21.716593 2.884822 5.139078 5.839795 1.554333 6.369480 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } bedrooms bathrooms sqft_living sqft_lot floors sqft_above sqft_basement lat long count 800.000000 800.000000 800.000000 800.000000 800.000000 800.000000 800.000000 800.000000 800.000000 mean 0.010727 -0.018346 -0.029080 0.052808 0.006684 -0.021866 -0.020484 -0.005631 0.000897 std 0.965422 0.963162 0.946367 1.569619 1.012587 0.955805 0.938793 1.022830 1.028155 min -3.618993 -2.677207 -1.657158 -0.335005 -0.889785 -1.524449 -0.670469 -2.656332 -1.778063 25% -0.400918 -0.459840 -0.701038 -0.229160 -0.889785 -0.708983 -0.670469 -0.624084 -0.789024 50% -0.400918 0.173694 -0.183032 -0.174051 -0.889785 -0.295425 -0.670469 0.174054 -0.174216 75% 0.671773 0.490461 0.417443 -0.100683 0.997519 0.479269 0.588182 0.842124 0.604540 max 4.962540 3.658128 5.785633 36.746809 3.828474 5.010933 4.016921 1.544926 6.412249 In [14]: scaler = StandardScaler () . fit ( y_train ) y_train = scaler . transform ( y_train ) y_val = scaler . transform ( y_val ) y_test = scaler . transform ( y_test ) One-Degree Polynomial Model In [15]: import statsmodels.api as sm from statsmodels.regression.linear_model import OLS model_1 = OLS ( np . array ( y_train ) . reshape ( - 1 , 1 ), sm . add_constant ( X_train_df )) . fit () model_1 . summary () Out[15]: OLS Regression Results Dep. Variable: y R-squared: 0.586 Model: OLS Adj. R-squared: 0.584 Method: Least Squares F-statistic: 422.3 Date: Mon, 07 Oct 2019 Prob (F-statistic): 0.00 Time: 15:13:28 Log-Likelihood: -2348.5 No. Observations: 2400 AIC: 4715. Df Residuals: 2391 BIC: 4767. Df Model: 8 Covariance Type: nonrobust coef std err t P>|t| [0.025 0.975] const -5.145e-15 0.013 -3.91e-13 1.000 -0.026 0.026 bedrooms -0.1592 0.017 -9.505 0.000 -0.192 -0.126 bathrooms 0.0422 0.022 1.914 0.056 -0.001 0.085 sqft_living 0.4011 0.011 36.238 0.000 0.379 0.423 sqft_lot -0.0058 0.014 -0.420 0.675 -0.033 0.021 floors -0.0470 0.017 -2.690 0.007 -0.081 -0.013 sqft_above 0.3866 0.013 30.254 0.000 0.362 0.412 sqft_basement 0.1242 0.014 8.651 0.000 0.096 0.152 lat 0.2414 0.013 17.983 0.000 0.215 0.268 long -0.1388 0.014 -9.605 0.000 -0.167 -0.110 Omnibus: 1646.401 Durbin-Watson: 2.009 Prob(Omnibus): 0.000 Jarque-Bera (JB): 52596.394 Skew: 2.797 Prob(JB): 0.00 Kurtosis: 25.241 Cond. No. 2.95e+19 Warnings: [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. [2] The smallest eigenvalue is 9.63e-36. This might indicate that there are strong multicollinearity problems or that the design matrix is singular. Two-Degree Polynomial Model In [16]: def add_square_terms ( df ): df = df . copy () cols = df . columns . copy () for col in cols : df [ ' {} &#94;2' . format ( col )] = df [ col ] ** 2 return df X_train_df_2 = add_square_terms ( X_train ) X_val_df_2 = add_square_terms ( X_val ) # Standardizing our added coefficients cols = X_train_df_2 . columns scaler = StandardScaler () . fit ( X_train_df_2 ) X_train_df_2 = pd . DataFrame ( scaler . transform ( X_train_df_2 ), columns = cols ) X_val_df_2 = pd . DataFrame ( scaler . transform ( X_val_df_2 ), columns = cols ) print ( X_train_df . shape , X_train_df_2 . shape ) # Also check using the describe() function that the mean and standard deviations are the way we want them X_train_df_2 . head () (2400, 9) (2400, 18) Out[16]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } bedrooms bathrooms sqft_living sqft_lot floors sqft_above sqft_basement lat long bedrooms&#94;2 bathrooms&#94;2 sqft_living&#94;2 sqft_lot&#94;2 floors&#94;2 sqft_above&#94;2 sqft_basement&#94;2 lat&#94;2 long&#94;2 0 -0.400918 -0.459840 -0.533523 -0.184294 -0.889785 -0.243002 -0.670469 -0.261919 -1.179294 -0.462425 -0.498149 -0.435619 -0.081332 -0.820725 -0.317640 -0.429442 -0.263451 1.180094 1 -0.400918 1.123994 0.919986 -0.129729 0.997519 1.399581 -0.670469 0.525365 0.289117 -0.462425 0.962623 0.551247 -0.079773 0.882097 1.104202 -0.429442 0.524670 -0.289785 2 0.671773 0.490461 -0.049020 -0.167446 -0.889785 -0.860426 1.499619 0.720739 0.545733 0.533184 0.286055 -0.174327 -0.080898 -0.820725 -0.625213 0.965746 0.720531 -0.546402 3 -0.400918 0.490461 -0.121180 -0.035583 -0.889785 0.222979 -0.670469 0.066599 -0.088678 -0.462425 0.286055 -0.217531 -0.076044 -0.820725 -0.003426 -0.429442 0.065197 0.088151 4 -0.400918 0.490461 -0.327352 -0.187215 -0.889785 -0.452693 0.154165 -1.411729 0.232092 -0.462425 0.286055 -0.332701 -0.081403 -0.820725 -0.436000 -0.227977 -1.411246 -0.232748 In [17]: model_2 = OLS ( np . array ( y_train ) . reshape ( - 1 , 1 ), sm . add_constant ( X_train_df_2 )) . fit () model_2 . summary () Out[17]: OLS Regression Results Dep. Variable: y R-squared: 0.612 Model: OLS Adj. R-squared: 0.609 Method: Least Squares F-statistic: 220.8 Date: Mon, 07 Oct 2019 Prob (F-statistic): 0.00 Time: 15:13:28 Log-Likelihood: -2269.9 No. Observations: 2400 AIC: 4576. Df Residuals: 2382 BIC: 4680. Df Model: 17 Covariance Type: nonrobust coef std err t P>|t| [0.025 0.975] const -6.175e-12 0.013 -4.84e-10 1.000 -0.025 0.025 bedrooms -0.1271 0.058 -2.186 0.029 -0.241 -0.013 bathrooms 0.1537 0.060 2.569 0.010 0.036 0.271 sqft_living 0.3406 0.026 12.895 0.000 0.289 0.392 sqft_lot -0.0278 0.030 -0.920 0.358 -0.087 0.032 floors -0.1006 0.087 -1.151 0.250 -0.272 0.071 sqft_above 0.2460 0.036 6.809 0.000 0.175 0.317 sqft_basement 0.2587 0.033 7.758 0.000 0.193 0.324 lat 83.5852 8.613 9.705 0.000 66.696 100.474 long -7.0103 16.124 -0.435 0.664 -38.628 24.608 bedrooms&#94;2 -0.0117 0.057 -0.207 0.836 -0.123 0.099 bathrooms&#94;2 -0.1395 0.061 -2.293 0.022 -0.259 -0.020 sqft_living&#94;2 0.2606 0.104 2.498 0.013 0.056 0.465 sqft_lot&#94;2 0.0395 0.029 1.366 0.172 -0.017 0.096 floors&#94;2 0.0449 0.083 0.539 0.590 -0.118 0.208 sqft_above&#94;2 0.0384 0.105 0.366 0.714 -0.167 0.244 sqft_basement&#94;2 -0.2640 0.049 -5.424 0.000 -0.359 -0.169 lat&#94;2 -83.3483 8.612 -9.678 0.000 -100.237 -66.460 long&#94;2 -6.8786 16.124 -0.427 0.670 -38.498 24.741 Omnibus: 1594.128 Durbin-Watson: 2.011 Prob(Omnibus): 0.000 Jarque-Bera (JB): 41401.592 Skew: 2.739 Prob(JB): 0.00 Kurtosis: 22.596 Cond. No. 2.09e+16 Warnings: [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. [2] The smallest eigenvalue is 3.68e-29. This might indicate that there are strong multicollinearity problems or that the design matrix is singular. Three-Degree Polynomial Model In [18]: # generalizing our function from above def add_square_and_cube_terms ( df ): df = df . copy () cols = df . columns . copy () for col in cols : df [ ' {} &#94;2' . format ( col )] = df [ col ] ** 2 df [ ' {} &#94;3' . format ( col )] = df [ col ] ** 3 return df X_train_df_3 = add_square_and_cube_terms ( X_train ) X_val_df_3 = add_square_and_cube_terms ( X_val ) # Standardizing our added coefficients cols = X_train_df_3 . columns scaler = StandardScaler () . fit ( X_train_df_3 ) X_train_df_3 = pd . DataFrame ( scaler . transform ( X_train_df_3 ), columns = cols ) X_val_df_3 = pd . DataFrame ( scaler . transform ( X_val_df_3 ), columns = cols ) print ( X_train_df . shape , X_train_df_3 . shape ) # Also check using the describe() function that the mean and standard deviations are the way we want them X_train_df_3 . head () (2400, 9) (2400, 27) Out[18]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } bedrooms bathrooms sqft_living sqft_lot floors sqft_above sqft_basement lat long bedrooms&#94;2 bedrooms&#94;3 bathrooms&#94;2 bathrooms&#94;3 sqft_living&#94;2 sqft_living&#94;3 sqft_lot&#94;2 sqft_lot&#94;3 floors&#94;2 floors&#94;3 sqft_above&#94;2 sqft_above&#94;3 sqft_basement&#94;2 sqft_basement&#94;3 lat&#94;2 lat&#94;3 long&#94;2 long&#94;3 0 -0.400918 -0.459840 -0.533523 -0.184294 -0.889785 -0.243002 -0.670469 -0.261919 -1.179294 -0.462425 -0.433878 -0.498149 -0.388130 -0.435619 -0.219568 -0.081332 -0.052800 -0.820725 -0.716812 -0.317640 -0.259891 -0.429442 -0.212933 -0.263451 -0.264982 1.180094 -1.180893 1 -0.400918 1.123994 0.919986 -0.129729 0.997519 1.399581 -0.670469 0.525365 0.289117 -0.462425 -0.433878 0.962623 0.609667 0.551247 0.166351 -0.079773 -0.052774 0.882097 0.708772 1.104202 0.616150 -0.429442 -0.212933 0.524670 0.523971 -0.289785 0.290452 2 0.671773 0.490461 -0.049020 -0.167446 -0.889785 -0.860426 1.499619 0.720739 0.545733 0.533184 0.342544 0.286055 0.085193 -0.174327 -0.140462 -0.080898 -0.052793 -0.820725 -0.716812 -0.625213 -0.367027 0.965746 0.341578 0.720531 0.720318 -0.546402 0.547071 3 -0.400918 0.490461 -0.121180 -0.035583 -0.889785 0.222979 -0.670469 0.066599 -0.088678 -0.462425 -0.433878 0.286055 0.085193 -0.217531 -0.154904 -0.076044 -0.052686 -0.820725 -0.716812 -0.003426 -0.113103 -0.429442 -0.212933 0.065197 0.063793 0.088151 -0.087625 4 -0.400918 0.490461 -0.327352 -0.187215 -0.889785 -0.452693 0.154165 -1.411729 0.232092 -0.462425 -0.433878 0.286055 0.085193 -0.332701 -0.190853 -0.081403 -0.052801 -0.820725 -0.716812 -0.436000 -0.306038 -0.227977 -0.182506 -1.411246 -1.410757 -0.232748 0.233404 In [19]: model_3 = OLS ( np . array ( y_train ) . reshape ( - 1 , 1 ), sm . add_constant ( X_train_df_3 )) . fit () model_3 . summary () Out[19]: OLS Regression Results Dep. Variable: y R-squared: 0.698 Model: OLS Adj. R-squared: 0.695 Method: Least Squares F-statistic: 211.2 Date: Mon, 07 Oct 2019 Prob (F-statistic): 0.00 Time: 15:13:28 Log-Likelihood: -1967.6 No. Observations: 2400 AIC: 3989. Df Residuals: 2373 BIC: 4145. Df Model: 26 Covariance Type: nonrobust coef std err t P>|t| [0.025 0.975] const 6.291e-09 0.011 5.58e-07 1.000 -0.022 0.022 bedrooms 0.2510 0.120 2.094 0.036 0.016 0.486 bathrooms -0.2267 0.120 -1.893 0.058 -0.461 0.008 sqft_living 0.2066 0.057 3.622 0.000 0.095 0.319 sqft_lot 0.0520 0.047 1.098 0.272 -0.041 0.145 floors 1.1766 0.624 1.886 0.059 -0.047 2.400 sqft_above 0.4473 0.078 5.715 0.000 0.294 0.601 sqft_basement -0.3982 0.060 -6.640 0.000 -0.516 -0.281 lat -6.976e+04 3592.874 -19.417 0.000 -7.68e+04 -6.27e+04 long 3.138e+04 8572.131 3.661 0.000 1.46e+04 4.82e+04 bedrooms&#94;2 -0.5999 0.218 -2.757 0.006 -1.027 -0.173 bedrooms&#94;3 0.2824 0.111 2.535 0.011 0.064 0.501 bathrooms&#94;2 0.8180 0.216 3.779 0.000 0.394 1.243 bathrooms&#94;3 -0.6577 0.119 -5.531 0.000 -0.891 -0.425 sqft_living&#94;2 2.2922 0.273 8.394 0.000 1.757 2.828 sqft_living&#94;3 -1.2107 0.219 -5.535 0.000 -1.640 -0.782 sqft_lot&#94;2 -0.1480 0.123 -1.207 0.227 -0.388 0.092 sqft_lot&#94;3 0.1319 0.088 1.491 0.136 -0.042 0.305 floors&#94;2 -2.3337 1.147 -2.034 0.042 -4.583 -0.084 floors&#94;3 1.1113 0.543 2.048 0.041 0.047 2.175 sqft_above&#94;2 -2.1768 0.351 -6.194 0.000 -2.866 -1.488 sqft_above&#94;3 1.3407 0.228 5.876 0.000 0.893 1.788 sqft_basement&#94;2 0.0363 0.149 0.243 0.808 -0.256 0.328 sqft_basement&#94;3 -0.1946 0.126 -1.546 0.122 -0.441 0.052 lat&#94;2 1.397e+05 7188.240 19.429 0.000 1.26e+05 1.54e+05 lat&#94;3 -6.99e+04 3595.377 -19.441 0.000 -7.69e+04 -6.28e+04 long&#94;2 6.284e+04 1.72e+04 3.663 0.000 2.92e+04 9.65e+04 long&#94;3 3.145e+04 8583.990 3.664 0.000 1.46e+04 4.83e+04 Omnibus: 1337.688 Durbin-Watson: 1.993 Prob(Omnibus): 0.000 Jarque-Bera (JB): 29677.038 Skew: 2.170 Prob(JB): 0.00 Kurtosis: 19.672 Cond. No. 2.25e+15 Warnings: [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. [2] The smallest eigenvalue is 4.47e-27. This might indicate that there are strong multicollinearity problems or that the design matrix is singular. N-Degree Polynomial Model In [20]: # generalizing our function from above def add_higher_order_polynomial_terms ( df , N = 7 ): df = df . copy () cols = df . columns . copy () for col in cols : for i in range ( 2 , N + 1 ): df [ ' {} &#94; {} ' . format ( col , i )] = df [ col ] ** i return df N = 8 X_train_df_N = add_higher_order_polynomial_terms ( X_train , N ) X_val_df_N = add_higher_order_polynomial_terms ( X_val , N ) # Standardizing our added coefficients cols = X_train_df_N . columns scaler = StandardScaler () . fit ( X_train_df_N ) X_train_df_N = pd . DataFrame ( scaler . transform ( X_train_df_N ), columns = cols ) X_val_df_N = pd . DataFrame ( scaler . transform ( X_val_df_N ), columns = cols ) print ( X_train_df . shape , X_train_df_N . shape ) # Also check using the describe() function that the mean and standard deviations are the way we want them X_train_df_N . head () (2400, 9) (2400, 72) Out[20]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } bedrooms bathrooms sqft_living sqft_lot floors sqft_above sqft_basement lat long bedrooms&#94;2 bedrooms&#94;3 bedrooms&#94;4 bedrooms&#94;5 bedrooms&#94;6 bedrooms&#94;7 bedrooms&#94;8 bathrooms&#94;2 bathrooms&#94;3 bathrooms&#94;4 bathrooms&#94;5 bathrooms&#94;6 bathrooms&#94;7 bathrooms&#94;8 sqft_living&#94;2 sqft_living&#94;3 sqft_living&#94;4 sqft_living&#94;5 sqft_living&#94;6 sqft_living&#94;7 sqft_living&#94;8 sqft_lot&#94;2 sqft_lot&#94;3 sqft_lot&#94;4 sqft_lot&#94;5 sqft_lot&#94;6 sqft_lot&#94;7 sqft_lot&#94;8 floors&#94;2 floors&#94;3 floors&#94;4 floors&#94;5 floors&#94;6 floors&#94;7 floors&#94;8 sqft_above&#94;2 sqft_above&#94;3 sqft_above&#94;4 sqft_above&#94;5 sqft_above&#94;6 sqft_above&#94;7 sqft_above&#94;8 sqft_basement&#94;2 sqft_basement&#94;3 sqft_basement&#94;4 sqft_basement&#94;5 sqft_basement&#94;6 sqft_basement&#94;7 sqft_basement&#94;8 lat&#94;2 lat&#94;3 lat&#94;4 lat&#94;5 lat&#94;6 lat&#94;7 lat&#94;8 long&#94;2 long&#94;3 long&#94;4 long&#94;5 long&#94;6 long&#94;7 long&#94;8 0 -0.400918 -0.459840 -0.533523 -0.184294 -0.889785 -0.243002 -0.670469 -0.261919 -1.179294 -0.462425 -0.433878 -0.339413 -0.231621 -0.149138 -0.097431 -0.067607 -0.498149 -0.388130 -0.241435 -0.141594 -0.088630 -0.062342 -0.049025 -0.435619 -0.219568 -0.091216 -0.246556 -0.658169 -1.501069 1.377053 -0.081332 -0.052800 -0.116437 0.432539 0.123517 0.488042 0.758862 -0.820725 -0.716812 -0.591427 -0.470475 -0.371825 -0.298830 -0.247064 -0.317640 -0.259891 -0.157166 -0.178065 -0.799711 -1.507797 1.422035 -0.429442 -0.212933 -0.096048 -0.050491 -0.161975 -0.055312 0.108540 -0.263451 -0.264982 -0.266511 -0.268039 -0.269565 -0.271089 -0.272612 1.180094 -1.180893 1.181692 -1.182490 1.183286 -1.184082 1.184877 1 -0.400918 1.123994 0.919986 -0.129729 0.997519 1.399581 -0.670469 0.525365 0.289117 -0.462425 -0.433878 -0.339413 -0.231621 -0.149138 -0.097431 -0.067607 0.962623 0.609667 0.282197 0.093936 0.009656 -0.022846 -0.033483 0.551247 0.166351 0.012318 0.119550 -1.053598 -1.021276 0.389612 -0.079773 -0.052774 -0.111868 -0.810279 0.823815 0.199480 1.000871 0.882097 0.708772 0.505638 0.316005 0.166200 0.059351 -0.012432 1.104202 0.616150 0.231521 0.288260 -1.225165 -1.032551 0.409224 -0.429442 -0.212933 -0.096048 -0.050491 -0.161975 -0.055312 0.108540 0.524670 0.523971 0.523268 0.522562 0.521851 0.521137 0.520419 -0.289785 0.290452 -0.291118 0.291784 -0.292450 0.293116 -0.293781 2 0.671773 0.490461 -0.049020 -0.167446 -0.889785 -0.860426 1.499619 0.720739 0.545733 0.533184 0.342544 0.161719 0.040880 -0.017513 -0.038115 -0.041916 0.286055 0.085193 -0.024414 -0.057144 -0.058395 -0.051989 -0.045573 -0.174327 -0.140462 -0.075159 -0.204441 0.001085 0.687907 -0.472558 -0.080898 -0.052793 -0.115420 -0.618477 -1.404683 0.374544 -0.388685 -0.820725 -0.716812 -0.591427 -0.470475 -0.371825 -0.298830 -0.247064 -0.625213 -0.367027 -0.183625 -0.195507 0.103163 1.058180 0.032349 0.965746 0.341578 0.061803 -0.010518 0.609624 1.172741 0.714587 0.720531 0.720318 0.720101 0.719880 0.719655 0.719425 0.719191 -0.546402 0.547071 -0.547739 0.548406 -0.549072 0.549737 -0.550401 3 -0.400918 0.490461 -0.121180 -0.035583 -0.889785 0.222979 -0.670469 0.066599 -0.088678 -0.462425 -0.433878 -0.339413 -0.231621 -0.149138 -0.097431 -0.067607 0.286055 0.085193 -0.024414 -0.057144 -0.058395 -0.051989 -0.045573 -0.217531 -0.154904 -0.078379 -0.213665 0.890215 -1.628144 0.193797 -0.076044 -0.052686 -0.090616 -1.003240 -1.014952 1.084197 -0.263787 -0.820725 -0.716812 -0.591427 -0.470475 -0.371825 -0.298830 -0.247064 -0.003426 -0.113103 -0.108971 -0.136170 0.866240 -1.633667 0.208379 -0.429442 -0.212933 -0.096048 -0.050491 -0.161975 -0.055312 0.108540 0.065197 0.063793 0.062389 0.060984 0.059577 0.058170 0.056761 0.088151 -0.087625 0.087098 -0.086570 0.086042 -0.085514 0.084986 4 -0.400918 0.490461 -0.327352 -0.187215 -0.889785 -0.452693 0.154165 -1.411729 0.232092 -0.462425 -0.433878 -0.339413 -0.231621 -0.149138 -0.097431 -0.067607 0.286055 0.085193 -0.024414 -0.057144 -0.058395 -0.051989 -0.045573 -0.332701 -0.190853 -0.085868 -0.233738 -1.094200 0.691654 1.372554 -0.081403 -0.052801 -0.116585 0.054276 -0.846603 0.175618 -1.669502 -0.820725 -0.716812 -0.591427 -0.470475 -0.371825 -0.298830 -0.247064 -0.436000 -0.306038 -0.169774 -0.187159 1.424508 1.642941 -0.565807 -0.227977 -0.182506 -0.092756 -0.050174 -0.159652 0.307214 -2.293748 -1.411246 -1.410757 -1.410261 -1.409758 -1.409249 -1.408733 -1.408211 -0.232748 0.233404 -0.234061 0.234716 -0.235372 0.236027 -0.236682 In [21]: model_N = OLS ( np . array ( y_train ) . reshape ( - 1 , 1 ), sm . add_constant ( X_train_df_N )) . fit () model_N . summary () Out[21]: OLS Regression Results Dep. Variable: y R-squared: 0.738 Model: OLS Adj. R-squared: 0.732 Method: Least Squares F-statistic: 106.4 Date: Mon, 07 Oct 2019 Prob (F-statistic): 0.00 Time: 15:13:28 Log-Likelihood: -1796.1 No. Observations: 2400 AIC: 3718. Df Residuals: 2337 BIC: 4083. Df Model: 62 Covariance Type: nonrobust coef std err t P>|t| [0.025 0.975] const 0.0790 0.044 1.788 0.074 -0.008 0.166 bedrooms 0.7485 1.667 0.449 0.653 -2.520 4.017 bathrooms 4.0292 2.090 1.928 0.054 -0.069 8.127 sqft_living -1.825e+10 8.44e+09 -2.161 0.031 -3.48e+10 -1.69e+09 sqft_lot 0.1034 0.047 2.200 0.028 0.011 0.196 floors 5.427e+09 2.53e+09 2.146 0.032 4.67e+08 1.04e+10 sqft_above 1.615e+10 7.47e+09 2.161 0.031 1.49e+09 3.08e+10 sqft_basement 8.668e+09 4.01e+09 2.161 0.031 8.02e+08 1.65e+10 lat -6.58e+11 1.11e+11 -5.907 0.000 -8.76e+11 -4.4e+11 long 1.891e+11 1.71e+11 1.105 0.269 -1.47e+11 5.25e+11 bedrooms&#94;2 -13.8231 16.496 -0.838 0.402 -46.172 18.526 bedrooms&#94;3 85.7910 75.252 1.140 0.254 -61.777 233.359 bedrooms&#94;4 -286.3415 209.397 -1.367 0.172 -696.964 124.281 bedrooms&#94;5 585.7759 382.024 1.533 0.125 -163.365 1334.917 bedrooms&#94;6 -724.1268 437.651 -1.655 0.098 -1582.351 134.097 bedrooms&#94;7 487.2274 279.519 1.743 0.081 -60.903 1035.358 bedrooms&#94;8 -135.4299 74.938 -1.807 0.071 -282.382 11.522 bathrooms&#94;2 -50.0310 17.008 -2.942 0.003 -83.384 -16.678 bathrooms&#94;3 271.5388 78.495 3.459 0.001 117.612 425.465 bathrooms&#94;4 -902.0249 244.292 -3.692 0.000 -1381.076 -422.974 bathrooms&#94;5 1860.8234 493.746 3.769 0.000 892.598 2829.048 bathrooms&#94;6 -2254.0226 602.565 -3.741 0.000 -3435.640 -1072.405 bathrooms&#94;7 1451.5753 399.258 3.636 0.000 668.638 2234.513 bathrooms&#94;8 -381.7826 109.773 -3.478 0.001 -597.045 -166.520 sqft_living&#94;2 3.2337 1.155 2.800 0.005 0.969 5.499 sqft_living&#94;3 -4.1768 2.059 -2.029 0.043 -8.214 -0.139 sqft_living&#94;4 3.5216 1.694 2.079 0.038 0.199 6.844 sqft_living&#94;5 -0.0344 0.018 -1.869 0.062 -0.071 0.002 sqft_living&#94;6 0.0243 0.013 1.815 0.070 -0.002 0.051 sqft_living&#94;7 0.0117 0.014 0.856 0.392 -0.015 0.039 sqft_living&#94;8 -0.0216 0.014 -1.575 0.115 -0.049 0.005 sqft_lot&#94;2 -0.2332 0.121 -1.924 0.054 -0.471 0.004 sqft_lot&#94;3 0.1763 0.087 2.023 0.043 0.005 0.347 sqft_lot&#94;4 -0.0156 0.012 -1.337 0.181 -0.038 0.007 sqft_lot&#94;5 0.0011 0.011 0.101 0.920 -0.020 0.022 sqft_lot&#94;6 0.0004 0.011 0.037 0.970 -0.021 0.021 sqft_lot&#94;7 -0.0104 0.011 -0.965 0.335 -0.031 0.011 sqft_lot&#94;8 0.0107 0.011 0.993 0.321 -0.010 0.032 floors&#94;2 -1.676e+10 7.8e+09 -2.147 0.032 -3.21e+10 -1.45e+09 floors&#94;3 1.529e+10 7.1e+09 2.155 0.031 1.38e+09 2.92e+10 floors&#94;4 4.149e+09 2.27e+09 1.830 0.067 -2.97e+08 8.59e+09 floors&#94;5 -1.176e+10 5.92e+09 -1.986 0.047 -2.34e+10 -1.49e+08 floors&#94;6 -3.924e+09 1.94e+09 -2.024 0.043 -7.73e+09 -1.22e+08 floors&#94;7 1.239e+10 5.63e+09 2.200 0.028 1.34e+09 2.34e+10 floors&#94;8 -4.878e+09 2.24e+09 -2.181 0.029 -9.27e+09 -4.91e+08 sqft_above&#94;2 -1.5414 1.287 -1.198 0.231 -4.065 0.982 sqft_above&#94;3 0.7910 1.763 0.449 0.654 -2.666 4.248 sqft_above&#94;4 0.1489 1.039 0.143 0.886 -1.889 2.187 sqft_above&#94;5 0.0015 0.017 0.090 0.928 -0.031 0.034 sqft_above&#94;6 -0.0184 0.013 -1.368 0.171 -0.045 0.008 sqft_above&#94;7 -0.0146 0.014 -1.066 0.287 -0.041 0.012 sqft_above&#94;8 -0.0068 0.014 -0.496 0.620 -0.034 0.020 sqft_basement&#94;2 1.9238 0.798 2.412 0.016 0.360 3.488 sqft_basement&#94;3 -6.6967 2.368 -2.828 0.005 -11.341 -2.053 sqft_basement&#94;4 12.2596 4.045 3.031 0.002 4.327 20.192 sqft_basement&#94;5 -8.5928 2.694 -3.190 0.001 -13.875 -3.311 sqft_basement&#94;6 0.0144 0.012 1.199 0.231 -0.009 0.038 sqft_basement&#94;7 0.0116 0.011 1.059 0.290 -0.010 0.033 sqft_basement&#94;8 -0.0086 0.011 -0.783 0.433 -0.030 0.013 lat&#94;2 2.588e+12 5.62e+11 4.601 0.000 1.49e+12 3.69e+12 lat&#94;3 -3.378e+12 1.13e+12 -2.991 0.003 -5.59e+12 -1.16e+12 lat&#94;4 1.107e+12 1.04e+12 1.067 0.286 -9.28e+11 3.14e+12 lat&#94;5 6.175e+11 2.07e+11 2.986 0.003 2.12e+11 1.02e+12 lat&#94;6 2.786e+11 4.35e+11 0.640 0.522 -5.75e+11 1.13e+12 lat&#94;7 -8.725e+11 3.57e+11 -2.447 0.014 -1.57e+12 -1.73e+11 lat&#94;8 3.168e+11 8.68e+10 3.651 0.000 1.47e+11 4.87e+11 long&#94;2 4.566e+11 5.54e+11 0.824 0.410 -6.3e+11 1.54e+12 long&#94;3 -1.043e+11 7.18e+11 -0.145 0.885 -1.51e+12 1.3e+12 long&#94;4 -7.335e+11 1.2e+12 -0.613 0.540 -3.08e+12 1.61e+12 long&#94;5 6.222e+11 1.23e+12 0.507 0.612 -1.78e+12 3.03e+12 long&#94;6 2.347e+12 1.36e+12 1.725 0.085 -3.2e+11 5.01e+12 long&#94;7 1.831e+12 1.01e+12 1.809 0.071 -1.54e+11 3.82e+12 long&#94;8 4.676e+11 2.65e+11 1.764 0.078 -5.22e+10 9.87e+11 Omnibus: 1365.789 Durbin-Watson: 2.050 Prob(Omnibus): 0.000 Jarque-Bera (JB): 31897.875 Skew: 2.217 Prob(JB): 0.00 Kurtosis: 20.301 Cond. No. 1.47e+16 Warnings: [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. [2] The smallest eigenvalue is 1.77e-28. This might indicate that there are strong multicollinearity problems or that the design matrix is singular. You can also create a model with interaction terms or any other higher order polynomial term of your choice. Note: Can you see how creating a function that takes in a dataframe and a degree and creates polynomial terms up until that degree can be useful? This is what we have you do in your homework! Regularization What is Regularization and why should I care? When we have a lot of predictors, we need to worry about overfitting. Let's check this out: In [22]: from sklearn.metrics import r2_score x = [ 1 , 2 , 3 , N ] models = [ model_1 , model_2 , model_3 , model_N ] X_trains = [ X_train_df , X_train_df_2 , X_train_df_3 , X_train_df_N ] X_vals = [ X_val_df , X_val_df_2 , X_val_df_3 , X_val_df_N ] r2_train = [] r2_val = [] for i , model in enumerate ( models ): y_pred_tra = model . predict ( sm . add_constant ( X_trains [ i ])) y_pred_val = model . predict ( sm . add_constant ( X_vals [ i ])) r2_train . append ( r2_score ( y_train , y_pred_tra )) r2_val . append ( r2_score ( y_val , y_pred_val )) fig , ax = plt . subplots ( figsize = ( 8 , 6 )) ax . plot ( x , r2_train , 'o-' , label = r 'Training $R&#94;2$' ) ax . plot ( x , r2_val , 'o-' , label = r 'Validation $R&#94;2$' ) ax . set_xlabel ( 'Number of degree of polynomial' ) ax . set_ylabel ( r '$R&#94;2$ score' ) ax . set_title ( r '$R&#94;2$ score vs polynomial degree' ) ax . legend (); We notice a big difference between training and validation R&#94;2 scores: seems like we are overfitting. Introducing: regularization. What about Multicollinearity? There's seemingly a lot of multicollinearity in the data. Take a look at this warning that we got when showing our summary for our polynomial models: What is multicollinearity ? Why do we have it in our dataset? Why is this a problem? Does regularization help solve the issue of multicollinearity? What does Regularization help with? We have some pretty large and extreme coefficient values in our most recent models. These coefficient values also have very high variance. We can also clearly see some overfitting to the training set. In order to reduce the coefficients of our parameters, we can introduce a penalty term that penalizes some of these extreme coefficient values. Specifically, regularization helps us: Avoid overfitting. Reduce features that have weak predictive power. Discourage the use of a model that is too complex Big Idea: Reduce Variance by Increasing Bias Image Source: here Ridge Regression Ridge Regression is one such form of regularization. In practice, the ridge estimator reduces the complexity of the model by shrinking the coefficients, but it doesn't nullify them. We control the amount of regularization using a parameter $\\lambda$. NOTE : sklearn's ridge regression package represents this $\\lambda$ using a parameter alpha. In Ridge Regression, the penalty term is proportional to the L2-norm of the coefficients. Lasso Regression Lasso Regression is another form of regularization. Again, we control the amount of regularization using a parameter $\\lambda$. NOTE : sklearn's lasso regression package represents this $\\lambda$ using a parameter alpha. In Lasso Regression, the penalty term is proportional to the L1-norm of the coefficients. Some Differences between Ridge and Lasso Regression Since Lasso regression tend to produce zero estimates for a number of model parameters - we say that Lasso solutions are sparse - we consider to be a method for variable selection. In Ridge Regression, the penalty term is proportional to the L2-norm of the coefficients whereas in Lasso Regression, the penalty term is proportional to the L1-norm of the coefficients. Ridge Regression has a closed form solution! Lasso Regression does not. We often have to solve this iteratively. In the sklearn package for Lasso regression, there is a parameter called max_iter that determines how many iterations we perform. Why Standardizing Variables was not a waste of time Lasso regression puts constraints on the size of the coefficients associated to each variable. However, this value will depend on the magnitude of each variable. It is therefore necessary to standardize the variables. Let's use Ridge and Lasso to regularize our degree N polynomial Exercise : Play around with different values of alpha. Notice the new $R&#94;2$ value and also the range of values that the predictors take in the plot. In [23]: from sklearn.linear_model import Ridge # some values you can try out: 0.01, 0.1, 0.5, 1, 5, 10, 20, 40, 100, 200, 500, 1000, 10000 alpha = 100 ridge_model = Ridge ( alpha = alpha ) . fit ( X_train_df_N , y_train ) print ( 'R squared score for our original OLS model: {} ' . format ( r2_val [ - 1 ])) print ( 'R squared score for Ridge with alpha= {} : {} ' . format ( alpha , ridge_model . score ( X_val_df_N , y_val ))) fig , ax = plt . subplots ( figsize = ( 18 , 8 ), ncols = 2 ) ax = ax . ravel () ax [ 0 ] . hist ( model_N . params , bins = 10 , alpha = 0.5 ) ax [ 0 ] . set_title ( 'Histogram of predictor values for Original model with N: {} ' . format ( N )) ax [ 0 ] . set_xlabel ( 'Predictor values' ) ax [ 0 ] . set_ylabel ( 'Frequency' ) ax [ 1 ] . hist ( ridge_model . coef_ . flatten (), bins = 20 , alpha = 0.5 ) ax [ 1 ] . set_title ( 'Histogram of predictor values for Ridge Model with alpha: {} ' . format ( alpha )) ax [ 1 ] . set_xlabel ( 'Predictor values' ) ax [ 1 ] . set_ylabel ( 'Frequency' ); R squared score for our original OLS model: -1.8608470610311345 R squared score for Ridge with alpha=100: 0.5869651490827923 In [24]: from sklearn.linear_model import Lasso # some values you can try out: 0.00001, 0.0001, 0.001, 0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10, 20 alpha = 0.01 lasso_model = Lasso ( alpha = alpha , max_iter = 1000 ) . fit ( X_train_df_N , y_train ) print ( 'R squared score for our original OLS model: {} ' . format ( r2_val [ - 1 ])) print ( 'R squared score for Lasso with alpha= {} : {} ' . format ( alpha , lasso_model . score ( X_val_df_N , y_val ))) fig , ax = plt . subplots ( figsize = ( 18 , 8 ), ncols = 2 ) ax = ax . ravel () ax [ 0 ] . hist ( model_N . params , bins = 10 , alpha = 0.5 ) ax [ 0 ] . set_title ( 'Histogram of predictor values for Original model with N: {} ' . format ( N )) ax [ 0 ] . set_xlabel ( 'Predictor values' ) ax [ 0 ] . set_ylabel ( 'Frequency' ) ax [ 1 ] . hist ( lasso_model . coef_ . flatten (), bins = 20 , alpha = 0.5 ) ax [ 1 ] . set_title ( 'Histogram of predictor values for Lasso Model with alpha: {} ' . format ( alpha )) ax [ 1 ] . set_xlabel ( 'Predictor values' ) ax [ 1 ] . set_ylabel ( 'Frequency' ); R squared score for our original OLS model: -1.8608470610311345 R squared score for Lasso with alpha=0.01: 0.5975930359800542 Model Selection and Cross-Validation Here's our current setup so far: So we try out 10,000 different models on our validation set and pick the one that's the best? No! Since we could also be overfitting the validation set! One solution to the problems raised by using a single validation set is to evaluate each model on multiple validation sets and average the validation performance. This is the essence of cross-validation! Image source: here Let's give this a try using RidgeCV and LassoCV : In [25]: from sklearn.linear_model import RidgeCV from sklearn.linear_model import LassoCV alphas = ( 0.001 , 0.01 , 0.1 , 10 , 100 , 1000 , 10000 ) # Let us do k-fold cross validation k = 4 fitted_ridge = RidgeCV ( alphas = alphas ) . fit ( X_train_df_N , y_train ) fitted_lasso = LassoCV ( alphas = alphas ) . fit ( X_train_df_N , y_train ) print ( 'R&#94;2 score for our original OLS model: {} \\n ' . format ( r2_val [ - 1 ])) ridge_a = fitted_ridge . alpha_ print ( 'Best alpha for ridge: {} ' . format ( ridge_a )) print ( 'R&#94;2 score for Ridge with alpha= {} : {} \\n ' . format ( ridge_a , fitted_ridge . score ( X_val_df_N , y_val ))) lasso_a = fitted_lasso . alpha_ print ( 'Best alpha for lasso: {} ' . format ( lasso_a )) print ( 'R squared score for Lasso with alpha= {} : {} ' . format ( lasso_a , fitted_lasso . score ( X_val_df_N , y_val ))) R&#94;2 score for our original OLS model: -1.8608470610311345 Best alpha for ridge: 1000.0 R&#94;2 score for Ridge with alpha=1000.0: 0.5779474940635888 Best alpha for lasso: 0.01 R squared score for Lasso with alpha=0.01: 0.5975930359800542 We can also look at the coefficients of our CV models. Final Step: report the score on the test set for the model you have chosen to be the best. End of Standard Section if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"sections","url":"sections/sec_4/"},{"title":"S-Section 04: Regularization and Model Selection","text":"Jupyter Notebooks S-Section 4: Regularization and Model Selection","tags":"sections","url":"sections/section4/"},{"title":"Lab 5: Exploratory Data Analysis, seaborn, more Plotting","text":"Jupyter Notebooks Lab 5: Exploratory Data Analysis, seaborn, more Plotting Lab 5: Solutions to Exploratory Data Analysis, seaborn, more Plotting","tags":"labs","url":"labs/lab05/"},{"title":"Lecture 9: Visualization for Communication","text":"Slides Visualization PDF (1 of 2) Visualization PDF (2 of 2) Visualization PPTX","tags":"lectures","url":"lectures/lecture9/"},{"title":"Lecture 8:Regularization and EDA","text":"Slides Regularizationn PDF Regularizationn PPTX EDA PDF EDA PPTX","tags":"lectures","url":"lectures/lecture8/"},{"title":"S-Section 03: Multiple Linear  and Polynomial Regression","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109A Introduction to Data Science Standard Section 3: Multiple Linear Regression and Polynomial Regression Harvard University Fall 2019 Instructors : Pavlos Protopapas, Kevin Rader, and Chris Tanner Section Leaders : Marios Mattheakis, Abhimanyu (Abhi) Vasishth, Robbert (Rob) Struyven In [ ]: #RUN THIS CELL import requests from IPython.core.display import HTML styles = requests . get ( \"http://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\" ) . text HTML ( styles ) For this section, our goal is to get you familiarized with Multiple Linear Regression. We have learned how to model data with kNN Regression and Simple Linear Regression and our goal now is to dive deep into Linear Regression. Specifically, we will: Load in the titanic dataset from seaborn Learn a few ways to plot distributions of variables using seaborn Learn about different kinds of variables including continuous, categorical and ordinal Perform single and multiple linear regression Learn about interaction terms Understand how to interpret coefficients in linear regression Look at polynomial regression Understand the assumptions being made in a linear regression model (Extra): look at some cool plots to raise your EDA game In [ ]: # Data and Stats packages import numpy as np import pandas as pd # Visualization packages import matplotlib.pyplot as plt import seaborn as sns sns . set () Extending Linear Regression Working with the Titanic Dataset from Seaborn For our dataset, we'll be using the passenger list from the Titanic, which famously sank in 1912. Let's have a look at the data. Some descriptions of the data are at https://www.kaggle.com/c/titanic/data , and here's how seaborn preprocessed it . The task is to build a regression model to predict the fare , based on different attributes. Let's keep a subset of the data, which includes the following variables: age sex class embark_town alone fare (the response variable) In [ ]: # Load the dataset from seaborn titanic = sns . load_dataset ( \"titanic\" ) titanic . head () In [ ]: # checking for null values chosen_vars = [ 'age' , 'sex' , 'class' , 'embark_town' , 'alone' , 'fare' ] titanic = titanic [ chosen_vars ] titanic . info () Exercise : check the datatypes of each column and display the statistics (min, max, mean and any others) for all the numerical columns of the dataset. In [ ]: ## your code here In [ ]: # %load 'solutions/sol1.py' Exercise : drop all the non-null rows in the dataset. Is this always a good idea? In [ ]: ## your code here In [ ]: # %load 'solutions/sol2.py' Now let us visualize the response variable. A good visualization of the distribution of a variable will enable us to answer three kinds of questions: What values are central or typical? (e.g., mean, median, modes) What is the typical spread of values around those central values? (e.g., variance/stdev, skewness) What are unusual or exceptional values (e.g., outliers) In [ ]: fig , ax = plt . subplots ( nrows = 1 , ncols = 3 , figsize = ( 24 , 6 )) ax = ax . ravel () sns . distplot ( titanic [ 'fare' ], ax = ax [ 0 ]) ax [ 0 ] . set_title ( 'Seaborn distplot' ) ax [ 0 ] . set_ylabel ( 'Normalized frequencies' ) sns . violinplot ( x = 'fare' , data = titanic , ax = ax [ 1 ]) ax [ 1 ] . set_title ( 'Seaborn violin plot' ) ax [ 1 ] . set_ylabel ( 'Frequencies' ) sns . boxplot ( x = 'fare' , data = titanic , ax = ax [ 2 ]) ax [ 2 ] . set_title ( 'Seaborn box plot' ) ax [ 2 ] . set_ylabel ( 'Frequencies' ) fig . suptitle ( 'Distribution of count' ); How do we interpret these plots? Train-Test Split In [ ]: from sklearn.model_selection import train_test_split titanic_train , titanic_test = train_test_split ( titanic , train_size = 0.7 , random_state = 99 ) titanic_train = titanic_train . copy () titanic_test = titanic_test . copy () print ( titanic_train . shape , titanic_test . shape ) Simple one-variable OLS Exercise : You've done this before: make a simple model using the OLS package from the statsmodels library predicting fare using age using the training data. Name your model model_1 and display the summary In [ ]: from statsmodels.api import OLS import statsmodels.api as sm In [ ]: # Your code here In [ ]: # %load 'solutions/sol3.py' Dealing with different kinds of variables In general, you should be able to distinguish between three kinds of variables: Continuous variables: such as fare or age Categorical variables: such as sex or alone . There is no inherent ordering between the different values that these variables can take on. These are sometimes called nominal variables. Read more here . Ordinal variables: such as class (first > second > third). There is some inherent ordering of the values in the variables, but the values are not continuous either. Note : While there is some inherent ordering in class , we will be treating it like a categorical variable. In [ ]: titanic_orig = titanic_train . copy () Let us now examine the sex column and see the value counts. In [ ]: titanic_train [ 'sex' ] . value_counts () Exercise : Create a column sex_male that is 1 if the passenger is male, 0 if female. The value counts indicate that these are the two options in this particular dataset. Ensure that the datatype is int . In [ ]: # your code here In [ ]: # %load 'solutions/sol4.py' Do we need a sex_female column, or a sex_others column? Why or why not? Now, let us look at class in greater detail. In [ ]: titanic_train [ 'class_Second' ] = ( titanic_train [ 'class' ] == 'Second' ) . astype ( int ) titanic_train [ 'class_Third' ] = 1 * ( titanic_train [ 'class' ] == 'Third' ) # just another way to do it In [ ]: titanic_train . info () In [ ]: # This function automates the above: titanic_train_copy = pd . get_dummies ( titanic_train , columns = [ 'sex' , 'class' ], drop_first = True ) titanic_train_copy . head () Linear Regression with More Variables Exercise : Fit a linear regression including the new sex and class variables. Name this model model_2 . Don't forget the constant! In [ ]: # your code here In [ ]: # %load 'solutions/sol5.py' Interpreting These Results Which of the predictors do you think are important? Why? All else equal, what does being male do to the fare? Going back to the example from class What is the interpretation of $\\beta_0$ and $\\beta_1$? Exploring Interactions In [ ]: sns . lmplot ( x = \"age\" , y = \"fare\" , hue = \"sex\" , data = titanic_train , size = 6 ) The slopes seem to be different for male and female. What does that indicate? Let us now try to add an interaction effect into our model. In [ ]: # It seemed like gender interacted with age and class. Can we put that in our model? titanic_train [ 'sex_male_X_age' ] = titanic_train [ 'age' ] * titanic_train [ 'sex_male' ] model_3 = sm . OLS ( titanic_train [ 'fare' ], sm . add_constant ( titanic_train [[ 'age' , 'sex_male' , 'class_Second' , 'class_Third' , 'sex_male_X_age' ]]) ) . fit () model_3 . summary () What happened to the age and male terms? In [ ]: # It seemed like gender interacted with age and class. Can we put that in our model? titanic_train [ 'sex_male_X_class_Second' ] = titanic_train [ 'age' ] * titanic_train [ 'class_Second' ] titanic_train [ 'sex_male_X_class_Third' ] = titanic_train [ 'age' ] * titanic_train [ 'class_Third' ] model_4 = sm . OLS ( titanic_train [ 'fare' ], sm . add_constant ( titanic_train [[ 'age' , 'sex_male' , 'class_Second' , 'class_Third' , 'sex_male_X_age' , 'sex_male_X_class_Second' , 'sex_male_X_class_Third' ]]) ) . fit () model_4 . summary () Polynomial Regression Perhaps we now believe that the fare also depends on the square of age. How would we include this term in our model? In [ ]: fig , ax = plt . subplots ( figsize = ( 12 , 6 )) ax . plot ( titanic_train [ 'age' ], titanic_train [ 'fare' ], 'o' ) x = np . linspace ( 0 , 80 , 100 ) ax . plot ( x , x , '-' , label = r '$y=x$' ) ax . plot ( x , 0.04 * x ** 2 , '-' , label = r '$y=c x&#94;2$' ) ax . set_title ( 'Plotting Age (x) vs Fare (y)' ) ax . set_xlabel ( 'Age (x)' ) ax . set_ylabel ( 'Fare (y)' ) ax . legend (); Exercise : Create a model that predicts fare from all the predictors in model_4 + the square of age. Show the summary of this model. Call it model_5 . Remember to use the training data, titanic_train . In [ ]: # your code here In [ ]: # %load 'solutions/sol6.py' Looking at All Our Models: Model Selection What has happened to the $R&#94;2$ as we added more features? Does this mean that the model is better? (What if we kept adding more predictors and interaction terms? In general, how should we choose a model? We will spend a lot more time on model selection and learn about ways to do so as the course progresses. In [ ]: models = [ model_1 , model_2 , model_3 , model_4 , model_5 ] fig , ax = plt . subplots ( figsize = ( 12 , 6 )) ax . plot ([ model . df_model for model in models ], [ model . rsquared for model in models ], 'x-' ) ax . set_xlabel ( \"Model degrees of freedom\" ) ax . set_title ( 'Model degrees of freedom vs training $R&#94;2$' ) ax . set_ylabel ( \"$R&#94;2$\" ); What about the test data? We added a lot of columns to our training data and must add the same to our test data in order to calculate $R&#94;2$ scores. In [ ]: # Added features for model 1 # Nothing new to be added # Added features for model 2 titanic_test = pd . get_dummies ( titanic_test , columns = [ 'sex' , 'class' ], drop_first = True ) # Added features for model 3 titanic_test [ 'sex_male_X_age' ] = titanic_test [ 'age' ] * titanic_test [ 'sex_male' ] # Added features for model 4 titanic_test [ 'sex_male_X_class_Second' ] = titanic_test [ 'age' ] * titanic_test [ 'class_Second' ] titanic_test [ 'sex_male_X_class_Third' ] = titanic_test [ 'age' ] * titanic_test [ 'class_Third' ] # Added features for model 5 titanic_test [ 'age&#94;2' ] = titanic_test [ 'age' ] ** 2 Calculating R&#94;2 scores In [ ]: from sklearn.metrics import r2_score r2_scores = [] y_preds = [] y_true = titanic_test [ 'fare' ] # model 1 y_preds . append ( model_1 . predict ( sm . add_constant ( titanic_test [ 'age' ]))) # model 2 y_preds . append ( model_2 . predict ( sm . add_constant ( titanic_test [[ 'age' , 'sex_male' , 'class_Second' , 'class_Third' ]]))) # model 3 y_preds . append ( model_3 . predict ( sm . add_constant ( titanic_test [[ 'age' , 'sex_male' , 'class_Second' , 'class_Third' , 'sex_male_X_age' ]]))) # model 4 y_preds . append ( model_4 . predict ( sm . add_constant ( titanic_test [[ 'age' , 'sex_male' , 'class_Second' , 'class_Third' , 'sex_male_X_age' , 'sex_male_X_class_Second' , 'sex_male_X_class_Third' ]]))) # model 5 y_preds . append ( model_5 . predict ( sm . add_constant ( titanic_test [[ 'age' , 'sex_male' , 'class_Second' , 'class_Third' , 'sex_male_X_age' , 'sex_male_X_class_Second' , 'sex_male_X_class_Third' , 'age&#94;2' ]]))) for y_pred in y_preds : r2_scores . append ( r2_score ( y_true , y_pred )) models = [ model_1 , model_2 , model_3 , model_4 , model_5 ] fig , ax = plt . subplots ( figsize = ( 12 , 6 )) ax . plot ([ model . df_model for model in models ], r2_scores , 'x-' ) ax . set_xlabel ( \"Model degrees of freedom\" ) ax . set_title ( 'Model degrees of freedom vs test $R&#94;2$' ) ax . set_ylabel ( \"$R&#94;2$\" ); Regression Assumptions. Should We Even Regress Linearly? Question : What are the assumptions of a linear regression model? We find that the answer to this question can be found on closer examimation of $\\epsilon$. What is $\\epsilon$? It is assumed that $\\epsilon$ is normally distributed with a mean of 0 and variance $\\sigma&#94;2$. But what does this tell us? Assumption 1: Constant variance of $\\epsilon$ errors. This means that if we plot our residuals , which are the differences between the true $Y$ and our predicted $\\hat{Y}$, they should look like they have constant variance and a mean of 0. We will show this in our plots. Assumption 2: Independence of $\\epsilon$ errors. This again comes from the distribution of $\\epsilon$ that we decide beforehand. Assumption 3: Linearity. This is an implicit assumption as we claim that Y can be modeled through a linear combination of the predictors. Important Note: Even though our predictors, for instance $X_2$, can be created by squaring or cubing another variable, we still use them in a linear equation as shown above, which is why polynomial regression is still a linear model. Assumption 4: Normality. We assume that the $\\epsilon$ is normally distributed, and we can show this in a histogram of the residuals. Exercise : Calculate the residuals for model 5, our most recent model. Optionally, plot and histogram these residuals and check the assumptions of the model. In [ ]: # your code here In [ ]: # %load 'solutions/sol7.py' What can you say about the assumptions of the model? End of Standard Section Extra: Visual exploration of predictors' correlations The dataset for this problem contains 10 simulated predictors and a response variable. In [ ]: # read in the data data = pd . read_csv ( '../data/dataset3.txt' ) data . head () In [ ]: # this effect can be replicated using the scatter_matrix function in pandas plotting sns . pairplot ( data ); Predictors x1, x2, x3 seem to be perfectly correlated while predictors x4, x5, x6, x7 seem correlated. In [ ]: data . corr () In [ ]: sns . heatmap ( data . corr ()) Extra: A Handy Matplotlib Guide source: http://matplotlib.org/faq/usage_faq.html See also this matplotlib tutorial. See also this violin plot tutorial. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"sections","url":"sections/sec_3/"},{"title":"S-Section 03: Multiple Linear and Polynomial  Regression","text":"Jupyter Notebooks S-Section 3: Multiple Linear Regression and Polynomial Regression","tags":"sections","url":"sections/section3/"},{"title":"Lab 4: Multiple and Polynomial Regression","text":"Jupyter Notebooks Lab 4: Multiple and Polynomial Regression Lab 4: Multiple and Polynomial Regression (solutions) Slides Lab 4 Slides: Multiple and Polynomial Regression (PPTX) Lab 4 Slides: Multiple and Polynomial Regression (PDF)","tags":"labs","url":"labs/lab04/"},{"title":"Lab 04: Multiple and Polynomial Regression","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS-109A Introduction to Data Science Lab 4: Multiple and Polynomial Regression (September 26, 2019 version) Harvard University Fall 2019 Instructors: Pavlos Protopapas, Kevin Rader, and Chris Tanner Lab Instructor: Chris Tanner and Eleni Kaxiras Authors: Rahul Dave, David Sondak, Will Claybaugh, Pavlos Protopapas, Chris Tanner In [1]: ## RUN THIS CELL TO GET THE RIGHT FORMATTING import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } span.sub-q { font-weight: bold; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Table of Contents Learning Goals / Tip of the Week / Terminology Training/Validation/Testing Splits (slides + interactive warm-up) Polynomial Regression, and Revisiting the Cab Data Multiple regression and exploring the Football data A nice trick for forward-backwards Cross-validation Learning Goals After this lab, you should be able to Explain the difference between train/validation/test data and WHY we have each. Implement cross-validation on a dataset Implement arbitrary multiple regression models in both SK-learn and Statsmodels. Interpret the coefficent estimates produced by each model, including transformed and dummy variables In [2]: import numpy as np import pandas as pd import matplotlib.pyplot as plt import statsmodels.api as sm from statsmodels.api import OLS from sklearn import preprocessing from sklearn.preprocessing import PolynomialFeatures from sklearn.metrics import r2_score from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from pandas.plotting import scatter_matrix import seaborn as sns % matplotlib inline Extra Tip of the Week Within your terminal (aka console aka command prompt), most shell environments support useful shortcuts: press the [up arrow] to navigate through your most recent commands press [CTRL + A] to go to the beginning of the line press [CTRL + E] to go to the end of the line press [CTRL + K] to clear the line type `history` to see the last commands you've run Terminology Say we have input features $X$, which via some function $f()$, approximates outputs $Y$. That is, $Y = f(X) + \\epsilon$ (where $\\epsilon$ represents our unmeasurable variation (i.e., irreducible error). Inference : estimates the function $f$, but the goal isn't to make predictions for $Y$; rather, it is more concerned with understanding the relationship between $X$ and $Y$. Prediction : estimates the function $f$ with the goal of making accurate $Y$ predictions for some unseen $X$. We have recently used two highly popular, useful libraries, statsmodels and sklearn . statsmodels is mostly focused on the inference task. It aims to make good estimates for $f()$ (via solving for our $\\beta$'s), and it provides expansive details about its certainty. It provides lots of tools to discuss confidence, but isn't great at dealing with test sets. sklearn is mostly focused on the prediction task. It aims to make a well-fit line to our input data $X$, so as to make good $Y$ predictions for some unseen inputs $X$. It provides a shallower analysis of our variables. In other words, sklearn is great at test sets and validations, but it can't really discuss uncertainty in the parameters or predictions. R-squared : An interpretable summary of how well the model did. 1 is perfect, 0 is a trivial baseline model based on the mean $y$ value, and negative is worse than the trivial model. F-statistic : A value testing whether we're likely to see these results (or even stronger ones) if none of the predictors actually mattered. Prob (F-statistic) : The probability that we'd see these results (or even stronger ones) if none of the predictors actually mattered. If this probability is small then either A) some combination of predictors actually matters or B) something rather unlikely has happened coef : The estimate of each beta. This has several sub-components: std err : The amount we'd expect this value to wiggle if we re-did the data collection and re-ran our model. More data tends to make this wiggle smaller, but sometimes the collected data just isn't enough to pin down a particular value. t and P>|t| : similar to the F-statistic, these measure the probability of seeing coefficients this big (or even bigger) if the given variable didn't actually matter. Small probability doesn't necessarily mean the value matters [0.025 0.975] : Endpoints of the 95% confidence interval. This is a interval drawn in a clever way and which gives an idea of where the true beta value might plausibly live. (If you want to understand why \"there's a 95% chance the true beta is in the interval\" is wrong , start a chat with Will : ) Part 2: Polynomial Regression, and Revisiting the Cab Data Polynomial regression uses a linear model to estimate a non-linear function (i.e., a function with polynomial terms). For example: $y = \\beta_0 + \\beta_1x_i + \\beta_1x_i&#94;{2}$ It is a linear model because we are still solving a linear equation (the linear aspect refers to the beta coefficients). In [3]: # read in the data, break into train and test cab_df = pd . read_csv ( \"../data/dataset_1.txt\" ) train_data , test_data = train_test_split ( cab_df , test_size =. 2 , random_state = 42 ) cab_df . head () Out[3]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } TimeMin PickupCount 0 860.0 33.0 1 17.0 75.0 2 486.0 13.0 3 300.0 5.0 4 385.0 10.0 In [4]: cab_df . shape Out[4]: (1250, 2) In [5]: # do some data cleaning X_train = train_data [ 'TimeMin' ] . values . reshape ( - 1 , 1 ) / 60 # transforms it to being hour-based y_train = train_data [ 'PickupCount' ] . values X_test = test_data [ 'TimeMin' ] . values . reshape ( - 1 , 1 ) / 60 # hour-based y_test = test_data [ 'PickupCount' ] . values def plot_cabs ( cur_model , poly_transformer = None ): # build the x values for the prediction line x_vals = np . arange ( 0 , 24 , . 1 ) . reshape ( - 1 , 1 ) # optionally use the passed-in transformer if poly_transformer != None : dm = poly_transformer . fit_transform ( x_vals ) else : dm = x_vals # make the prediction at each x value prediction = cur_model . predict ( dm ) # plot the prediction line, and the test data plt . plot ( x_vals , prediction , color = 'k' , label = \"Prediction\" ) plt . scatter ( X_test , y_test , label = \"Test Data\" ) # label your plots plt . ylabel ( \"Number of Taxi Pickups\" ) plt . xlabel ( \"Time of Day (Hours Past Midnight)\" ) plt . legend () plt . show () In [6]: from sklearn.linear_model import LinearRegression fitted_cab_model0 = LinearRegression () . fit ( X_train , y_train ) plot_cabs ( fitted_cab_model0 ) In [7]: fitted_cab_model0 . score ( X_test , y_test ) Out[7]: 0.240661535615741 Exercise Questions : The above code uses sklearn . As more practice, and to help you stay versed in both libraries, perform the same task (fit a linear regression line) using statsmodels and report the $r&#94;2$ score. Is it the same value as what sklearn reports, and is this the expected behavior? In [9]: #### EXERCISE: write code here (feel free to work with a partner) We can see that there's still a lot of variation in cab pickups that's not being captured by a linear fit. Further, the linear fit is predicting massively more pickups at 11:59pm than at 12:00am. This is a bad property, and it's the conseqeuence of having a straight line with a non-zero slope. However, we can add columns to our data for $TimeMin&#94;2$ and $TimeMin&#94;3$ and so on, allowing a curvy polynomial line to hopefully fit the data better. We'll be using sklearn 's PolynomialFeatures() function to take some of the tedium out of building the expanded input data. In fact, if all we want is a formula like $y \\approx \\beta_0 + \\beta_1 x + \\beta_2 x&#94;2 + ...$, it will directly return a new copy of the data in this format! In [10]: transformer_3 = PolynomialFeatures ( 3 , include_bias = False ) expanded_train = transformer_3 . fit_transform ( X_train ) # TRANSFORMS it to polynomial features pd . DataFrame ( expanded_train ) . describe () # notice that the columns now contain x, x&#94;2, x&#94;3 values Out[10]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 count 1000.000000 1000.000000 1000.000000 mean 11.717217 182.833724 3234.000239 std 6.751751 167.225711 3801.801966 min 0.066667 0.004444 0.000296 25% 6.100000 37.210833 226.996222 50% 11.375000 129.390694 1471.820729 75% 17.437500 304.066458 5302.160684 max 23.966667 574.401111 13766.479963 A few notes on PolynomialFeatures : The interface is a bit strange. PolynomialFeatures is a 'transformer' in sklearn. We'll be using several transformers that learn a transformation on the training data, and then we will apply those transformations on future data. With PolynomialFeatures, the .fit() is pretty trivial, and we often fit and transform in one command, as seen above with `.fit_transform() . You rarely want to include_bias (a column of all 1's), since sklearn will add it automatically. Remember, when using statsmodels, you can just .add_constant() right before you fit the data. If you want polynomial features for a several different variables (i.e., multinomial regression), you should call .fit_transform() separately on each column and append all the results to a copy of the data (unless you also want interaction terms between the newly-created features). See np.concatenate() for joining arrays. In [11]: fitted_cab_model3 = LinearRegression () . fit ( expanded_train , y_train ) print ( \"fitting expanded_train:\" , expanded_train ) plot_cabs ( fitted_cab_model3 , transformer_3 ) fitting expanded_train: [[6.73333333e+00 4.53377778e+01 3.05274370e+02] [2.18333333e+00 4.76694444e+00 1.04078287e+01] [1.41666667e+00 2.00694444e+00 2.84317130e+00] ... [1.96666667e+01 3.86777778e+02 7.60662963e+03] [1.17333333e+01 1.37671111e+02 1.61534104e+03] [1.42000000e+01 2.01640000e+02 2.86328800e+03]] Exercise Questions : Calculate the polynomial model's $R&#94;2$ performance on the test set. Does the polynomial model improve on the purely linear model? Make a residual plot for the polynomial model. What does this plot tell us about the model? In [12]: # ANSWER 1 expanded_test = transformer_3 . fit_transform ( X_test ) print ( \"Test R-squared:\" , fitted_cab_model3 . score ( expanded_test , y_test )) # NOTE 1: unlike statsmodels' r2_score() function, sklearn has a .score() function # NOTE 2: fit_transform() is a nifty function that transforms the data, then fits it Test R-squared: 0.33412512570778774 In [13]: # ANSWER 2: does it? In [14]: # ANSWER 3 (class discussion about the residuals) x_matrix = transformer_3 . fit_transform ( X_train ) prediction = fitted_cab_model3 . predict ( x_matrix ) residual = y_train - prediction plt . scatter ( X_train , residual , label = \"Residual\" ) plt . axhline ( 0 , color = 'k' ) plt . title ( \"Residuals for the Cubic Model\" ) plt . ylabel ( \"Residual Number of Taxi Pickups\" ) plt . xlabel ( \"Time of Day (Hours Past Midnight)\" ) plt . legend () Out[14]: Other features Polynomial features are not the only constucted features that help fit the data. Because these data have a 24 hour cycle, we may want to build features that follow such a cycle. For example, $sin(24\\frac{x}{2\\pi})$, $sin(12\\frac{x}{2\\pi})$, $sin(8\\frac{x}{2\\pi})$. Other feature transformations are appropriate to other types of data. For instance certain feature transformations have been developed for geographical data. Scaling Features When using polynomials, we are explicitly trying to use the higher-order values for a given feature. However, sometimes these polynomial features can take on values that are drastically large, making it difficult for the system to learn an appropriate bias weight due to its large values and potentially large variance. To counter this, sometimes one may be interested in scaling the values for a given feature. For our ongoing taxi-pickup example, using polynomial features improved our model. If we wished to scale the features, we could use sklearn 's StandardScaler() function: In [15]: # SCALES THE EXPANDED/POLY TRANSFORMED DATA # we don't need to convert to a pandas dataframe, but it can be useful for scaling select columns train_copy = pd . DataFrame ( expanded_train . copy ()) test_copy = pd . DataFrame ( expanded_test . copy ()) # Fit the scaler on the training data scaler = StandardScaler () . fit ( train_copy ) # Scale both the test and training data. train_scaled = scaler . transform ( expanded_train ) test_scaled = scaler . transform ( expanded_test ) # we could optionally run a new regression model on this scaled data fitted_scaled_cab = LinearRegression () . fit ( train_scaled , y_train ) fitted_scaled_cab . score ( test_scaled , y_test ) Out[15]: 0.33412512570778274 Part 3: Multiple regression and exploring the Football (aka soccer) data Let's move on to a different dataset! The data imported below were scraped by Shubham Maurya and record various facts about players in the English Premier League. Our goal will be to fit models that predict the players' market value (what the player could earn when hired by a new team), as estimated by https://www.transfermarkt.us . name : Name of the player club : Club of the player age : Age of the player position : The usual position on the pitch position_cat : 1 for attackers, 2 for midfielders, 3 for defenders, 4 for goalkeepers market_value : As on transfermrkt.com on July 20th, 2017 page_views : Average daily Wikipedia page views from September 1, 2016 to May 1, 2017 fpl_value : Value in Fantasy Premier League as on July 20th, 2017 fpl_sel : % of FPL players who have selected that player in their team fpl_points : FPL points accumulated over the previous season region : 1 for England, 2 for EU, 3 for Americas, 4 for Rest of World nationality : Player's nationality new_foreign : Whether a new signing from a different league, for 2017/18 (till 20th July) age_cat : a categorical version of the Age feature club_id : a numerical version of the Club feature big_club : Whether one of the Top 6 clubs new_signing : Whether a new signing for 2017/18 (till 20th July) As always, we first import, verify, split, and explore the data. Part 3.1: Import and verification and grouping In [16]: league_df = pd . read_csv ( \"../data/league_data.txt\" ) print ( league_df . dtypes ) # QUESTION: what would you guess is the mean age? mean salary? #league_df.head() name object club object age int64 position object position_cat int64 market_value float64 page_views int64 fpl_value float64 fpl_sel object fpl_points int64 region float64 nationality object new_foreign int64 age_cat int64 club_id int64 big_club int64 new_signing int64 dtype: object In [17]: league_df . shape Out[17]: (461, 17) In [18]: #league_df.describe() (Stratified) train/test split We want to make sure that the training and test data have appropriate representation of each region; it would be bad for the training data to entirely miss a region. This is especially important because some regions are rather rare. Exercise Questions : Use the train_test_split() function, while (a) ensuring the test size is 20% of the data, and; (2) using 'stratify' argument to split the data (look up documentation online), keeping equal representation of each region. This doesn't work by default, correct? What is the issue? Deal with the issue you encountered above. Hint: you may find numpy's .isnan() and panda's .dropna() functions useful! How did you deal with the error generated by train_test_split ? How did you justify your action? your answer here : In [33]: # EXERCISE: feel free to work with a partner In [25]: train_data . shape , test_data . shape Out[25]: ((1000, 2), (250, 2)) Now that we won't be peeking at the test set, let's explore and look for patterns! We'll introduce a number of useful pandas and numpy functions along the way. Groupby Pandas' .groupby() function is a wonderful tool for data analysis. It allows us to analyze each of several subgroups. Many times, .groupby() is combined with .agg() to get a summary statistic for each subgroup. For instance: What is the average market value, median page views, and maximum fpl for each player position? In [23]: train_data . groupby ( 'position' ) . agg ({ 'market_value' : np . mean , 'page_views' : np . median , 'fpl_points' : np . max }) --------------------------------------------------------------------------- KeyError Traceback (most recent call last) in ----> 1 train_data.groupby('position').agg({ 2 'market_value' : np . mean , 3 'page_views' : np . median , 4 'fpl_points' : np . max 5 }) /usr/local/lib/python3.7/site-packages/pandas/core/generic.py in groupby (self, by, axis, level, as_index, sort, group_keys, squeeze, observed, **kwargs) 7894 squeeze = squeeze , 7895 observed = observed , -> 7896 ** kwargs 7897 ) 7898 /usr/local/lib/python3.7/site-packages/pandas/core/groupby/groupby.py in groupby (obj, by, **kwds) 2476 raise TypeError ( \"invalid type: {}\" . format ( obj ) ) 2477 -> 2478 return klass ( obj , by , ** kwds ) /usr/local/lib/python3.7/site-packages/pandas/core/groupby/groupby.py in __init__ (self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, **kwargs) 389 sort = sort , 390 observed = observed , --> 391 mutated = self . mutated , 392 ) 393 /usr/local/lib/python3.7/site-packages/pandas/core/groupby/grouper.py in _get_grouper (obj, key, axis, level, sort, observed, mutated, validate) 619 in_axis , name , level , gpr = False , None , gpr , None 620 else : --> 621 raise KeyError ( gpr ) 622 elif isinstance ( gpr , Grouper ) and gpr . key is not None : 623 # Add key to exclusions KeyError : 'position' In [22]: train_data . position . unique () --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) in ----> 1 train_data . position . unique ( ) /usr/local/lib/python3.7/site-packages/pandas/core/generic.py in __getattr__ (self, name) 5178 if self . _info_axis . _can_hold_identifiers_and_holds_name ( name ) : 5179 return self [ name ] -> 5180 return object . __getattribute__ ( self , name ) 5181 5182 def __setattr__ ( self , name , value ) : AttributeError : 'DataFrame' object has no attribute 'position' In [26]: train_data . groupby ([ 'big_club' , 'position' ]) . agg ({ 'market_value' : np . mean , 'page_views' : np . mean , 'fpl_points' : np . mean }) --------------------------------------------------------------------------- KeyError Traceback (most recent call last) in ----> 1 train_data.groupby(['big_club', 'position']).agg({ 2 'market_value' : np . mean , 3 'page_views' : np . mean , 4 'fpl_points' : np . mean 5 }) /usr/local/lib/python3.7/site-packages/pandas/core/generic.py in groupby (self, by, axis, level, as_index, sort, group_keys, squeeze, observed, **kwargs) 7894 squeeze = squeeze , 7895 observed = observed , -> 7896 ** kwargs 7897 ) 7898 /usr/local/lib/python3.7/site-packages/pandas/core/groupby/groupby.py in groupby (obj, by, **kwds) 2476 raise TypeError ( \"invalid type: {}\" . format ( obj ) ) 2477 -> 2478 return klass ( obj , by , ** kwds ) /usr/local/lib/python3.7/site-packages/pandas/core/groupby/groupby.py in __init__ (self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, **kwargs) 389 sort = sort , 390 observed = observed , --> 391 mutated = self . mutated , 392 ) 393 /usr/local/lib/python3.7/site-packages/pandas/core/groupby/grouper.py in _get_grouper (obj, key, axis, level, sort, observed, mutated, validate) 619 in_axis , name , level , gpr = False , None , gpr , None 620 else : --> 621 raise KeyError ( gpr ) 622 elif isinstance ( gpr , Grouper ) and gpr . key is not None : 623 # Add key to exclusions KeyError : 'big_club' Exercise Question : Notice that the .groupby() function above takes a list of two column names. Does the order matter? What happens if we switch the two so that 'position' is listed before 'big_club'? In [27]: # EXERCISE: feel free to work with a partner Part 3.2: Linear regression on the football data This section of the lab focuses on fitting a model to the football (soccer) data and interpreting the model results. The model we'll use is $$\\text{market_value} \\approx \\beta_0 + \\beta_1\\text{fpl_points} + \\beta_2\\text{age} + \\beta_3\\text{age}&#94;2 + \\beta_4log_2\\left(\\text{page_views}\\right) + \\beta_5\\text{new_signing} +\\beta_6\\text{big_club} + \\beta_7\\text{position_cat}$$ We're including a 2nd degree polynomial in age because we expect pay to increase as a player gains experience, but then decrease as they continue aging. We're taking the log of page views because they have such a large, skewed range and the transformed variable will have fewer outliers that could bias the line. We choose the base of the log to be 2 just to make interpretation cleaner. Exercise Questions : Build the data and fit this model to it. How good is the overall model? Interpret the regression model. What is the meaning of the coefficient for: age and age$&#94;2$ $log_2($page_views$)$ big_club What should a player do in order to improve their market value? How many page views should a player go get to increase their market value by 10? In [29]: # Q1: we'll do most of it for you ... y_train = train_data [ 'market_value' ] y_test = test_data [ 'market_value' ] def build_football_data ( df ): x_matrix = df [[ 'fpl_points' , 'age' , 'new_signing' , 'big_club' , 'position_cat' ]] . copy () x_matrix [ 'log_views' ] = np . log2 ( df [ 'page_views' ]) # WRITE CODE FOR CREATING THE AGE SQUARED COLUMN #### # OPTIONALLY WRITE CODE to adjust the ordering of the columns, just so that it corresponds with the equation above #### # add a constant x_matrix = sm . add_constant ( x_matrix ) return x_matrix # use build_football_data() to transform both the train_data and test_data train_transformed = build_football_data ( train_data ) test_transformed = build_football_data ( test_data ) fitted_model_1 = OLS ( endog = y_train , exog = train_transformed , hasconst = True ) . fit () fitted_model_1 . summary () # WRITE CODE TO RUN r2_score(), then answer the above question about the overall goodness of the model --------------------------------------------------------------------------- KeyError Traceback (most recent call last) /usr/local/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc (self, key, method, tolerance) 2889 try : -> 2890 return self . _engine . get_loc ( key ) 2891 except KeyError : pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc () pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc () pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item () pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item () KeyError : 'market_value' During handling of the above exception, another exception occurred: KeyError Traceback (most recent call last) in 1 # Q1: we'll do most of it for you ... ----> 2 y_train = train_data [ 'market_value' ] 3 y_test = test_data [ 'market_value' ] 4 def build_football_data ( df ) : 5 x_matrix = df [ [ 'fpl_points' , 'age' , 'new_signing' , 'big_club' , 'position_cat' ] ] . copy ( ) /usr/local/lib/python3.7/site-packages/pandas/core/frame.py in __getitem__ (self, key) 2973 if self . columns . nlevels > 1 : 2974 return self . _getitem_multilevel ( key ) -> 2975 indexer = self . columns . get_loc ( key ) 2976 if is_integer ( indexer ) : 2977 indexer = [ indexer ] /usr/local/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc (self, key, method, tolerance) 2890 return self . _engine . get_loc ( key ) 2891 except KeyError : -> 2892 return self . _engine . get_loc ( self . _maybe_cast_indexer ( key ) ) 2893 indexer = self . get_indexer ( [ key ] , method = method , tolerance = tolerance ) 2894 if indexer . ndim > 1 or indexer . size > 1 : pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc () pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc () pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item () pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item () KeyError : 'market_value' In [31]: # Q2: let's use the age coefficients to show the effect of age has on one's market value; # we can get the age and age&#94;2 coefficients via: agecoef = fitted_model_1 . params . age age2coef = fitted_model_1 . params . age_squared # let's set our x-axis (corresponding to age) to be a wide range from -100 to 100, # just to see a grand picture of the function x_vals = np . linspace ( - 100 , 100 , 1000 ) y_vals = agecoef * x_vals + age2coef * x_vals ** 2 # WRITE CODE TO PLOT x_vals vs y_vals plt . plot ( x_vals , y_vals ) plt . title ( \"Effect of Age\" ) plt . xlabel ( \"Age\" ) plt . ylabel ( \"Contribution to Predicted Market Value\" ) plt . show () # Q2A: WHAT HAPPENS IF WE USED ONLY AGE (not AGE&#94;2) in our model (what's the r2?); make the same plot of age vs market value # Q2B: WHAT HAPPENS IF WE USED ONLY AGE&#94;2 (not age) in our model (what's the r2?); make the same plot of age&#94;2 vs market value # Q2C: PLOT page views vs market value # EXERCISE: WRITE CODE HERE --------------------------------------------------------------------------- NameError Traceback (most recent call last) in 1 # Q2: let's use the age coefficients to show the effect of age has on one's market value; 2 # we can get the age and age&#94;2 coefficients via: ----> 3 agecoef = fitted_model_1 . params . age 4 age2coef = fitted_model_1 . params . age_squared 5 NameError : name 'fitted_model_1' is not defined Part 3.3: Turning Categorical Variables into multiple binary variables Of course, we have an error in how we've included player position. Even though the variable is numeric (1,2,3,4) and the model runs without issue, the value we're getting back is garbage. The interpretation, such as it is, is that there is an equal effect of moving from position category 1 to 2, from 2 to 3, and from 3 to 4, and that this effect is probably between -0.5 to -1 (depending on your run). In reality, we don't expect moving from one position category to another to be equivalent, nor for a move from category 1 to category 3 to be twice as important as a move from category 1 to category 2. We need to introduce better features to model this variable. We'll use pd.get_dummies to do the work for us. In [ ]: train_design_recoded = pd . get_dummies ( train_transformed , columns = [ 'position_cat' ], drop_first = True ) test_design_recoded = pd . get_dummies ( test_transformed , columns = [ 'position_cat' ], drop_first = True ) train_design_recoded . head () We've removed the original position_cat column and created three new ones. Why only three new columns? Why does pandas give us the option to drop the first category? Exercise Questions : If we're fitting a model without a constant, should we have three dummy columns or four dummy columns? Fit a model on the new, recoded data, then interpret the coefficient of position_cat_2 . In [32]: # FEEL FREE ETO WORK WITH A PARTNER Answers : Part 4: A nice trick for forward-backwards XOR (operator &#94;) is a logical operation that only returns true when input differ. We can use it to implement forward-or-backwards selection when we want to keep track of whet predictors are \"left\" from a given list of predictors. The set analog is \"symmetric difference\". From the python docs: s.symmetric_difference(t) s &#94; t new set with elements in either s or t but not both In [ ]: set () &#94; set ([ 1 , 2 , 3 ]) In [ ]: set ([ 1 ]) &#94; set ([ 1 , 2 , 3 ]) In [ ]: set ([ 1 , 2 ]) &#94; set ([ 1 , 2 , 3 ]) Exercise Outline a step-forwards algorithm which uses this idea BONUS EXERCISE: We have provided a spreadsheet of Boston housing prices (data/boston_housing.csv). The 14 columns are as follows: CRIM: per capita crime rate by town ZN: proportion of residential land zoned for lots over 25,000 sq.ft. INDUS: proportion of non-retail business acres per town CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) NOX: nitric oxides concentration (parts per 10 million) 1 https://archive.ics.uci.edu/ml/datasets/Housing 123 20.2. Load the Dataset 124 RM: average number of rooms per dwelling AGE: proportion of owner-occupied units built prior to 1940 DIS: weighted distances to ﬁve Boston employment centers RAD: index of accessibility to radial highways TAX: full-value property-tax rate per \\$10,000 PTRATIO: pupil-teacher ratio by town B: 1000(Bk−0.63)2 where Bk is the proportion of blacks by town LSTAT: % lower status of the population MEDV: Median value of owner-occupied homes in $1000s We can see that the input attributes have a mixture of units There are 450 observations. Exercise Using the above file, try your best to predict housing prices. (the 14th column) We have provided a test set data/boston_housing_test.csv but refrain from looking at the file or evaluating on it until you have finalized and trained a model. Load in the data. It is tab-delimited. Quickly look at a summary of the data to familiarize yourself with it and ensure nothing is too egregious. Use a previously-discussed function to automatically partition the data into a training and validation (aka development) set. It is up to you to choose how large these two portions should be. Train a basic model on just a subset of the features. What is the performance on the validation set? Train a basic model on all of the features. What is the performance on the validation set? Toy with the model until you feel your results are reasonably good. Perform cross-validation with said model, and measure the average performance. Are the results what you expected? Were the average results better or worse than that from your original 1 validation set? Experiment with other models, and for each, perform 10-fold cross-validation. Which model yields the best average performance? Select this as your final model. Use this model to evaulate your performance on the testing set. What is your performance (MSE)? Is this what you expected? if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab04/notebook/"},{"title":"Lab 04: Multiple and Polynomial Regression","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS-109A Introduction to Data Science Lab 4: Multiple and Polynomial Regression (September 26, 2019 version) Harvard University Fall 2019 Instructors: Pavlos Protopapas, Kevin Rader, and Chris Tanner Lab Instructor: Chris Tanner and Eleni Kaxiras Authors: Rahul Dave, David Sondak, Will Claybaugh, Pavlos Protopapas, Chris Tanner In [2]: ## RUN THIS CELL TO GET THE RIGHT FORMATTING import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\" ) . text HTML ( styles ) --------------------------------------------------------------------------- gaierror Traceback (most recent call last) /usr/local/lib/python3.7/site-packages/urllib3/connection.py in _new_conn (self) 159 conn = connection.create_connection( --> 160 (self._dns_host, self.port), self.timeout, **extra_kw) 161 /usr/local/lib/python3.7/site-packages/urllib3/util/connection.py in create_connection (address, timeout, source_address, socket_options) 56 ---> 57 for res in socket . getaddrinfo ( host , port , family , socket . SOCK_STREAM ) : 58 af , socktype , proto , canonname , sa = res /usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/socket.py in getaddrinfo (host, port, family, type, proto, flags) 747 addrlist = [ ] --> 748 for res in _socket . getaddrinfo ( host , port , family , type , proto , flags ) : 749 af , socktype , proto , canonname , sa = res gaierror : [Errno 8] nodename nor servname provided, or not known During handling of the above exception, another exception occurred: NewConnectionError Traceback (most recent call last) /usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py in urlopen (self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw) 602 body = body , headers = headers , --> 603 chunked=chunked) 604 /usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py in _make_request (self, conn, method, url, timeout, chunked, **httplib_request_kw) 343 try : --> 344 self . _validate_conn ( conn ) 345 except ( SocketTimeout , BaseSSLError ) as e : /usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py in _validate_conn (self, conn) 842 if not getattr ( conn , 'sock' , None ) : # AppEngine might not have `.sock` --> 843 conn . connect ( ) 844 /usr/local/lib/python3.7/site-packages/urllib3/connection.py in connect (self) 315 # Add certificate verification --> 316 conn = self . _new_conn ( ) 317 hostname = self . host /usr/local/lib/python3.7/site-packages/urllib3/connection.py in _new_conn (self) 168 raise NewConnectionError( --> 169 self, \"Failed to establish a new connection: %s\" % e) 170 NewConnectionError : : Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known During handling of the above exception, another exception occurred: MaxRetryError Traceback (most recent call last) /usr/local/lib/python3.7/site-packages/requests/adapters.py in send (self, request, stream, timeout, verify, cert, proxies) 448 retries = self . max_retries , --> 449 timeout = timeout 450 ) /usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py in urlopen (self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw) 640 retries = retries.increment(method, url, error=e, _pool=self, --> 641 _stacktrace=sys.exc_info()[2]) 642 retries . sleep ( ) /usr/local/lib/python3.7/site-packages/urllib3/util/retry.py in increment (self, method, url, response, error, _pool, _stacktrace) 398 if new_retry . is_exhausted ( ) : --> 399 raise MaxRetryError ( _pool , url , error or ResponseError ( cause ) ) 400 MaxRetryError : HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /Harvard-IACS/2018-CS109A/master/content/styles/cs109.css (Caused by NewConnectionError(' : Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')) During handling of the above exception, another exception occurred: ConnectionError Traceback (most recent call last) in 2 import requests 3 from IPython . core . display import HTML ----> 4 styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\" ) . text 5 HTML ( styles ) /usr/local/lib/python3.7/site-packages/requests/api.py in get (url, params, **kwargs) 73 74 kwargs . setdefault ( 'allow_redirects' , True ) ---> 75 return request ( 'get' , url , params = params , ** kwargs ) 76 77 /usr/local/lib/python3.7/site-packages/requests/api.py in request (method, url, **kwargs) 58 # cases, and look like a memory leak in others. 59 with sessions . Session ( ) as session : ---> 60 return session . request ( method = method , url = url , ** kwargs ) 61 62 /usr/local/lib/python3.7/site-packages/requests/sessions.py in request (self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json) 531 } 532 send_kwargs . update ( settings ) --> 533 resp = self . send ( prep , ** send_kwargs ) 534 535 return resp /usr/local/lib/python3.7/site-packages/requests/sessions.py in send (self, request, **kwargs) 644 645 # Send the request --> 646 r = adapter . send ( request , ** kwargs ) 647 648 # Total elapsed time of the request (approximately) /usr/local/lib/python3.7/site-packages/requests/adapters.py in send (self, request, stream, timeout, verify, cert, proxies) 514 raise SSLError ( e , request = request ) 515 --> 516 raise ConnectionError ( e , request = request ) 517 518 except ClosedPoolError as e : ConnectionError : HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /Harvard-IACS/2018-CS109A/master/content/styles/cs109.css (Caused by NewConnectionError(' : Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')) Table of Contents Learning Goals / Tip of the Week / Terminology Training/Validation/Testing Splits (slides + interactive warm-up) Polynomial Regression, and Revisiting the Cab Data Multiple regression and exploring the Football data A nice trick for forward-backwards Learning Goals After this lab, you should be able to Explain the difference between train/validation/test data and WHY we have each. Implement cross-validation on a dataset Implement arbitrary multiple regression models in both SK-learn and Statsmodels. Interpret the coefficent estimates produced by each model, including transformed and dummy variables In [3]: import numpy as np import pandas as pd import matplotlib.pyplot as plt import statsmodels.api as sm from statsmodels.api import OLS from sklearn import preprocessing from sklearn.preprocessing import PolynomialFeatures from sklearn.metrics import r2_score from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from pandas.plotting import scatter_matrix import seaborn as sns % matplotlib inline Extra Tip of the Week Within your terminal (aka console aka command prompt), most shell environments support useful shortcuts: press the [up arrow] to navigate through your most recent commands press [CTRL + A] to go to the beginning of the line press [CTRL + E] to go to the end of the line press [CTRL + K] to clear the line type `history` to see the last commands you've run Terminology Say we have input features $X$, which via some function $f()$, approximates outputs $Y$. That is, $Y = f(X) + \\epsilon$ (where $\\epsilon$ represents our unmeasurable variation (i.e., irreducible error). Inference : estimates the function $f$, but the goal isn't to make predictions for $Y$; rather, it is more concerned with understanding the relationship between $X$ and $Y$. Prediction : estimates the function $f$ with the goal of making accurate $Y$ predictions for some unseen $X$. We have recently used two highly popular, useful libraries, statsmodels and sklearn . statsmodels is mostly focused on the inference task. It aims to make good estimates for $f()$ (via solving for our $\\beta$'s), and it provides expansive details about its certainty. It provides lots of tools to discuss confidence, but isn't great at dealing with test sets. sklearn is mostly focused on the prediction task. It aims to make a well-fit line to our input data $X$, so as to make good $Y$ predictions for some unseen inputs $X$. It provides a shallower analysis of our variables. In other words, sklearn is great at test sets and validations, but it can't really discuss uncertainty in the parameters or predictions. R-squared : An interpretable summary of how well the model did. 1 is perfect, 0 is a trivial baseline model based on the mean $y$ value, and negative is worse than the trivial model. F-statistic : A value testing whether we're likely to see these results (or even stronger ones) if none of the predictors actually mattered. Prob (F-statistic) : The probability that we'd see these results (or even stronger ones) if none of the predictors actually mattered. If this probability is small then either A) some combination of predictors actually matters or B) something rather unlikely has happened coef : The estimate of each beta. This has several sub-components: std err : The amount we'd expect this value to wiggle if we re-did the data collection and re-ran our model. More data tends to make this wiggle smaller, but sometimes the collected data just isn't enough to pin down a particular value. t and P>|t| : similar to the F-statistic, these measure the probability of seeing coefficients this big (or even bigger) if the given variable didn't actually matter. Small probability doesn't necessarily mean the value matters [0.025 0.975] : Endpoints of the 95% confidence interval. This is a interval drawn in a clever way and which gives an idea of where the true beta value might plausibly live. (If you want to understand why \"there's a 95% chance the true beta is in the interval\" is wrong , start a chat with Will : ) Part 2: Polynomial Regression, and Revisiting the Cab Data Polynomial regression uses a linear model to estimate a non-linear function (i.e., a function with polynomial terms). For example: $y = \\beta_0 + \\beta_1x_i + \\beta_1x_i&#94;{2}$ It is a linear model because we are still solving a linear equation (the linear aspect refers to the beta coefficients). In [4]: # read in the data, break into train and test cab_df = pd . read_csv ( \"../data/dataset_1.txt\" ) train_data , test_data = train_test_split ( cab_df , test_size =. 2 , random_state = 42 ) cab_df . head () Out[4]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } TimeMin PickupCount 0 860.0 33.0 1 17.0 75.0 2 486.0 13.0 3 300.0 5.0 4 385.0 10.0 In [5]: cab_df . shape Out[5]: (1250, 2) In [6]: # do some data cleaning X_train = train_data [ 'TimeMin' ] . values . reshape ( - 1 , 1 ) / 60 # transforms it to being hour-based y_train = train_data [ 'PickupCount' ] . values X_test = test_data [ 'TimeMin' ] . values . reshape ( - 1 , 1 ) / 60 # hour-based y_test = test_data [ 'PickupCount' ] . values def plot_cabs ( cur_model , poly_transformer = None ): # build the x values for the prediction line x_vals = np . arange ( 0 , 24 , . 1 ) . reshape ( - 1 , 1 ) # optionally use the passed-in transformer if poly_transformer != None : dm = poly_transformer . fit_transform ( x_vals ) else : dm = x_vals # make the prediction at each x value prediction = cur_model . predict ( dm ) # plot the prediction line, and the test data plt . plot ( x_vals , prediction , color = 'k' , label = \"Prediction\" ) plt . scatter ( X_test , y_test , label = \"Test Data\" ) # label your plots plt . ylabel ( \"Number of Taxi Pickups\" ) plt . xlabel ( \"Time of Day (Hours Past Midnight)\" ) plt . legend () plt . show () In [7]: from sklearn.linear_model import LinearRegression fitted_cab_model0 = LinearRegression () . fit ( X_train , y_train ) plot_cabs ( fitted_cab_model0 ) In [8]: fitted_cab_model0 . score ( X_test , y_test ) Out[8]: 0.240661535615741 Exercise Questions : The above code uses sklearn . As more practice, and to help you stay versed in both libraries, perform the same task (fit a linear regression line) using statsmodels and report the $r&#94;2$ score. Is it the same value as what sklearn reports, and is this the expected behavior? In [9]: ### SOLUTION: # augment the data with a column vector of 1's train_data_augmented = sm . add_constant ( X_train ) test_data_augmented = sm . add_constant ( X_test ) # fit the model on the training data OLSModel = OLS ( train_data [ 'PickupCount' ] . values , train_data_augmented ) . fit () # get the prediction results ols_predicted_pickups_test = OLSModel . predict ( test_data_augmented ) r2_score_test = r2_score ( test_data [[ 'PickupCount' ]] . values , ols_predicted_pickups_test ) print ( r2_score_test ) 0.240661535615741 We can see that there's still a lot of variation in cab pickups that's not being captured by a linear fit. Further, the linear fit is predicting massively more pickups at 11:59pm than at 12:00am. This is a bad property, and it's the conseqeuence of having a straight line with a non-zero slope. However, we can add columns to our data for $TimeMin&#94;2$ and $TimeMin&#94;3$ and so on, allowing a curvy polynomial line to hopefully fit the data better. We'll be using sklearn 's PolynomialFeatures() function to take some of the tedium out of building the expanded input data. In fact, if all we want is a formula like $y \\approx \\beta_0 + \\beta_1 x + \\beta_2 x&#94;2 + ...$, it will directly return a new copy of the data in this format! In [10]: transformer_3 = PolynomialFeatures ( 3 , include_bias = False ) expanded_train = transformer_3 . fit_transform ( X_train ) # TRANSFORMS it to polynomial features pd . DataFrame ( expanded_train ) . describe () # notice that the columns now contain x, x&#94;2, x&#94;3 values Out[10]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 count 1000.000000 1000.000000 1000.000000 mean 11.717217 182.833724 3234.000239 std 6.751751 167.225711 3801.801966 min 0.066667 0.004444 0.000296 25% 6.100000 37.210833 226.996222 50% 11.375000 129.390694 1471.820729 75% 17.437500 304.066458 5302.160684 max 23.966667 574.401111 13766.479963 A few notes on PolynomialFeatures : The interface is a bit strange. PolynomialFeatures is a 'transformer' in sklearn. We'll be using several transformers that learn a transformation on the training data, and then we will apply those transformations on future data. With PolynomialFeatures, the .fit() is pretty trivial, and we often fit and transform in one command, as seen above with `.fit_transform() . You rarely want to include_bias (a column of all 1's), since sklearn will add it automatically. Remember, when using statsmodels, you can just .add_constant() right before you fit the data. If you want polynomial features for a several different variables (i.e., multinomial regression), you should call .fit_transform() separately on each column and append all the results to a copy of the data (unless you also want interaction terms between the newly-created features). See np.concatenate() for joining arrays. In [11]: fitted_cab_model3 = LinearRegression () . fit ( expanded_train , y_train ) print ( \"fitting expanded_train:\" , expanded_train ) plot_cabs ( fitted_cab_model3 , transformer_3 ) fitting expanded_train: [[6.73333333e+00 4.53377778e+01 3.05274370e+02] [2.18333333e+00 4.76694444e+00 1.04078287e+01] [1.41666667e+00 2.00694444e+00 2.84317130e+00] ... [1.96666667e+01 3.86777778e+02 7.60662963e+03] [1.17333333e+01 1.37671111e+02 1.61534104e+03] [1.42000000e+01 2.01640000e+02 2.86328800e+03]] Exercise Questions : Calculate the polynomial model's $R&#94;2$ performance on the test set. Does the polynomial model improve on the purely linear model? Make a residual plot for the polynomial model. What does this plot tell us about the model? In [12]: # ANSWER 1 expanded_test = transformer_3 . fit_transform ( X_test ) print ( \"Test R-squared:\" , fitted_cab_model3 . score ( expanded_test , y_test )) # NOTE 1: unlike statsmodels' r2_score() function, sklearn has a .score() function # NOTE 2: fit_transform() is a nifty function that transforms the data, then fits it Test R-squared: 0.33412512570778774 In [13]: # ANSWER 2: yes it does. In [14]: # ANSWER 3 (class discussion about the residuals) x_matrix = transformer_3 . fit_transform ( X_train ) prediction = fitted_cab_model3 . predict ( x_matrix ) residual = y_train - prediction plt . scatter ( X_train , residual , label = \"Residual\" ) plt . axhline ( 0 , color = 'k' ) plt . title ( \"Residuals for the Cubic Model\" ) plt . ylabel ( \"Residual Number of Taxi Pickups\" ) plt . xlabel ( \"Time of Day (Hours Past Midnight)\" ) plt . legend () Out[14]: Other features Polynomial features are not the only constucted features that help fit the data. Because these data have a 24 hour cycle, we may want to build features that follow such a cycle. For example, $sin(24\\frac{x}{2\\pi})$, $sin(12\\frac{x}{2\\pi})$, $sin(8\\frac{x}{2\\pi})$. Other feature transformations are appropriate to other types of data. For instance certain feature transformations have been developed for geographical data. Scaling Features When using polynomials, we are explicitly trying to use the higher-order values for a given feature. However, sometimes these polynomial features can take on values that are drastically large, making it difficult for the system to learn an appropriate bias weight due to its large values and potentially large variance. To counter this, sometimes one may be interested in scaling the values for a given feature. For our ongoing taxi-pickup example, using polynomial features improved our model. If we wished to scale the features, we could use sklearn 's StandardScaler() function: In [15]: # SCALES THE EXPANDED/POLY TRANSFORMED DATA # we don't need to convert to a pandas dataframe, but it can be useful for scaling select columns train_copy = pd . DataFrame ( expanded_train . copy ()) test_copy = pd . DataFrame ( expanded_test . copy ()) # Fit the scaler on the training data scaler = StandardScaler () . fit ( train_copy ) # Scale both the test and training data. train_scaled = scaler . transform ( expanded_train ) test_scaled = scaler . transform ( expanded_test ) # we could optionally run a new regression model on this scaled data fitted_scaled_cab = LinearRegression () . fit ( train_scaled , y_train ) fitted_scaled_cab . score ( test_scaled , y_test ) Out[15]: 0.33412512570778274 Part 3: Multiple regression and exploring the Football (aka soccer) data Let's move on to a different dataset! The data imported below were scraped by Shubham Maurya and record various facts about players in the English Premier League. Our goal will be to fit models that predict the players' market value (what the player could earn when hired by a new team), as estimated by https://www.transfermarkt.us . name : Name of the player club : Club of the player age : Age of the player position : The usual position on the pitch position_cat : 1 for attackers, 2 for midfielders, 3 for defenders, 4 for goalkeepers market_value : As on www.transfermarkt.us.on July 20th, 2017 page_views : Average daily Wikipedia page views from September 1, 2016 to May 1, 2017 fpl_value : Value in Fantasy Premier League as on July 20th, 2017 fpl_sel : % of FPL players who have selected that player in their team fpl_points : FPL points accumulated over the previous season region : 1 for England, 2 for EU, 3 for Americas, 4 for Rest of World nationality : Player's nationality new_foreign : Whether a new signing from a different league, for 2017/18 (till 20th July) age_cat : a categorical version of the Age feature club_id : a numerical version of the Club feature big_club : Whether one of the Top 6 clubs new_signing : Whether a new signing for 2017/18 (till 20th July) As always, we first import, verify, split, and explore the data. Part 3.1: Import and verification and grouping In [23]: league_df = pd . read_csv ( \"../data/league_data.txt\" ) print ( league_df . dtypes ) # QUESTION: what would you guess is the mean age? mean salary? league_df . head () # turns out, it's a lot name object club object age int64 position object position_cat int64 market_value float64 page_views int64 fpl_value float64 fpl_sel object fpl_points int64 region float64 nationality object new_foreign int64 age_cat int64 club_id int64 big_club int64 new_signing int64 dtype: object Out[23]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name club age position position_cat market_value page_views fpl_value fpl_sel fpl_points region nationality new_foreign age_cat club_id big_club new_signing 0 Alexis Sanchez Arsenal 28 LW 1 65.0 4329 12.0 17.10% 264 3.0 Chile 0 4 1 1 0 1 Mesut Ozil Arsenal 28 AM 1 50.0 4395 9.5 5.60% 167 2.0 Germany 0 4 1 1 0 2 Petr Cech Arsenal 35 GK 4 7.0 1529 5.5 5.90% 134 2.0 Czech Republic 0 6 1 1 0 3 Theo Walcott Arsenal 28 RW 1 20.0 2393 7.5 1.50% 122 1.0 England 0 4 1 1 0 4 Laurent Koscielny Arsenal 31 CB 3 22.0 912 6.0 0.70% 121 2.0 France 0 4 1 1 0 In [17]: league_df . shape Out[17]: (461, 17) In [18]: league_df . describe () Out[18]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } age position_cat market_value page_views fpl_value fpl_points region new_foreign age_cat club_id big_club new_signing count 461.000000 461.000000 461.000000 461.000000 461.000000 461.000000 460.000000 461.000000 461.000000 461.000000 461.000000 461.000000 mean 26.804772 2.180043 11.012039 763.776573 5.447939 57.314534 1.993478 0.034707 3.206074 10.334056 0.303688 0.145336 std 3.961892 1.000061 12.257403 931.805757 1.346695 53.113811 0.957689 0.183236 1.279795 5.726475 0.460349 0.352822 min 17.000000 1.000000 0.050000 3.000000 4.000000 0.000000 1.000000 0.000000 1.000000 1.000000 0.000000 0.000000 25% 24.000000 1.000000 3.000000 220.000000 4.500000 5.000000 1.000000 0.000000 2.000000 6.000000 0.000000 0.000000 50% 27.000000 2.000000 7.000000 460.000000 5.000000 51.000000 2.000000 0.000000 3.000000 10.000000 0.000000 0.000000 75% 30.000000 3.000000 15.000000 896.000000 5.500000 94.000000 2.000000 0.000000 4.000000 15.000000 1.000000 0.000000 max 38.000000 4.000000 75.000000 7664.000000 12.500000 264.000000 4.000000 1.000000 6.000000 20.000000 1.000000 1.000000 (Stratified) train/test split We want to make sure that the training and test data have appropriate representation of each region; it would be bad for the training data to entirely miss a region. This is especially important because some regions are rather rare. Exercise Questions : Use the train_test_split() function, while (a) ensuring the test size is 20% of the data, and; (2) using 'stratify' argument to split the data (look up documentation online), keeping equal representation of each region. This doesn't work by default, correct? What is the issue? Deal with the issue you encountered above. Hint: you may find numpy's .isnan() and panda's .dropna() functions useful! How did you deal with the error generated by train_test_split ? How did you justify your action? In [38]: ### SOLUTION: try : # Doesn't work: a value is missing train_data , test_data = train_test_split ( league_df , test_size = 0.2 , stratify = league_df [ 'region' ]) except : # Count the missing lines and drop them missing_rows = np . isnan ( league_df [ 'region' ]) print ( \"Uh oh, {} lines missing data! Dropping them\" . format ( np . sum ( missing_rows ))) league_df = league_df . dropna ( subset = [ 'region' ]) train_data , test_data = train_test_split ( league_df , test_size = 0.2 , stratify = league_df [ 'region' ]) In [39]: train_data . shape , test_data . shape Out[39]: ((368, 17), (92, 17)) Now that we won't be peeking at the test set, let's explore and look for patterns! We'll introduce a number of useful pandas and numpy functions along the way. Groupby Pandas' .groupby() function is a wonderful tool for data analysis. It allows us to analyze each of several subgroups. Many times, .groupby() is combined with .agg() to get a summary statistic for each subgroup. For instance: What is the average market value, median page views, and maximum fpl for each player position? In [40]: train_data . groupby ( 'position' ) . agg ({ 'market_value' : np . mean , 'page_views' : np . median , 'fpl_points' : np . max }) Out[40]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } market_value page_views fpl_points position AM 29.557692 1434.0 218 CB 9.890972 387.5 178 CF 14.950000 748.0 224 CM 11.049020 425.0 139 DM 11.913793 478.0 131 GK 7.563514 436.0 149 LB 9.314815 385.0 177 LM 4.000000 325.5 99 LW 18.382609 766.0 264 RB 8.557692 281.5 170 RM 10.600000 566.0 105 RW 11.990741 504.0 162 SS 7.900000 997.0 178 In [41]: train_data . position . unique () Out[41]: array(['GK', 'CF', 'RW', 'CB', 'CM', 'LB', 'LM', 'DM', 'RB', 'RM', 'SS', 'LW', 'AM'], dtype=object) In [42]: train_data . groupby ([ 'big_club' , 'position' ]) . agg ({ 'market_value' : np . mean , 'page_views' : np . mean , 'fpl_points' : np . mean }) Out[42]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } market_value page_views fpl_points big_club position 0 AM 12.850000 485.800000 81.200000 CB 4.886170 328.723404 42.063830 CF 8.429688 841.875000 54.687500 CM 6.581081 360.486486 40.162162 DM 7.264706 424.058824 44.470588 GK 4.315217 385.652174 52.739130 LB 5.710526 270.631579 54.105263 LM 3.857143 349.142857 48.571429 LW 7.910714 528.071429 46.857143 RB 4.333333 300.277778 47.000000 RM 4.333333 280.333333 1.666667 RW 8.352273 560.727273 52.590909 SS 7.900000 2139.400000 60.200000 1 AM 40.000000 2446.125000 149.875000 CB 19.300000 936.680000 66.440000 CF 31.000000 2536.230769 102.153846 CM 22.857143 1801.785714 65.500000 DM 18.500000 1186.666667 63.333333 GK 12.900000 816.071429 63.500000 LB 17.875000 991.750000 77.750000 LM 5.000000 936.000000 26.000000 LW 34.672222 2505.222222 135.666667 RB 18.062500 1025.875000 102.000000 RM 20.000000 2028.000000 94.000000 RW 28.000000 1369.400000 85.200000 Exercise Question : Notice that the .groupby() function above takes a list of two column names. Does the order matter? What happens if we switch the two so that 'position' is listed before 'big_club'? In [43]: ### SOLUTION: train_data . groupby ([ 'position' , 'big_club' ]) . agg ({ 'market_value' : np . mean , 'page_views' : np . mean , 'fpl_points' : np . mean }) # in this case, our values are the same, as we are not aggregating anything differently; # however, our view / grouping is merely different. visually, it often makes most sense to # group such that the left-most (earlier) groupings have fewer distinct options than # the ones to the right of it, but it all depends on what you're trying to discern. Out[43]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } market_value page_views fpl_points position big_club AM 0 12.850000 485.800000 81.200000 1 40.000000 2446.125000 149.875000 CB 0 4.886170 328.723404 42.063830 1 19.300000 936.680000 66.440000 CF 0 8.429688 841.875000 54.687500 1 31.000000 2536.230769 102.153846 CM 0 6.581081 360.486486 40.162162 1 22.857143 1801.785714 65.500000 DM 0 7.264706 424.058824 44.470588 1 18.500000 1186.666667 63.333333 GK 0 4.315217 385.652174 52.739130 1 12.900000 816.071429 63.500000 LB 0 5.710526 270.631579 54.105263 1 17.875000 991.750000 77.750000 LM 0 3.857143 349.142857 48.571429 1 5.000000 936.000000 26.000000 LW 0 7.910714 528.071429 46.857143 1 34.672222 2505.222222 135.666667 RB 0 4.333333 300.277778 47.000000 1 18.062500 1025.875000 102.000000 RM 0 4.333333 280.333333 1.666667 1 20.000000 2028.000000 94.000000 RW 0 8.352273 560.727273 52.590909 1 28.000000 1369.400000 85.200000 SS 0 7.900000 2139.400000 60.200000 Part 3.2: Linear regression on the football data This section of the lab focuses on fitting a model to the football (soccer) data and interpreting the model results. The model we'll use is $$\\text{market_value} \\approx \\beta_0 + \\beta_1\\text{fpl_points} + \\beta_2\\text{age} + \\beta_3\\text{age}&#94;2 + \\beta_4log_2\\left(\\text{page_views}\\right) + \\beta_5\\text{new_signing} +\\beta_6\\text{big_club} + \\beta_7\\text{position_cat}$$ We're including a 2nd degree polynomial in age because we expect pay to increase as a player gains experience, but then decrease as they continue aging. We're taking the log of page views because they have such a large, skewed range and the transformed variable will have fewer outliers that could bias the line. We choose the base of the log to be 2 just to make interpretation cleaner. Exercise Questions : Build the data and fit this model to it. How good is the overall model? Interpret the regression model. What is the meaning of the coefficient for: age and age$&#94;2$ $log_2($page_views$)$ big_club What should a player do in order to improve their market value? How many page views should a player go get to increase their market value by 10? In [44]: # Q1: we'll do most of it for you ... y_train = train_data [ 'market_value' ] y_test = test_data [ 'market_value' ] def build_football_data ( df ): x_matrix = df [[ 'fpl_points' , 'age' , 'new_signing' , 'big_club' , 'position_cat' ]] . copy () x_matrix [ 'log_views' ] = np . log2 ( df [ 'page_views' ]) # CREATES THE AGE SQUARED COLUMN x_matrix [ 'age_squared' ] = df [ 'age' ] ** 2 # OPTIONALLY WRITE CODE to adjust the ordering of the columns, just so that it corresponds with the equation above x_matrix = x_matrix [[ 'fpl_points' , 'age' , 'age_squared' , 'log_views' , 'new_signing' , 'big_club' , 'position_cat' ]] # add a constant x_matrix = sm . add_constant ( x_matrix ) return x_matrix # use build_football_data() to transform both the train_data and test_data train_transformed = build_football_data ( train_data ) test_transformed = build_football_data ( test_data ) fitted_model_1 = OLS ( endog = y_train , exog = train_transformed , hasconst = True ) . fit () fitted_model_1 . summary () # WRITE CODE TO RUN r2_score(), then answer the above question about the overall goodness of the model r2_score ( y_test , fitted_model_1 . predict ( test_transformed )) # The model is reasonably good. We're capturing about 64%-69% of the variation in market values, # and the test set confirms that we're not overfitting too badly. /usr/local/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead. return ptp(axis=axis, out=out, **kwargs) Out[44]: 0.6139310215058921 In [45]: # Q2: let's use the age coefficients to show the effect of age has on one's market value; # we can get the age and age&#94;2 coefficients via: agecoef = fitted_model_1 . params . age age2coef = fitted_model_1 . params . age_squared # let's set our x-axis (corresponding to age) to be a wide range from -100 to 100, # just to see a grand picture of the function x_vals = np . linspace ( - 100 , 100 , 1000 ) y_vals = agecoef * x_vals + age2coef * x_vals ** 2 # WRITE CODE TO PLOT x_vals vs y_vals plt . plot ( x_vals , y_vals ) plt . title ( \"Effect of Age\" ) plt . xlabel ( \"Age\" ) plt . ylabel ( \"Contribution to Predicted Market Value\" ) plt . show () # Q2A: WHAT HAPPENS IF WE USED ONLY AGE (not AGE&#94;2) in our model (what's the r2?); make the same plot of age vs market value # Q2B: WHAT HAPPENS IF WE USED ONLY AGE&#94;2 (not age) in our model (what's the r2?); make the same plot of age&#94;2 vs market value # Q2C: PLOT page views vs market value # SOLUTION page_view_coef = fitted_model_1 . params . log_views x_vals = np . linspace ( 0 , 15 ) y_vals = page_view_coef * x_vals plt . plot ( x_vals , y_vals ) plt . title ( \"Effect of Page Views\" ) plt . xlabel ( \"Page Views\" ) plt . ylabel ( \"Contribution to Predicted Market Value\" ) plt . show () # 3- Linear regression on non-experimental data can't determine causation, so we can't prove that # a given relationship runs in the direction we might think. For instance, doing whatever it # takes to get more page views probably doesn't meaningfully increase market value; it's likely # the causation runs in the other direction and great players get more views. Even so, we can use # page views to help us tell who is a great player and thus likely to be paid well. Part 3.3: Turning Categorical Variables into multiple binary variables Of course, we have an error in how we've included player position. Even though the variable is numeric (1,2,3,4) and the model runs without issue, the value we're getting back is garbage. The interpretation, such as it is, is that there is an equal effect of moving from position category 1 to 2, from 2 to 3, and from 3 to 4, and that this effect is probably between -0.5 to -1 (depending on your run). In reality, we don't expect moving from one position category to another to be equivalent, nor for a move from category 1 to category 3 to be twice as important as a move from category 1 to category 2. We need to introduce better features to model this variable. We'll use pd.get_dummies to do the work for us. In [46]: train_design_recoded = pd . get_dummies ( train_transformed , columns = [ 'position_cat' ], drop_first = True ) test_design_recoded = pd . get_dummies ( test_transformed , columns = [ 'position_cat' ], drop_first = True ) train_design_recoded . head () Out[46]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } const fpl_points age age_squared log_views new_signing big_club position_cat_2 position_cat_3 position_cat_4 416 1.0 2 30 900 8.066089 0 0 0 0 1 196 1.0 83 29 841 10.626622 1 0 0 0 0 86 1.0 47 26 676 7.491853 1 0 0 0 0 362 1.0 39 25 625 9.400879 0 0 0 0 0 60 1.0 0 24 576 5.700440 0 0 0 1 0 We've removed the original position_cat column and created three new ones. Why only three new columns? Why does pandas give us the option to drop the first category? Exercise Questions : If we're fitting a model without a constant, should we have three dummy columns or four dummy columns? Fit a model on the new, recoded data, then interpret the coefficient of position_cat_2 . In [47]: ### SOLUTION: resu = OLS ( y_train , train_design_recoded ) . fit () resu . summary () print ( \"r2:\" , r2_score ( y_test , resu . predict ( test_design_recoded ))) print ( \"position_cat_2 coef:\" , resu . params . position_cat_2 ) train_design_recoded . shape , y_train . shape r2: 0.6105087003325882 position_cat_2 coef: -1.1708868527201026 Out[47]: ((368, 10), (368,)) SOLUTION: If our model does not have a constant, we must include all four dummy variable columns. If we drop one, we're not modeling any effect of being in that category, and effectively assuming the dropped category's effect is 0. Being in position 2 (instead of position 1) has an impact between -1.54 and +2.38 on a player's market value. Since we're using an intercept, the dropped category becomes the baseline and the effect of any dummy variable is the effect of being in that category instead of the baseline category. Part 4: A nice trick for forward-backwards XOR (operator &#94;) is a logical operation that only returns true when input differ. We can use it to implement forward-or-backwards selection when we want to keep track of whet predictors are \"left\" from a given list of predictors. The set analog is \"symmetric difference\". From the python docs: s.symmetric_difference(t) s &#94; t new set with elements in either s or t but not both In [48]: set () &#94; set ([ 1 , 2 , 3 ]) Out[48]: {1, 2, 3} In [49]: set ([ 1 ]) &#94; set ([ 1 , 2 , 3 ]) Out[49]: {2, 3} In [50]: set ([ 1 , 2 ]) &#94; set ([ 1 , 2 , 3 ]) Out[50]: {3} Exercise Outline a step-forwards algorithm which uses this idea SOLUTION: Start with no predictors in a set, selected_predictors . Then the \"xor\" will give the set of all predictors. Go through them 1-by -1, seeing which has the highest score/ OR lowestaic/bic. Add this predictor to the selected_predictors . Now repeat. The xor will eliminate this predictor from the remaining predictors. In the next iteration we will pick the next predictor which when combined with the first one gibes the lowest aic/bic of all 2-predictor models. We repeat. We finally chose the best bic model from the 1 -predictor models, 2-predictor models, 3-predictor models and so on... BONUS EXERCISE: We have provided a spreadsheet of Boston housing prices (data/boston_housing.csv). The 14 columns are as follows: CRIM: per capita crime rate by town ZN: proportion of residential land zoned for lots over 25,000 sq.ft. INDUS: proportion of non-retail business acres per town CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) NOX: nitric oxides concentration (parts per 10 million) RM: average number of rooms per dwelling AGE: proportion of owner-occupied units built prior to 1940 DIS: weighted distances to ﬁve Boston employment centers RAD: index of accessibility to radial highways TAX: full-value property-tax rate per \\$10,000 PTRATIO: pupil-teacher ratio by town B: 1000(Bk−0.63)2 where Bk is the proportion of blacks by town LSTAT: % lower status of the population MEDV: Median value of owner-occupied homes in $1000s We can see that the input attributes have a mixture of units There are 450 observations. Exercise Using the above file, try your best to predict housing prices. (the 14th column) We have provided a test set data/boston_housing_test.csv but refrain from looking at the file or evaluating on it until you have finalized and trained a model. Load in the data. It is tab-delimited. Quickly look at a summary of the data to familiarize yourself with it and ensure nothing is too egregious. Use a previously-discussed function to automatically partition the data into a training and validation (aka development) set. It is up to you to choose how large these two portions should be. Train a basic model on just a subset of the features. What is the performance on the validation set? Train a basic model on all of the features. What is the performance on the validation set? Toy with the model until you feel your results are reasonably good. Perform cross-validation with said model, and measure the average performance. Are the results what you expected? Were the average results better or worse than that from your original 1 validation set? Experiment with other models, and for each, perform 10-fold cross-validation. Which model yields the best average performance? Select this as your final model. Use this model to evaulate your performance on the testing set. What is your performance (MSE)? Is this what you expected? if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab04/notebook-poly/"},{"title":"Advanced Section 2: Regularization","text":"Notes Advanced Section: Methods of regularization and their justifications: Notes [pdf] Slides Advanced Section: Methods of regularization and their justifications [pdf] Advanced Section: Methods of regularization and their justifications [pptx] Notebook Advanced Section: Methods of regularization and their justifications: Demo Notebook [ipynb]","tags":"A-section","url":"a-section/a-section2/"},{"title":"Advanced Sections 2:","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } Advanced section 2 - Regularization This notebooks shows, in code, the effects of the regularization methods. We also show the instability that can arise in OLS. In [1]: # Imports import numpy as np import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D as a3d from plotly.offline import download_plotlyjs , init_notebook_mode , plot , iplot from plotly.plotly import plot , iplot import plotly.graph_objs as go init_notebook_mode ( connected = True ) from copy import deepcopy % matplotlib inline % matplotlib notebook window.PlotlyConfig = {MathJaxConfig: 'local'}; if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});} requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});} Create regression problem To exemplify the estimators and their behavior on different types of data, we create a basic 2D regression, as well as a 2d regression with highly colinear predictors. Let's start with a normal regression with random predictor values: In [2]: ## Global variables for plots # True betas: b_true = np . array ([ 3 , 7 ]) . reshape (( 2 , 1 )) # Samples and Y noise N = 100 sigma = 5 # linspaces lsp = np . linspace ( - 1.5 , 1.5 , 20 ) lsp_x , lsp_y = np . meshgrid ( lsp , lsp ) lsp_mat = np . column_stack (( lsp_x . flatten (), lsp_y . flatten ())) In [3]: # Generate random data from the true betas X = np . random . rand ( N , 2 ) * 10 - 5 X = ( X - X . mean ( axis = 0 )) / X . std ( axis = 0 ) eps = np . random . normal ( scale = sigma , size = ( N , 1 )) y = np . dot ( X , b_true ) + eps Plot regression problem In [4]: # 3D plot with Axes3D. 3D plotting with this is suboptimal, as it does no actual 3d rendering. def plot_scatter_axes3d ( X , y , b_true ): # y surface from true betas y_noiseless = np . dot ( lsp_mat , b_true ) . reshape (( 20 , 20 )) fig = plt . figure ( figsize = [ 9 , 7 ]) ax = fig . gca ( projection = '3d' ) ax . scatter ( X [:, 0 ], X [:, 1 ], y , color = 'red' , alpha = 1 , zorder = y ) ax . plot_surface ( lsp_x , lsp_y , np . dot ( lsp_mat , b_true ) . reshape (( 20 , 20 )), color = 'black' , alpha = 0.5 , zorder = y_noiseless ) plt . show () plot_scatter_axes3d ( X , y , b_true ); In [5]: # 3D plot with plotly. Plotly is a much better approach for 3d plots, but it requires the user to have an online account. # plotly.tools.set_credentials_file(username='camilofosco', api_key='AY1QtDdBCza2qZePnygz') def plot_scatter_plotly ( X , y , b_true ): # y surface from true betas y_noiseless = np . dot ( lsp_mat , b_true ) . reshape (( 20 , 20 )) data = [ go . Scatter3d ( x = X [:, 0 ], y = X [:, 1 ], z = y , mode = 'markers' , marker = dict ( size = 5 , color = 'green' , line = dict ( color = 'rgba(217, 217, 217, 0.14)' , width = 0.5 ), opacity = 1 ) ), go . Surface ( x = lsp_x , y = lsp_y , z = y_noiseless , colorscale = 'Greens' , opacity = 0.8 , showscale = False ), ] layout = go . Layout ( title = '2D Regression' , autosize = False , width = 700 , height = 700 , ) fig = go . Figure ( data = data , layout = layout ) return fig , data print ( X . shape , y . shape ) fig , data = plot_scatter_plotly ( X , y , b_true ) print ( len ( data )) iplot ( fig , filename = '2D Regression - normal data' ) (100, 2) (100, 1) 2 /anaconda3/lib/python3.6/site-packages/IPython/core/display.py:689: UserWarning: Consider using IPython.display.IFrame instead Out[5]: In [6]: # Regression types to use: regr = [ 'OLS' ] colors = [ 'Blues' , 'Reds' ] Calculate regression coefficients for OLS (normal data) In [7]: from sklearn.linear_model import LinearRegression , Ridge , Lasso , ElasticNet , RidgeCV , LassoCV , ElasticNetCV def fit_regression ( X , y , regr = [ 'OLS' ], verbose = True ): betas = [] if regr == 'all' : regr = [ 'OLS' , 'Ridge' , 'LASSO' , 'EN' ] for r in regr : if r == 'OLS' : # OLS fit regr_ols = LinearRegression ( fit_intercept = False ) regr_ols . fit ( X , y ) beta_ols = regr_ols . coef_ if verbose : print ( f 'OLS coefficients: {beta_ols} ' ) betas . append ( beta_ols ) elif r == 'Ridge' : # Ridge fit regr_ridge = RidgeCV ( fit_intercept = False ) regr_ridge . fit ( X , y ) beta_ridge = regr_ridge . coef_ if verbose : print ( f 'Ridge coefficients: {beta_ridge} , regularization coef: {regr_ridge.alpha_} ' ) betas . append ( beta_ridge ) elif r == 'LASSO' : # LASSO fit regr_lasso = LassoCV ( fit_intercept = False ) regr_lasso . fit ( X , y ) beta_lasso = regr_lasso . coef_ if verbose : print ( f 'LASSO coefficients: {beta_lasso} , regularization coef: {regr_lasso.alpha_} ' ) betas . append ( beta_lasso ) elif r == 'EN' : # Elastic Net fit regr_EN = ElasticNetCV ( fit_intercept = False ) regr_EN . fit ( X , y ) beta_EN = regr_EN . coef_ if verbose : print ( f 'ElasticNet coefficients: {beta_EN} , regularization coef: {regr_EN.alpha_} ' ) betas . append ( beta_EN ) return betas print ( 'True coefficents:' , b_true . ravel ()) betas = fit_regression ( X , y . ravel (), regr = regr ); True coefficents: [3 7] OLS coefficients: [2.7448308 7.30976811] Plot fitted planes (normal data) In [8]: def plot_fitted_planes ( betas , colors , names , data = [], return_traces = False ): for i , b in enumerate ( betas ): y = np . dot ( lsp_mat , b . reshape (( 2 , 1 ))) . reshape (( 20 , 20 )) data . append ( go . Surface ( x = lsp_x , y = lsp_y , z = y , colorscale = colors [ i ], text = names [ i ], showscale = False )) layout = go . Layout ( title = '2D Regression' , autosize = False , width = 700 , height = 700 , ) if return_traces : return data fig = go . Figure ( data = data , layout = layout ) return fig fig = plot_fitted_planes ( betas , colors = colors , names = regr , data = deepcopy ( data )) iplot ( fig , filename = '2D Regression with different estimators - normal data' ) /anaconda3/lib/python3.6/site-packages/IPython/core/display.py:689: UserWarning: Consider using IPython.display.IFrame instead Out[8]: Create regression problem with colinearity In [9]: # Generate random data with high colinearity between predictors x1 = np . random . rand ( N , 1 ) * 10 - 5 x2 = x1 + np . random . normal ( scale = 0.2 , size = ( N , 1 )) X_colin = np . column_stack (( x1 , x2 )) X_colin = ( X_colin - X_colin . mean ( axis = 0 )) / X_colin . std ( axis = 0 ) eps = np . random . normal ( scale = sigma , size = ( N , 1 )) y_colin = np . dot ( X_colin , b_true ) + eps Plot regression problem with colinearity In [10]: fig , data_colin = plot_scatter_plotly ( X_colin , y_colin , b_true ) iplot ( fig , filename = '2D Regression - normal data' ) Out[10]: Calculate regression coefficients (colinear data) In [11]: print ( 'True coefficents:' , b_true . ravel ()) betas_colin = fit_regression ( X_colin , y_colin . ravel (), regr = regr ); True coefficents: [3 7] OLS coefficients: [10.18864184 0.20719093] Plot fitting planes (colinear data) In [12]: fig = plot_fitted_planes ( betas_colin , colors = colors , names = regr , data = deepcopy ( data_colin )) iplot ( fig , filename = '2D Regression with different estimators - colinear data' ) Out[12]: Add a small perturbation to the colinear data and fit again In [13]: # Perturbation is just a bit of small uniform noise: perturbation = np . random . rand ( X_colin . shape [ 0 ], X_colin . shape [ 1 ]) * 0.05 X_colin_pert = X_colin + perturbation y_colin_pert = np . dot ( X_colin_pert , b_true ) + eps print ( 'True coefficents:' , b_true . ravel ()) betas = fit_regression ( X_colin_pert , y_colin_pert . ravel (), regr = regr ); fig , data_colin_pert = plot_scatter_plotly ( X_colin_pert , y_colin_pert , b_true ) fig = plot_fitted_planes ( betas , colors = colors , names = regr , data = deepcopy ( data_colin_pert )) iplot ( fig , filename = '2D Regression with different estimators - colinear data' ) True coefficents: [3 7] OLS coefficients: [3.59464312 6.79142214] Out[13]: This clearly shows how unstable our estimates are in OLS. As expected, in this case, the inverse Gram Matrix $(X&#94;TX)&#94;{-1}$ (proportional to covariance) will present very large diagonal values: Condition number and eigenvalues In [14]: print ( 'Inverse of Gram Matrix for colinear data (propto covariance matrix of betas):' ) print ( np . linalg . inv ( np . dot ( X_colin . T , X_colin ))) print ( 'Condition number of Gram Matrix:' ) print ( np . linalg . cond ( np . dot ( X_colin . T , X_colin ))) Inverse of Gram Matrix for colinear data (propto covariance matrix of betas): [[ 2.82282151 -2.81781707] [-2.81781707 2.82282151]] Condition number of Gram Matrix: 1127.1277155550463 In [15]: eigval , eigvec = np . linalg . eig ( np . dot ( X_colin . T , X_colin )) print ( \"Matrix X[:5] =\" ) display ( X [: 5 ]) print ( \"Eigenvalues =\" ) display ( eigval ) print ( \"Eigenvectors =\" ) display ( eigvec ) print ( \"Max(eigenvalues)/Min(eigenvalues)\" ) display ( max ( eigval ) / min ( eigval )) Matrix X[:5] = array([[ 1.75683671, 0.65680951], [-1.60918975, 1.54938769], [ 0.20357474, -0.48327303], [ 0.72870872, 1.21985667], [ 0.15826972, -1.14201238]]) Eigenvalues = array([1.77284892e-01, 1.99822715e+02]) Eigenvectors = array([[-0.70710678, -0.70710678], [ 0.70710678, -0.70710678]]) Max(eigenvalues)/Min(eigenvalues) 1127.127715555074 In [16]: print ( ' \\n Compare to non-colinear data:' ) print ( np . linalg . inv ( np . dot ( X . T , X ))) print ( 'Condition number of Gram Matrix with non-colinear data:' ) print ( np . linalg . cond ( np . dot ( X . T , X ))) Compare to non-colinear data: [[ 0.01033188 -0.00185174] [-0.00185174 0.01033188]] Condition number of Gram Matrix with non-colinear data: 1.4367237004517126 In [17]: eigval , eigvec = np . linalg . eig ( np . dot ( X . T , X )) print ( \"Matrix X[:5] =\" ) display ( X [: 5 ]) print ( \"Eigenvalues =\" ) display ( eigval ) print ( \"Eigenvectors =\" ) display ( eigvec ) print ( \"Max(eigenvalues)/Min(eigenvalues)\" ) display ( max ( eigval ) / min ( eigval )) Matrix X[:5] = array([[ 1.75683671, 0.65680951], [-1.60918975, 1.54938769], [ 0.20357474, -0.48327303], [ 0.72870872, 1.21985667], [ 0.15826972, -1.14201238]]) Eigenvalues = array([117.92257778, 82.07742222]) Eigenvectors = array([[ 0.70710678, -0.70710678], [ 0.70710678, 0.70710678]]) Max(eigenvalues)/Min(eigenvalues) 1.4367237004517126 Analyze loss surfaces In [18]: def OLS_loss ( X , y , beta , lbda = 0 ): y_hat = np . dot ( X , beta ) return np . sum (( y_hat - y ) ** 2 , axis = 0 ) def Ridge_loss ( X , y , beta , lbda ): y_hat = np . dot ( X , beta ) return np . sum (( y_hat - y ) ** 2 , axis = 0 ) + lbda * np . sum ( beta ** 2 , axis = 0 ) def LASSO_loss ( X , y , beta , lbda ): y_hat = np . dot ( X , beta ) return ( 1 / ( 2 * len ( X ))) * np . sum (( y_hat - y ) ** 2 , axis = 0 ) + lbda * np . sum ( np . abs ( beta ), axis = 0 ) def EN_loss ( X , y , beta , lbda ): ratio = 0.1 y_hat = np . dot ( X , beta ) return ( 1 / ( 2 * len ( X ))) * np . sum (( y_hat - y ) ** 2 , axis = 0 ) + lbda * ( ratio * np . sum ( beta ** 2 , axis = 0 ) + ( 1 - ratio ) * np . sum ( np . abs ( beta ), axis = 0 )) In [19]: # linspace for loss surface L = 40 lsp_b = np . linspace ( - 20 , 20 , L ) lsp_b_x , lsp_b_y = np . meshgrid ( lsp_b , lsp_b ) lsp_b_mat = np . column_stack (( lsp_b_x . flatten (), lsp_b_y . flatten ())) def build_surface_fig ( loss_values ): data = [ go . Surface ( x = lsp_b_x , y = lsp_b_y , z = loss_values , colorscale = 'Viridis' , opacity = 0.7 , contours = dict ( z = dict ( show = True , width = 3 , highlight = True , highlightcolor = 'orange' , project = dict ( z = True ), usecolormap = True )) ) ] layout = go . Layout ( title = 'Loss surface' , autosize = False , width = 700 , height = 700 , scene = dict ( xaxis = dict ( title = 'Beta 1' ), yaxis = dict ( title = 'Beta 2' ), zaxis = dict ( title = 'Loss' ) ) ) fig = go . Figure ( data = data , layout = layout ) display ( iplot ( fig , filename = '2D Regression with different estimators - colinear data' )) build_surface_fig ( OLS_loss ( X_colin , y_colin . reshape ( - 1 , 1 ), lsp_b_mat . T , 100 ) . reshape (( L , L ))); In [20]: # # OLS # loss_values = OLS_loss(X, y, lsp_b_mat.T).reshape((L,L)) # fig, data = build_surface_fig(loss_values) # iplot(fig, filename='Loss Surface') # # Ridge # loss_values = Ridge_loss(X, y, lsp_b_mat.T, 100.0).reshape((L,L)) # fig, data = build_surface_fig(loss_values) # iplot(fig, filename='Loss Surface') # # LASSO # loss_values = LASSO_loss(X, y, lsp_b_mat.T, 100.0).reshape((L,L)) # fig, data = build_surface_fig(loss_values) # iplot(fig, filename='Loss Surface') # # Elastic Net # loss_values = EN_loss(X, y, lsp_b_mat.T, 100.0).reshape((L,L)) # fig, data = build_surface_fig(loss_values) # fig['layout'].update() # iplot(fig, filename='Loss Surface') In [21]: from ipywidgets import interactive , HBox , VBox def loss_3d_interactive ( X , y , loss = 'Ridge' ): '''Uses plotly to draw an interactive 3D representation of the loss function, with a slider to control the regularization factor. Inputs: X: predictor matrix for the regression problem. Has to be of dim n x 2 y: response vector loss: string with the loss to plot. Options are 'Ridge', 'LASSO', 'EN'. ''' if loss == 'Ridge' : loss_function = Ridge_loss lbda_slider_min = 0 lbda_slider_max = 1000 lbda_step = 1 clf = Ridge () elif loss == 'LASSO' : loss_function = LASSO_loss lbda_slider_min = 1 lbda_slider_max = 150 lbda_step = 1 clf = Lasso () elif loss == 'EN' : loss_function = EN_loss lbda_slider_min = 1 lbda_slider_max = 150 lbda_step = 1 clf = ElasticNet () else : raise ValueError ( \"Loss string not recognized. Available options are: 'Ridge', 'LASSO', 'EN'.\" ) # linspace for loss surface L = 20 lsp_b = np . linspace ( - 10 , 10 , L ) lsp_b_x , lsp_b_y = np . meshgrid ( lsp_b , lsp_b ) lsp_b_mat = np . column_stack (( lsp_b_x . flatten (), lsp_b_y . flatten ())) # Get all optimal betas for current lambda range precomp_coefs = [] for l in range ( lbda_slider_min , lbda_slider_max + 1 , lbda_step ): clf . set_params ( alpha = l ) clf . fit ( X , y ) precomp_coefs . append ( clf . coef_ ) f = go . FigureWidget ( data = [ go . Surface ( x = lsp_b_x , y = lsp_b_y , z = loss_function ( X , y . reshape ( - 1 , 1 ), lsp_b_mat . T , 0 ) . reshape (( L , L )), colorscale = 'Viridis' , colorbar = dict ( len = 0.75 ), opacity = 0.7 , name = r \"Loss function\" , contours = dict ( z = dict ( show = True , width = 4 , highlight = True , highlightcolor = 'orange' , project = dict ( z = True ), usecolormap = True )) ), go . Scatter3d ( x = [ p [ 0 ] for p in precomp_coefs ], y = [ p [ 1 ] for p in precomp_coefs ], z = np . zeros ( len ( precomp_coefs )), name = r \"Trajectory Beta 1 and Beta 2\" , marker = dict ( size = 1 , color = 'red' , line = dict ( color = 'red' , width = 0 ), opacity = 1 ) ), go . Scatter3d ( x = [ 0 ], y = [ 0 ], z = [ 0 ], name = r \"Beta 1 and Beta 2 with constraint\" , marker = dict ( size = 10 , color = 'orange' , opacity = 1 ), ), go . Scatter3d ( x = [ 3 ], y = [ 7 ], z = [ 0 ], name = r \"True Beta 1 and Beta 2 = (3,7)\" , marker = dict ( size = 10 , color = 'blue' , opacity = 1 ), ), ], layout = go . Layout ( scene = go . layout . Scene ( xaxis = dict ( title = 'Beta 1' ), yaxis = dict ( title = 'Beta 2' ), zaxis = dict ( title = 'Loss' ), camera = go . layout . scene . Camera ( up = dict ( x = 0 , y = 0 , z = 1 ), center = dict ( x = 0 , y = 0 , z = 0 ), eye = dict ( x = 1.25 , y = 1.25 , z = 1.25 )) ), width = 1000 , height = 700 ,) ) def update_z ( lbda ): f . data [ 0 ] . z = loss_function ( X , y . reshape ( - 1 , 1 ), lsp_b_mat . T , lbda ) . reshape (( L , L )) beta_opt = precomp_coefs [( lbda - lbda_slider_min ) // ( lbda_step )] f . data [ - 2 ] . x = [ beta_opt [ 0 ]] f . data [ - 2 ] . y = [ beta_opt [ 1 ]] f . data [ - 2 ] . z = [ 0 ] lambda_slider = interactive ( update_z , lbda = ( lbda_slider_min , lbda_slider_max , lbda_step )) vb = VBox (( f , lambda_slider )) vb . layout . align_items = 'center' display ( vb ) In [22]: print ( X_colin . shape , y_colin . shape ) loss_3d_interactive ( X_colin , y_colin . ravel (), loss = 'Ridge' ) (100, 2) (100, 1) var element = $('#0986ade7-c1e0-458a-921c-5a4ec6324a99'); {\"model_id\": \"8e284f3a41e3458c986cc58884d9482f\", \"version_major\": 2, \"version_minor\": 0} In [23]: print ( X_colin . shape , y_colin . shape ) loss_3d_interactive ( X_colin , y_colin . ravel (), loss = 'LASSO' ) (100, 2) (100, 1) var element = $('#961167ad-75da-429d-bc4c-3c6c8b0c9242'); {\"model_id\": \"101d731391e143428b508df21023fe1a\", \"version_major\": 2, \"version_minor\": 0} In [24]: print ( X_colin . shape , y_colin . shape ) loss_3d_interactive ( X_colin , y_colin . ravel (), loss = 'EN' ) (100, 2) (100, 1) var element = $('#e7606911-d39d-4d6a-8df4-0532aca78eca'); {\"model_id\": \"effb804b68c4440db9b90dadac812895\", \"version_major\": 2, \"version_minor\": 0} Bayesian Interpretations of Lasso And Ridge In [25]: from ipywidgets import interactive , HBox , VBox import scipy.stats def interactive_dist (): '''Uses plotly to draw an interactive 3D representation of the loss function, with a slider to control the regularization factor. Inputs: X: predictor matrix for the regression problem. Has to be of dim n x 2 y: response vector loss: string with the loss to plot. Options are 'Ridge', 'LASSO', 'EN'. ''' # linspace for loss surface L = 20 x = np . linspace ( - 0.6 , 0.6 , 1000 ) y = scipy . stats . norm . pdf ( x , 0 ) y_2 = scipy . stats . laplace . pdf ( x , 0 , 2 ) f = go . FigureWidget ( data = [ go . Scatter ( x = x , y = y_2 , name = r \"Normal(mean = 0, scale = σ²/λ) = RIDGE\" ), go . Scatter ( x = x , y = y_2 , name = r \"Laplacienne(mean = 0, scale = σ²/λ) = LASSO\" ) ], layout = go . Layout ( title = 'Normal and Laplacienne Distribution with interactive λ (assume σ²=1)' , xaxis = dict ( title = 'Beta' ,), yaxis = dict ( title = 'pdf' , range = [ 0 , 15 ]), width = 1000 , height = 500 ,) ) def update_z ( lbda ): f . data [ 0 ] . y = scipy . stats . norm . pdf ( x , 0 , ( 1 / lbda )) f . data [ 1 ] . y = scipy . stats . laplace . pdf ( x , 0 , ( 2 / lbda )) lambda_slider = interactive ( update_z , lbda = ( 0.5 , 30 , 1 )) vb = VBox (( f , lambda_slider )) vb . layout . align_items = 'center' display ( vb ) interactive_dist () var element = $('#f3a56179-d5ba-45a7-bb46-c823717a9290'); {\"model_id\": \"ff5a09b6755346e39e6e4b31f4ae526c\", \"version_major\": 2, \"version_minor\": 0} if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"a-section","url":"a-section/a-section2/notebook/"},{"title":"Lecture 7: Model Selection and Regularization","text":"Slides PDF PPTX","tags":"lectures","url":"lectures/lecture7/"},{"title":"Lecture 6: Multiple Linear Regression, Polynomial Regression","text":"Slides PDF PPTX","tags":"lectures","url":"lectures/lecture6/"},{"title":"S-Section 02: kNN and Linear Regression","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109A Introduction to Data Science Standard Section 2: kNN and Linear Regression Harvard University Fall 2019 Instructors : Pavlos Protopapas, Kevin Rader, and Chris Tanner Section Leaders : Marios Mattheakis, Abhimanyu (Abhi) Vasishth, Robbert (Rob) Struyven In [ ]: #RUN THIS CELL import requests from IPython.core.display import HTML styles = requests . get ( \"http://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\" ) . text HTML ( styles ) For this section, our goal is to get you familiarized with k-Nearest Neighbors (kNN) and Linear Regression. We have learned how some aspects of dealing with data (loading in data files, scraping data from the web, visualizing data) and now we're moving to data modeling. Specifically, we will: Load in the Bikeshare dataset Do some basic exploratory data analysis (EDA) of the dataset Split it into a training and test dataset and understand why this is needed Learn to use kNN using the sklearn package (bonus: we will also look at writing the algorithm without sklearn) Learn to use the statsmodels and sklearn packages for Linear Regression. Learn about confidence intervals and how to extract them. For this section we will be using the following packages: In [ ]: #Matrices, Dataframe and Plotting Operations import numpy as np import pandas as pd import seaborn as sns import matplotlib import matplotlib.pyplot as plt % matplotlib inline Working with Dataframes Load in the Bikeshare dataset and perform EDA: The task is to build a regression model for a bike share system to predict the total number of bike rentals in a given day , based on attributes about the day. Such a demand forecasting model would be useful in planning the number of bikes that need to be available in the system on any given day, and also in monitoring traffic in the city. The data for this problem was collected from the Capital Bikeshare program in Washington D.C. over two years. The data set is provided in the file 'bikeshare.csv'. Each row in these files contains 10 attributes describing a day and its weather. Description of variables season (1 = spring, 2 = summer, 3 = fall, 4 = winter) month (1 through 12, with 1 denoting Jan) holiday (1 = the day is a holiday, 0 = otherwise) day_of_week (0 through 6, with 0 denoting Sunday) workingday (1 = the day is neither a holiday or weekend, 0 = otherwise) weather 1: Clear, Few clouds, Partly cloudy, Partly cloudy 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog temp (temperature in Celsius) atemp (apparent, or relative outdoor, or real feel temperature, in Celsius) humidity (relative humidity) windspeed (wind speed) count (response variable i.e. total number of bike rentals on the day) Load the BikeShare dataset and drop the unnecessary columns In [ ]: bikeshare = pd . read_csv ( '../data/bikeshare.csv' ) . drop ( columns = [ 'Unnamed: 0' ]) print ( \"Length of Dataset:\" , len ( bikeshare )) display ( bikeshare . head ()) In [ ]: display ( bikeshare . describe ()) We can also use the groupby function to look at mean stats aggregated by month In [ ]: # Your code here In [ ]: # %load '../solutions/sol1.py' Let's plot the variation of count with month. Is there a seasonal change? In [ ]: # Your code here In [ ]: # %load '../solutions/sol2.py' What is temp, a_temp, is there a difference? Let us plot them both In [ ]: # Your code here In [ ]: # %load '../solutions/sol3.py' What did we do wrong here? Why does the plot look like this? Sorting! Whenever your plot makes zig-zag changes across the scale, it is because matplotlib is trying to connect the points sequentially from the top (using a line plot) and skipping across the scale when $x_{i+1}$ is lower than $x_{i}$. So let's sort. In [ ]: # Sorting new = bikeshare . sort_values ([ 'temp' ]) plt . plot ( new [ 'temp' ], new [ 'atemp' ], '-b' , alpha = 1 ) plt . xlabel ( 'Temp' ) plt . ylabel ( 'A - Temp' ) plt . title ( 'A - Temp vs Temp' ) plt . show () It still looks weird, why? Let's have a closer look at the dataframe: In [ ]: display ( new . head ( 10 )) There are multiple atemp values for each temp value, which if not sorted will bounce around at the same x-value. Thus, we need to sort both axes simultaneously. In [ ]: new = bikeshare . sort_values ([ 'temp' , 'atemp' ]) plt . plot ( new [ 'temp' ], new [ 'atemp' ], '-b' ) plt . xlabel ( 'Temp' ) plt . ylabel ( 'A - Temp' ) plt . title ( 'A - Temp vs Temp' ) plt . show () By plotting efficiently, we found an anomaly we would have otherwise overlooked. It looks like there is a problem with the data around temp greater than 30 and atemp less than 10 . Show all rows in the dataframe where the temp is greater than 30 and the atemp is less than 10 In [ ]: # Your code here In [ ]: # %load '../solutions/sol4.py' Anomaly! atemp and temp are usually lineary related except at this one datapoint. Now, we get to make a judgement call as to whether we should keep the datapoint? We'll come back to this question after the lecture on Missing Data and Imputation. Worth a thought though. In [ ]: bikeshare = bikeshare . drop ([ 188 ]) We can now try what we wrote and we should end up with no rows in the dataframe where the temp is greater than 30 and the atemp is less than 10 In [ ]: # %load '../solutions/sol4.py' Split up the data into a training set and a test set using the 'train_test_split' function from sklearn: Having an idea of what the data looks like, we want to predict count. We will be breaking up the data into a training and a testing set. The training set will be used to train the model, while the testing set will be used to quantify how well our model does. The testing set is a way for us to ensure our model doesn't overfit our training data. Let us first create a function that will randomly split the data up into a 70-30 split, with 70% of the data going into the training set: In [ ]: from sklearn.model_selection import train_test_split train_data , test_data = train_test_split ( bikeshare , test_size = 0.30 , random_state = 42 ) print ( \"Length of Training set = \" , len ( train_data )) print ( \"Length of Testing set = \" , len ( test_data )) Calculate the ratio of the number of points in the training set to the number of points in the testing set to see if we have split the data correctly In [ ]: # Your code here In [ ]: # %load '../solutions/sol5.py' kNN Regression Using sklearn to implement kNN: We will now use the scikit learn (sklearn) package to implement kNN. Then, we can fit the model and use various metrics to assess our accuracy. General sklearn model fitting code-structure : #Split Data into Train and Test Set x_train, y_train = training_data.drop('Response_Variable', axis=1), training_data['Response_Variable'] x_test, y_test = test_data.drop('Response_Variable', axis=1), test_data['Response_Variable'] #Define Model model = sklearn_model_name(hyper_parameter1 = value1, hyper_parameter2 = value2) #Fit Model model.fit(x_train, y_train) #Get Prediction y_pred_train = model.predict(x_train) y_pred_test = model.predict(x_test) #Evaluate Model r2_train = model.score(y_train, y_pred_train) r2_test = model.score(y_test, y_pred_test) #Print Results print(\"Score for Model (Training):\", r2_train) print(\"Score for Model (Testing) :\", r2_test) Every model has a list of hyperparameters that can be set using sklearn for the specific problem. In practice it is advisable to cross-validate a list of values to find best model fit. model.fit calculates the parameters of your model corresponding to the training data and hyperparameters you provided. model.predict(X) is the standard method called to make the model predict values for a specific X. Depending on if you feed x_train or x_test, you will get a y_prediction_train or y_prediction_test respectively. Evaluation of model can vary according to the task at hand i.e. Regression or Classification. For Regression, $R&#94;2$ Score is standard while for Classification, Accuracy (%) is standard. In [ ]: from sklearn.neighbors import KNeighborsRegressor # Set kNN parameter: k = 5 # Now we can fit the model, predict our variable of interest, and then evaluate our fit: # First, we create the classifier object: neighbors = KNeighborsRegressor ( n_neighbors = k ) # Then, we fit the model using x_train as training data and y_train as target values: neighbors . fit ( train_data [[ 'temp' ]], train_data [ 'count' ]) # Retreieve our predictions: prediction_knn = neighbors . predict ( test_data [[ 'temp' ]]) # This returns the mean accuracy on the given test data and labels, or in other words, # the R squared value -- A constant model that always predicts the expected value of y, # disregarding the input features, would get a R&#94;2 score of 1. r2_train = neighbors . score ( train_data [[ 'temp' ]], train_data [ 'count' ]) r2_test = neighbors . score ( test_data [[ 'temp' ]], test_data [ 'count' ]) print ( \"Length of Test Data:\" , len ( test_data [ 'count' ])) print ( \"R&#94;2 Score of kNN on training set:\" , r2_train ) print ( \"R&#94;2 Score of kNN on testing set: \" , r2_test ) In [ ]: # SubPlots fig , axes = plt . subplots ( nrows = 1 , ncols = 2 , figsize = ( 20 , 6 )) axes [ 0 ] . set_ylim ([ 0 , 10000 ]) axes [ 0 ] . plot ( train_data [ 'temp' ], train_data [ 'count' ], 'o' , label = 'Data' ) sorted_temp = train_data . sort_values ([ 'temp' ]) prediction_knn = neighbors . predict ( sorted_temp [[ 'temp' ]]) axes [ 0 ] . plot ( sorted_temp [ 'temp' ], prediction_knn , '*-' , label = 'Prediction' ) axes [ 0 ] . set_xlabel ( 'Temperature' ) axes [ 0 ] . set_ylabel ( '# of Rides' ) axes [ 0 ] . set_title ( \"Temp vs Count kNN Regression Training Set (k= {} )\" . format ( k )) axes [ 0 ] . legend () axes [ 1 ] . set_ylim ([ 0 , 10000 ]) axes [ 1 ] . plot ( test_data [ 'temp' ], test_data [ 'count' ], 'o' , label = 'Data' ) #, '*') sorted_temp = test_data . sort_values ([ 'temp' ]) prediction_knn = neighbors . predict ( sorted_temp [[ 'temp' ]]) axes [ 1 ] . plot ( sorted_temp [ 'temp' ], prediction_knn , '*-' , label = 'Prediction' ) axes [ 1 ] . set_xlabel ( 'Temperature' ) axes [ 1 ] . set_ylabel ( '# of Rides' ) axes [ 1 ] . set_title ( \"Temp vs Count kNN Regression Test Set (k= {} )\" . format ( k )) axes [ 1 ] . legend () fig . suptitle ( \"Bike Rides\" ); Linear Regression We just went over the kNN prediction method. Now, we will fit the same data with Linear Regression model. We will use a the same training/testing dataset as before and create our linear regression objects. In [ ]: from sklearn.linear_model import LinearRegression from statsmodels.api import OLS import statsmodels.api as sm #Split Data into X,Y x_train , y_train = train_data [ 'temp' ], train_data [ 'count' ] x_test , y_test = test_data [ 'temp' ], test_data [ 'count' ] #Add constant x_train_ca = sm . add_constant ( x_train ) x_test_ca = sm . add_constant ( x_test ) Fit a Linear Regression (OLS) model using statsmodels and print out the coefficients of temp and const Hint : StatsModels use a Y followed by X structure while feeding data in contrast to sklearn that uses X followed by Y. Give the name results to your fit model In [ ]: # Your code here In [ ]: # %load '../solutions/sol6.py' In [ ]: # Plotting our model fig , axes = plt . subplots ( 1 , 2 , figsize = ( 20 , 6 )) axes = axes . ravel () axes [ 0 ] . plot ( x_train , y_train , 'o' ) sorted_temp = train_data . sort_values ([ 'temp' ]) prediction_lr = results . predict ( sm . add_constant ( sorted_temp [[ 'temp' ]])) axes [ 0 ] . plot ( sorted_temp [ 'temp' ], prediction_lr , '*-' , label = 'Prediction' ) axes [ 0 ] . set_title ( 'Temp vs Count Linear Regression for Training Set' ) axes [ 1 ] . plot ( x_test , y_test , 'o' ) sorted_temp = test_data . sort_values ([ 'temp' ]) prediction_lr = results . predict ( sm . add_constant ( sorted_temp [[ 'temp' ]])) axes [ 1 ] . plot ( sorted_temp [ 'temp' ], prediction_lr , '*-' , label = 'Prediction' ) axes [ 1 ] . set_title ( 'Temp vs Count Linear Regression for Test Set' ) for i , ax in enumerate ( axes ): ax . set_ylim ( 0 , 10000 ) ax . set_xlabel ( 'Temperature' ) ax . set_ylabel ( '# of Rides' ) ax . legend () In [ ]: # Metrics, Performance Evaluation and Helpful functions from sklearn import metrics # To compute the mean squared error (notice that we are now using the TEST set): print ( \"R&#94;2 Score for Linear Regression (Training):\" , metrics . r2_score ( y_train , results . predict ( x_train_ca ))) print ( \"R&#94;2 Score for Linear Regression (Testing) :\" , metrics . r2_score ( y_test , results . predict ( x_test_ca ))) Check out results.summary() and pay close attention to the table that shows up In [ ]: results . summary () Confidence Intervals In Data Science, a confidence interval (CI) is a type of interval estimate, computed from the statistics of the observed data, that might contain the true value of an unknown population parameter. Simply speaking, a Confidence Interval is a range of values we are fairly sure our true value lies in. It is important to remind ourselves here that Confidence Intervals belong to a parameter and not a statistic. Thus, they represent the window in which the true value exists for the entire population when all we have is a sample. See if you can implement a 95% confidence interval using statsmodels In [ ]: # Your code here In [ ]: # %load '../solutions/sol7.py' In the above block of code, results.conf_int(alpha=thresh) returns a dataframe with columns 0 and 1. We explained Confidence Intervals above where because we assume normal symetric distribution of data, the 95% Confidence Interval means there's 2.5% chance of the true value lying below the values in Column 0 and 2.5% chance of the true value lying above Column 1. End of Standard Section Extra: Train-Test Split using a mask In [ ]: #Function to Split data into Train and Test Set def split_data ( data ): #Calculate Length of Dataset length = len ( data ) #Define Split split = 0.7 #Set a random Seed For Shuffling np . random . seed ( 9001 ) #Generate a Mask with a X:Y Split mask = np . random . rand ( length ) < split #Separate train and test data data_train = data [ mask ] data_test = data [ ~ mask ] #Return Separately return data_train , data_test In [ ]: #Split data using defined function train_data_manual , test_data_manual = split_data ( bikeshare ) print ( \"Length of Training set:\" , len ( train_data_manual )) print ( \"Length of Testing set:\" , len ( test_data_manual )) In [ ]: ## Check that the ratio between test and train sets is right test_data_manual . shape [ 0 ] / ( test_data_manual . shape [ 0 ] + train_data_manual . shape [ 0 ]) Extra: Implementing the kNN Algorithm by hand To really understand how the kNN algorithm works, it helps to go through the algorithm line by line in code. In [ ]: #kNN Algorithm def knn_algorithm ( train , test , k ): #Create any empty list to store our predictions in predictions = [] #Separate the response and predictor variables from training and test set: train_x = train [ 'temp' ] train_y = train [ 'count' ] test_x = test [ 'temp' ] test_y = test [ 'count' ] for i , ele in enumerate ( test_x ): #For each test point, store the distance between all training points and test point distances = pd . DataFrame (( train_x . values - ele ) ** 2 , index = train . index ) distances . columns = [ 'dist' ] #display(distances) #Then, we sum across the columns per row to obtain the Euclidean distance squared ##distances = vec_distances.sum(axis = 1) #Sort the distances to training points (in ascending order) and take first k points nearest_k = distances . sort_values ( by = 'dist' ) . iloc [: k ] #For simplicity, we omitted the square rooting of the Euclidean distance because the #square root function preserves order. #Take the mean of the y-values of training set corresponding to the nearest k points k_mean = train_y [ nearest_k . index ] . mean () #Add on the mean to our predicted y-value list predictions . append ( k_mean ) #Create a dataframe with the x-values from test and predicted y-values predict = test . copy () predict [ 'predicted_count' ] = pd . Series ( predictions , index = test . index ) return predict Now to run the algorithm on our dataset with $k = 5$: In [ ]: #Run the kNN function k = 5 predicted_knn = knn_algorithm ( train_data , test_data , k ) predicted_knn . head () We want to have a way to evaluate our predictions from the kNN algorithm with $k=5$. One way is to compute the $R&#94;2$ coefficient. Let's create a function for that: In [ ]: #Test predictions in comparison to true value of test set def evaluate ( predicted , true ): #Find the squared error: squared_error = ( predicted [ 'predicted_count' ] - true [ 'count' ]) ** 2 #Finding the mean squared error: error_var = squared_error . sum () sample_var = (( true [ 'count' ] - true [ 'count' ] . mean ()) ** 2 ) . sum () r = ( 1 - ( error_var / sample_var )) return r Then let's apply this function to our predictions: In [ ]: print ( \"Length of Test Data:\" , len ( test_data )) print ( \"R&#94;2 Score of kNN test:\" , evaluate ( predicted_knn , test_data )) In [ ]: predicted_knn_train = knn_algorithm ( test_data , train_data , k ) print ( \"R&#94;2 Score of kNN train:\" , evaluate ( predicted_knn_train , train_data )) Extra: Computing different performance metrics by hand Now, we will compute metrics that can be used to assess fit. Note: sklearn.metrics is class of functions that consists of all the metrics we care about to evaluate our models. While it is not hard to implement them yourself, it is helpful to go through http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics . In [ ]: model = sm . OLS ( y_train , x_train_ca ) results = model . fit () #Find the squared error: y_pred_train = results . predict ( x_train_ca ) squared_error_train = ( y_pred_train - y_train ) ** 2 #Finding the mean squared error: error_var_train = squared_error_train . mean () sample_var_train = (( y_train - y_train . mean ()) ** 2 ) . mean () y_pred_test = results . predict ( x_test_ca ) squared_error_test = ( y_pred_test - y_test ) ** 2 #Finding the mean squared error: error_var_test = squared_error_test . mean () sample_var_test = (( y_test - y_test . mean ()) ** 2 ) . mean () print ( error_var_train , sample_var_train , 1 - error_var_train / sample_var_train ) print ( error_var_test , sample_var_test , 1 - error_var_test / sample_var_test ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"sections","url":"sections/sec_2/"},{"title":"S-Section 02: kNN and Linear Regression","text":"Jupyter Notebooks S-Section 2: kNN and Linear Regression","tags":"sections","url":"sections/section2/"},{"title":"Lab 3: Matplotlib, Simple Linear Regression, kNN, array reshape","text":"Jupyter Notebooks Lab 3: Matplotlib, Simple Linear Regression, kNN, array reshape Lab 3: Matplotlib, Simple Linear Regression, kNN, array reshape - extended edition Lab 3: Matplotlib, Prelab","tags":"labs","url":"labs/lab-3/"},{"title":"Lab 03: Extended Matplotlib, Simple Linear Regression, kNN, array reshape","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109A Introduction to Data Science Lab 3: plotting, K-NN Regression, Simple Linear Regression Harvard University Fall 2019 Instructors: Pavlos Protopapas, Kevin Rader, and Chris Tanner Material prepared by : David Sondak, Will Claybaugh, Pavlos Protopapas, and Eleni Kaxiras. Extended Edition Same as the one done in class with the following additions/clarifications: I added another example to illustrate the difference between .iloc and .loc in pandas -- > here I added some notes on why we are adding a constant in our linear regression model --> here How to run the solutions: Uncomment the following line and run the cell: # %load solutions/knn_regression.py This will bring up the code in the cell but WILL NOT RUN it. You need to run the cell again in order to actually run the code In [1]: #RUN THIS CELL import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } span.sub-q { font-weight: bold; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Learning Goals By the end of this lab, you should be able to: Review numpy including 2-D arrays and understand array reshaping Use matplotlib to make plots Feel comfortable with simple linear regression Feel comfortable with $k$ nearest neighbors This lab corresponds to lectures 4 and 5 and maps on to homework 2 and beyond. Table of Contents HIGHLIGHTS FROM PRE-LAB 1 - Review of numpy 2 - Intro to matplotlib plus more LAB 3 MATERIAL 3 - Simple Linear Regression 4 - Building a model with statsmodels and sklearn 5 - Example: Simple linear regression with automobile data 6 - $k$Nearest Neighbors In [ ]: import numpy as np import scipy as sp import matplotlib as mpl import matplotlib.cm as cm import matplotlib.pyplot as plt import pandas as pd import time pd . set_option ( 'display.width' , 500 ) pd . set_option ( 'display.max_columns' , 100 ) pd . set_option ( 'display.notebook_repr_html' , True ) #import seaborn as sns import warnings warnings . filterwarnings ( 'ignore' ) # Displays the plots for us. % matplotlib inline In [ ]: # Use this as a variable to load solutions: %load PATHTOSOLUTIONS/exercise1.py. It will be substituted in the code # so do not worry if it disappears after you run the cell. PATHTOSOLUTIONS = 'solutions' 1 - Review of the numpy Python library In lab1 we learned about the numpy library (documentation) and its fast array structure, called the numpy array . In [ ]: # import numpy import numpy as np In [ ]: # make an array my_array = np . array ([ 1 , 4 , 9 , 16 ]) my_array In [ ]: print ( f 'Size of my array: {my_array.size} , or length of my array: {len(my_array)}' ) print ( f 'Shape of my array: {my_array.shape} ' ) Notice the way the shape appears in numpy arrays For a 1D array, .shape returns a tuple with 1 element (n,) For a 2D array, .shape returns a tuple with 2 elements (n,m) For a 3D array, .shape returns a tuple with 3 elements (n,m,p) In [ ]: # How to reshape a 1D array to a 2D my_array . reshape ( - 1 , 2 ) Numpy arrays support the same operations as lists! Below we slice and iterate. In [ ]: print ( \"array[2:4]:\" , my_array [ 2 : 4 ]) # A slice of the array # Iterate over the array for ele in my_array : print ( \"element:\" , ele ) Remember numpy gains a lot of its efficiency from being strongly typed (all elements are of the same type, such as integer or floating point). If the elements of an array are of a different type, numpy will force them into the same type (the longest in terms of bytes) In [ ]: mixed = np . array ([ 1 , 2.3 , 'eleni' , True ]) print ( type ( 1 ), type ( 2.3 ), type ( 'eleni' ), type ( True )) mixed # all elements will become strings Next, we push ahead to two-dimensional arrays and begin to dive into some of the deeper aspects of numpy . In [ ]: # create a 2d-array by handing a list of lists my_array2d = np . array ([ [ 1 , 2 , 3 , 4 ], [ 5 , 6 , 7 , 8 ], [ 9 , 10 , 11 , 12 ] ]) my_array2d Array Slicing (a reminder...) Numpy arrays can be sliced, and can be iterated over with loops. Below is a schematic illustrating slicing two-dimensional arrays. Notice that the list slicing syntax still works! array[2:,3] says \"in the array, get rows 2 through the end, column 3]\" array[3,:] says \"in the array, get row 3, all columns\". Pandas Slicing (a reminder...) .iloc is by position (position is unique), .loc is by label (label is not unique) In [ ]: # import cast dataframe cast = pd . read_csv ( '../data/cast.csv' , encoding = 'utf_8' ) cast . head () In [ ]: # get me rows 10 to 13 (python slicing style : exclusive of end) cast . iloc [ 10 : 13 ] In [ ]: # get me columns 0 to 2 but all rows - use head() cast . iloc [:, 0 : 2 ] . head () In [ ]: # get me rows 10 to 13 AND only columns 0 to 2 cast . iloc [ 10 : 13 , 0 : 2 ] In [ ]: # COMPARE: get me rows 10 to 13 (pandas slicing style : inclusive of end) cast . loc [ 10 : 13 ] In [ ]: # give me columns 'year' and 'type' by label but only for rows 5 to 10 cast . loc [ 5 : 10 ,[ 'year' , 'type' ]] Another example of positioning with .iloc and loc Look at the following data frame. It is a bad example because we have duplicate values for the index but that is legal in pandas. It's just a bad practice and we are doing it to illustrate the difference between positioning with .iloc and loc . To keep rows unique, though, internally, pandas has its own index which in this dataframe runs from 0 to 2 . In [ ]: index = [ 'A' , 'Z' , 'A' ] famous = pd . DataFrame ({ 'Elton' : [ 'singer' , 'Candle in the wind' , 'male' ], 'Maraie' : [ 'actress' , 'Do not know' , 'female' ], 'num' : np . random . randn ( 3 )}, index = index ) famous In [ ]: # accessing elements by label can bring up duplicates!! famous . loc [ 'A' ] # since we want all rows is the same as famous.loc['A',:] In [ ]: # accessing elements by position is unique - brings up only one row famous . iloc [ 1 ] 2 - Plotting with matplotlib and beyond matplotlib is a very powerful python library for making scientific plots. We will not focus too much on the internal aspects of matplotlib in today's lab. There are many excellent tutorials out there for matplotlib . For example, matplotlib homepage matplotlib tutorial Conveying your findings convincingly is an absolutely crucial part of any analysis. Therefore, you must be able to write well and make compelling visuals. Creating informative visuals is an involved process and we won't cover that in this lab. However, part of creating informative data visualizations means generating readable figures. If people can't read your figures or have a difficult time interpreting them, they won't understand the results of your work. Here are some non-negotiable commandments for any plot: Label $x$ and $y$ axes Axes labels should be informative Axes labels should be large enough to read Make tick labels large enough Include a legend if necessary Include a title if necessary Use appropriate line widths Use different line styles for different lines on the plot Use different markers for different lines There are other important elements, but that list should get you started on your way. We will work with matplotlib and seaborn for plotting in this class. matplotlib is a very powerful python library for making scientific plots. seaborn is a little more specialized in that it was developed for statistical data visualization. We will cover some seaborn later in class. In the meantime you can look at the seaborn documentation First, let's generate some data. Let's plot some functions We will use the following three functions to make some plots: Logistic function: \\begin{align*} f\\left(z\\right) = \\dfrac{1}{1 + be&#94;{-az}} \\end{align*} where $a$ and $b$ are parameters. Hyperbolic tangent: \\begin{align*} g\\left(z\\right) = b\\tanh\\left(az\\right) + c \\end{align*} where $a$, $b$, and $c$ are parameters. Rectified Linear Unit: \\begin{align*} h\\left(z\\right) = \\left{ \\begin{array}{lr} z, \\quad z > 0 \\\\ \\epsilon z, \\quad z\\leq 0 \\end{array} \\right. \\end{align*} where $\\epsilon < 0$ is a small, positive parameter. You are given the code for the first two functions. Notice that $z$ is passed in as a numpy array and that the functions are returned as numpy arrays. Parameters are passed in as floats. You should write a function to compute the rectified linear unit. The input should be a numpy array for $z$ and a positive float for $\\epsilon$. In [ ]: import numpy as np def logistic ( z : np . ndarray , a : float , b : float ) -> np . ndarray : \"\"\" Compute logistic function Inputs: a: exponential parameter b: exponential prefactor z: numpy array; domain Outputs: f: numpy array of floats, logistic function \"\"\" den = 1.0 + b * np . exp ( - a * z ) return 1.0 / den def stretch_tanh ( z : np . ndarray , a : float , b : float , c : float ) -> np . ndarray : \"\"\" Compute stretched hyperbolic tangent Inputs: a: horizontal stretch parameter (a>1 implies a horizontal squish) b: vertical stretch parameter c: vertical shift parameter z: numpy array; domain Outputs: g: numpy array of floats, stretched tanh \"\"\" return b * np . tanh ( a * z ) + c def relu ( z : np . ndarray , eps : float = 0.01 ) -> np . ndarray : \"\"\" Compute rectificed linear unit Inputs: eps: small positive parameter z: numpy array; domain Outputs: h: numpy array; relu \"\"\" return np . fmax ( z , eps * z ) Now let's make some plots. First, let's just warm up and plot the logistic function. In [ ]: x = np . linspace ( - 5.0 , 5.0 , 100 ) # Equally spaced grid of 100 pts between -5 and 5 f = logistic ( x , 1.0 , 1.0 ) # Generate data In [ ]: plt . plot ( x , f ) plt . xlabel ( 'x' ) plt . ylabel ( 'f' ) plt . title ( 'Logistic Function' ) plt . grid ( True ) Figures with subplots Let's start thinking about the plots as objects. We have the figure object which is like a matrix of smaller plots named axes . You can use array notation when handling it. In [ ]: fig , ax = plt . subplots ( 1 , 1 ) # Get figure and axes objects ax . plot ( x , f ) # Make a plot # Create some labels ax . set_xlabel ( 'x' ) ax . set_ylabel ( 'f' ) ax . set_title ( 'Logistic Function' ) # Grid ax . grid ( True ) Wow, it's exactly the same plot! Notice, however, the use of ax.set_xlabel() instead of plt.xlabel() . The difference is tiny, but you should be aware of it. I will use this plotting syntax from now on. What else do we need to do to make this figure better? Here are some options: Make labels bigger! Make line fatter Make tick mark labels bigger Make the grid less pronounced Make figure bigger Let's get to it. In [ ]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) # Make figure bigger # Make line plot ax . plot ( x , f , lw = 4 ) # Update ticklabel size ax . tick_params ( labelsize = 24 ) # Make labels ax . set_xlabel ( r '$x$' , fontsize = 24 ) # Use TeX for mathematical rendering ax . set_ylabel ( r '$f(x)$' , fontsize = 24 ) # Use TeX for mathematical rendering ax . set_title ( 'Logistic Function' , fontsize = 24 ) ax . grid ( True , lw = 1.5 , ls = '--' , alpha = 0.75 ) Notice: lw stands for linewidth . We could also write ax.plot(x, f, linewidth=4) ls stands for linestyle . alpha stands for transparency. The only thing remaining to do is to change the $x$ limits. Clearly these should go from $-5$ to $5$. In [ ]: #fig.savefig('logistic.png') # Put this in a markdown cell and uncomment this to check what you saved. # ![](../images/logistic.png) Resources If you want to see all the styles available, please take a look at the documentation. Line styles Marker styles Everything you could ever want We haven't discussed it yet, but you can also put a legend on a figure. You'll do that in the next exercise. Here are some additional resources: Legend Grid ax.legend(loc='best', fontsize=24); Exercise Do the following: Make a figure with the logistic function, hyperbolic tangent, and rectified linear unit. Use different line styles for each plot Put a legend on your figure Here's an example of a figure: In [ ]: # your code here # First get the data f = logistic ( x , 2.0 , 1.0 ) g = stretch_tanh ( x , 2.0 , 0.5 , 0.5 ) h = relu ( x ) fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) # Create figure object # Make actual plots # (Notice the label argument!) ax . plot ( x , f , lw = 4 , ls = '-' , label = r '$L(x;1)$' ) ax . plot ( x , g , lw = 4 , ls = '--' , label = r '$\\tanh(2x)$' ) ax . plot ( x , h , lw = 4 , ls = '-.' , label = r '$relu(x; 0.01)$' ) # Make the tick labels readable ax . tick_params ( labelsize = 24 ) # Set axes limits to make the scale nice ax . set_xlim ( x . min (), x . max ()) ax . set_ylim ( h . min (), 1.1 ) # Make readable labels ax . set_xlabel ( r '$x$' , fontsize = 24 ) ax . set_ylabel ( r '$h(x)$' , fontsize = 24 ) ax . set_title ( 'Activation Functions' , fontsize = 24 ) # Set up grid ax . grid ( True , lw = 1.75 , ls = '--' , alpha = 0.75 ) # Put legend on figure ax . legend ( loc = 'best' , fontsize = 24 ); fig . savefig ( '../images/nice_plots.png' ) Exercise These figures look nice in the plot and it makes sense for comparison. Now let's put the 3 different figures in separate plots. Make a separate plot for each figure and line them up on the same row. In [ ]: # your code here In [ ]: # %load solutions/three_subplots.py Exercise Make a grid of 2 x 3 separate plots, 3 will be empty. Just plot the functions and do not worry about cosmetics. We just want you ro see the functionality. In [ ]: # your code here In [ ]: % load solutions/six_subplots.py 3 - Simple Linear Regression Linear regression and its many extensions are a workhorse of the statistics and data science community, both in application and as a reference point for other models. Most of the major concepts in machine learning can be and often are discussed in terms of various linear regression models. Thus, this section will introduce you to building and fitting linear regression models and some of the process behind it, so that you can 1) fit models to data you encounter 2) experiment with different kinds of linear regression and observe their effects 3) see some of the technology that makes regression models work. Linear regression with a toy dataset We first examine a toy problem, focusing our efforts on fitting a linear model to a small dataset with three observations. Each observation consists of one predictor $x_i$ and one response $y_i$ for $i = 1, 2, 3$, \\begin{align*} (x , y) = \\{(x_1, y_1), (x_2, y_2), (x_3, y_3)\\}. \\end{align*} To be very concrete, let's set the values of the predictors and responses. \\begin{equation*} (x , y) = \\{(1, 2), (2, 2), (3, 4)\\} \\end{equation*} There is no line of the form $\\beta_0 + \\beta_1 x = y$ that passes through all three observations, since the data are not collinear. Thus our aim is to find the line that best fits these observations in the least-squares sense , as discussed in lecture. Exercise (for home) Make two numpy arrays out of this data, x_train and y_train Check the dimentions of these arrays Try to reshape them into a different shape Make points into a very simple scatterplot Make a better scatterplot In [ ]: # your code here In [ ]: # solution x_train = np . array ([ 1 , 2 , 3 ]) y_train = np . array ([ 2 , 3 , 6 ]) type ( x_train ) In [ ]: x_train . shape In [ ]: x_train = x_train . reshape ( 3 , 1 ) x_train . shape In [ ]: # %load solutions/simple_scatterplot.py # Make a simple scatterplot plt . scatter ( x_train , y_train ) # check dimensions print ( x_train . shape , y_train . shape ) In [ ]: # %load solutions/nice_scatterplot.py def nice_scatterplot ( x , y , title ): # font size f_size = 18 # make the figure fig , ax = plt . subplots ( 1 , 1 , figsize = ( 8 , 5 )) # Create figure object # set axes limits to make the scale nice ax . set_xlim ( np . min ( x ) - 1 , np . max ( x ) + 1 ) ax . set_ylim ( np . min ( y ) - 1 , np . max ( y ) + 1 ) # adjust size of tickmarks in axes ax . tick_params ( labelsize = f_size ) # remove tick labels ax . tick_params ( labelbottom = False , bottom = False ) # adjust size of axis label ax . set_xlabel ( r '$x$' , fontsize = f_size ) ax . set_ylabel ( r '$y$' , fontsize = f_size ) # set figure title label ax . set_title ( title , fontsize = f_size ) # you may set up grid with this ax . grid ( True , lw = 1.75 , ls = '--' , alpha = 0.15 ) # make actual plot (Notice the label argument!) #ax.scatter(x, y, label=r'$my points$') #ax.scatter(x, y, label='$my points$') ax . scatter ( x , y , label = r '$my\\,points$' ) ax . legend ( loc = 'best' , fontsize = f_size ); return ax nice_scatterplot ( x_train , y_train , 'hello nice plot' ) Formulae Linear regression is special among the models we study because it can be solved explicitly. While most other models (and even some advanced versions of linear regression) must be solved itteratively, linear regression has a formula where you can simply plug in the data. For the single predictor case it is: \\begin{align} \\beta_1 &= \\frac{\\sum_{i=1}&#94;n{(x_i-\\bar{x})(y_i-\\bar{y})}}{\\sum_{i=1}&#94;n{(x_i-\\bar{x})&#94;2}}\\\\ \\beta_0 &= \\bar{y} - \\beta_1\\bar{x}\\ \\end{align} Where $\\bar{y}$ and $\\bar{x}$ are the mean of the y values and the mean of the x values, respectively. Building a model from scratch In this part, we will solve the equations for simple linear regression and find the best fit solution to our toy problem. The snippets of code below implement the linear regression equations on the observed predictors and responses, which we'll call the training data set. Let's walk through the code. We have to reshape our arrrays to 2D. We will see later why. Exercise make an array with shape (2,3) reshape it to a size that you want In [ ]: # your code here In [ ]: #solution xx = np . array ([[ 1 , 2 , 3 ],[ 4 , 6 , 8 ]]) xxx = xx . reshape ( - 1 , 2 ) xxx . shape In [ ]: # Reshape to be a proper 2D array x_train = x_train . reshape ( x_train . shape [ 0 ], 1 ) y_train = y_train . reshape ( y_train . shape [ 0 ], 1 ) print ( x_train . shape ) In [ ]: # first, compute means y_bar = np . mean ( y_train ) x_bar = np . mean ( x_train ) # build the two terms numerator = np . sum ( ( x_train - x_bar ) * ( y_train - y_bar ) ) denominator = np . sum (( x_train - x_bar ) ** 2 ) print ( numerator . shape , denominator . shape ) #check shapes Why the empty brackets? (The numerator and denominator are scalars, as expected.) In [ ]: #slope beta1 beta_1 = numerator / denominator #intercept beta0 beta_0 = y_bar - beta_1 * x_bar print ( \"The best-fit line is {0:3.2f} + {1:3.2f} * x\" . format ( beta_0 , beta_1 )) print ( f 'The best fit is {beta_0} ' ) Exercise Turn the code from the above cells into a function called simple_linear_regression_fit , that inputs the training data and returns beta0 and beta1 . To do this, copy and paste the code from the above cells below and adjust the code as needed, so that the training data becomes the input and the betas become the output. def simple_linear_regression_fit ( x_train : np . ndarray , y_train : np . ndarray ) -> np . ndarray : return Check your function by calling it with the training data from above and printing out the beta values. In [ ]: # Your code here In [ ]: # %load solutions/simple_linear_regression_fit.py def simple_linear_regression_fit ( x_train : np . ndarray , y_train : np . ndarray ) -> np . ndarray : \"\"\" Inputs: x_train: a (num observations by 1) array holding the values of the predictor variable y_train: a (num observations by 1) array holding the values of the response variable Returns: beta_vals: a (num_features by 1) array holding the intercept and slope coeficients \"\"\" # Check input array sizes if len ( x_train . shape ) < 2 : print ( \"Reshaping features array.\" ) x_train = x_train . reshape ( x_train . shape [ 0 ], 1 ) if len ( y_train . shape ) < 2 : print ( \"Reshaping observations array.\" ) y_train = y_train . reshape ( y_train . shape [ 0 ], 1 ) # first, compute means y_bar = np . mean ( y_train ) x_bar = np . mean ( x_train ) # build the two terms numerator = np . sum ( ( x_train - x_bar ) * ( y_train - y_bar ) ) denominator = np . sum (( x_train - x_bar ) ** 2 ) #slope beta1 beta_1 = numerator / denominator #intercept beta0 beta_0 = y_bar - beta_1 * x_bar return np . array ([ beta_0 , beta_1 ]) Let's run this function and see the coefficients In [ ]: x_train = np . array ([ 1 , 2 , 3 ]) y_train = np . array ([ 2 , 2 , 4 ]) betas = simple_linear_regression_fit ( x_train , y_train ) beta_0 = betas [ 0 ] beta_1 = betas [ 1 ] print ( \"The best-fit line is {0:8.6f} + {1:8.6f} * x\" . format ( beta_0 , beta_1 )) Exercise Do the values of beta0 and beta1 seem reasonable? Plot the training data using a scatter plot. Plot the best fit line with beta0 and beta1 together with the training data. In [ ]: # Your code here In [ ]: # %load solutions/best_fit_scatterplot.py fig_scat , ax_scat = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) # Plot best-fit line x_train = np . array ([[ 1 , 2 , 3 ]]) . T best_fit = beta_0 + beta_1 * x_train ax_scat . scatter ( x_train , y_train , s = 300 , label = 'Training Data' ) ax_scat . plot ( x_train , best_fit , ls = '--' , label = 'Best Fit Line' ) ax_scat . set_xlabel ( r '$x_ {train} $' ) ax_scat . set_ylabel ( r '$y$' ); The values of beta0 and beta1 seem roughly reasonable. They capture the positive correlation. The line does appear to be trying to get as close as possible to all the points. 4 - Building a model with statsmodels and sklearn Now that we can concretely fit the training data from scratch, let's learn two python packages to do it all for us: statsmodels and scikit-learn (sklearn) . Our goal is to show how to implement simple linear regression with these packages. For an important sanity check, we compare the $\\beta$ values from statsmodels and sklearn to the $\\beta$ values that we found from above with our own implementation. For the purposes of this lab, statsmodels and sklearn do the same thing. More generally though, statsmodels tends to be easier for inference [finding the values of the slope and intercept and dicussing uncertainty in those values], whereas sklearn has machine-learning algorithms and is better for prediction [guessing y values for a given x value]. (Note that both packages make the same guesses, it's just a question of which activity they provide more support for. Note: statsmodels and sklearn are different packages! Unless we specify otherwise, you can use either one. Why do we need to add a constant in our simple linear regression model? Let's say we a data set of two obsevations with one predictor and one response variable each. We would then have the following two equations if we run a simple linear regression model. $$y_1=\\beta_0 + \\beta_1*x_1$$ $$y_2=\\beta_0 + \\beta_1*x_2$$ For simplicity and calculation efficiency we want to \"absorb\" the constant $b_0$ into an array with $b_1$ so we have only multiplication. To do this we introduce the constant ${x}&#94;0=1$ $$y_1=\\beta_0*{x_1}&#94;0 + \\beta_1*x_1$$ $$y_2=\\beta_0 * {x_2}&#94;0 + \\beta_1*x_2$$ That becomes: $$y_1=\\beta_0*1 + \\beta_1*x_1$$ $$y_2=\\beta_0 * 1 + \\beta_1*x_2$$ In matrix notation: $$ \\left [ \\begin{array}{c} y_1 \\\\ y_2 \\\\ \\end{array} \\right] = \\left [ \\begin{array}{cc} 1& x_1 \\\\ 1 & x_2 \\\\ \\end{array} \\right] \\cdot \\left [ \\begin{array}{c} \\beta_0 \\\\ \\beta_1 \\\\ \\end{array} \\right] $$ sklearn adds the constant for us where in statsmodels we need to explicitly add it using sm.add_constant Below is the code for statsmodels . Statsmodels does not by default include the column of ones in the $X$ matrix, so we include it manually with sm.add_constant . In [ ]: import statsmodels.api as sm In [ ]: # create the X matrix by appending a column of ones to x_train X = sm . add_constant ( x_train ) # this is the same matrix as in our scratch problem! print ( X ) # build the OLS model (ordinary least squares) from the training data toyregr_sm = sm . OLS ( y_train , X ) # do the fit and save regression info (parameters, etc) in results_sm results_sm = toyregr_sm . fit () # pull the beta parameters out from results_sm beta0_sm = results_sm . params [ 0 ] beta1_sm = results_sm . params [ 1 ] print ( f 'The regression coef from statsmodels are: beta_0 = {beta0_sm:8.6f} and beta_1 = {beta1_sm:8.6f} ' ) Besides the beta parameters, results_sm contains a ton of other potentially useful information. In [ ]: import warnings warnings . filterwarnings ( 'ignore' ) print ( results_sm . summary ()) Now let's turn our attention to the sklearn library. In [ ]: from sklearn import linear_model In [ ]: # build the least squares model toyregr = linear_model . LinearRegression () # save regression info (parameters, etc) in results_skl results = toyregr . fit ( x_train , y_train ) # pull the beta parameters out from results_skl beta0_skl = toyregr . intercept_ beta1_skl = toyregr . coef_ [ 0 ] print ( \"The regression coefficients from the sklearn package are: beta_0 = {0:8.6f} and beta_1 = {1:8.6f} \" . format ( beta0_skl , beta1_skl )) We should feel pretty good about ourselves now, and we're ready to move on to a real problem! The scikit-learn library and the shape of things Before diving into a \"real\" problem, let's discuss more of the details of sklearn . Scikit-learn is the main Python machine learning library. It consists of many learners which can learn models from data, as well as a lot of utility functions such as train_test_split() . Use the following to add the library into your code: import sklearn In scikit-learn , an estimator is a Python object that implements the methods fit(X, y) and predict(T) Let's see the structure of scikit-learn needed to make these fits. fit() always takes two arguments: estimator . fit ( Xtrain , ytrain ) We will consider two estimators in this lab: LinearRegression and KNeighborsRegressor . It is very important to understand that Xtrain must be in the form of a 2x2 array with each row corresponding to one sample, and each column corresponding to the feature values for that sample. ytrain on the other hand is a simple array of responses. These are continuous for regression problems. Practice with sklearn and a real dataset We begin by loading up the mtcars dataset. This data was extracted from the 1974 Motor Trend US magazine, and comprises of fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models). We will load this data to a dataframe with 32 observations on 11 (numeric) variables. Here is an explanation of the features: mpg is Miles/(US) gallon cyl is Number of cylinders, disp is Displacement (cu.in.), hp is Gross horsepower, drat is Rear axle ratio, wt is the Weight (1000 lbs), qsec is 1/4 mile time, vs is Engine (0 = V-shaped, 1 = straight), am is Transmission (0 = automatic, 1 = manual), gear is the Number of forward gears, carb is Number of carburetors. In [ ]: import pandas as pd #load mtcars dfcars = pd . read_csv ( \"../data/mtcars.csv\" ) dfcars . head () In [ ]: # Fix the column title dfcars = dfcars . rename ( columns = { \"Unnamed: 0\" : \"car name\" }) dfcars . head () In [ ]: dfcars . shape Searching for values: how many cars have 4 gears? In [ ]: len ( dfcars [ dfcars . gear == 4 ] . drop_duplicates ( subset = 'car name' , keep = 'first' )) Next, let's split the dataset into a training set and test set. In [ ]: # split into training set and testing set from sklearn.model_selection import train_test_split #set random_state to get the same split every time traindf , testdf = train_test_split ( dfcars , test_size = 0.2 , random_state = 42 ) In [ ]: # testing set is around 20% of the total data; training set is around 80% print ( \"Shape of full dataset is: {0} \" . format ( dfcars . shape )) print ( \"Shape of training dataset is: {0} \" . format ( traindf . shape )) print ( \"Shape of test dataset is: {0} \" . format ( testdf . shape )) Now we have training and test data. We still need to select a predictor and a response from this dataset. Keep in mind that we need to choose the predictor and response from both the training and test set. You will do this in the exercises below. However, we provide some starter code for you to get things going. In [ ]: traindf . head () In [ ]: # Extract the response variable that we're interested in y_train = traindf . mpg y_train Exercise Use slicing to get the same vector y_train Now, notice the shape of y_train . In [ ]: y_train . shape , type ( y_train ) Array reshape This is a 1D array as should be the case with the Y array. Remember, sklearn requires a 2D array only for the predictor array. You will have to pay close attention to this in the exercises later. Sklearn doesn't care too much about the shape of y_train . The whole reason we went through that whole process was to show you how to reshape your data into the correct format. IMPORTANT: Remember that your response variable ytrain can be a vector but your predictor variable xtrain must be an array! 5 - Example: Simple linear regression with automobile data We will now use sklearn to predict automobile mileage per gallon (mpg) and evaluate these predictions. We already loaded the data and split them into a training set and a test set. We need to choose the variables that we think will be good predictors for the dependent variable mpg . Exercise in pairs Pick one variable to use as a predictor for simple linear regression. Discuss your reasons with the person next to you. Justify your choice with some visualizations. Is there a second variable you'd like to use? For example, we're not doing multiple linear regression here, but if we were, is there another variable you'd like to include if we were using two predictors? In [ ]: x_wt = dfcars . wt x_wt . shape In [ ]: # Your code here In [ ]: # %load solutions/cars_simple_EDA.py Exercise Use sklearn to fit the training data using simple linear regression. Use the model to make mpg predictions on the test set. Plot the data and the prediction. Print out the mean squared error for the training set and the test set and compare. In [ ]: from sklearn.linear_model import LinearRegression from sklearn.model_selection import train_test_split from sklearn.metrics import mean_squared_error dfcars = pd . read_csv ( \"../data/mtcars.csv\" ) dfcars = dfcars . rename ( columns = { \"Unnamed: 0\" : \"name\" }) dfcars . head () In [ ]: traindf , testdf = train_test_split ( dfcars , test_size = 0.2 , random_state = 42 ) y_train = np . array ( traindf . mpg ) X_train = np . array ( traindf . wt ) X_train = X_train . reshape ( X_train . shape [ 0 ], 1 ) In [ ]: y_test = np . array ( testdf . mpg ) X_test = np . array ( testdf . wt ) X_test = X_test . reshape ( X_test . shape [ 0 ], 1 ) In [ ]: # Let's take another look at our data dfcars . head () In [ ]: # And out train and test sets y_train . shape , X_train . shape In [ ]: y_test . shape , X_test . shape In [ ]: #create linear model regression = LinearRegression () #fit linear model regression . fit ( X_train , y_train ) predicted_y = regression . predict ( X_test ) r2 = regression . score ( X_test , y_test ) print ( f 'R&#94;2 = {r2:.5} ' ) In [ ]: print ( regression . score ( X_train , y_train )) print ( mean_squared_error ( predicted_y , y_test )) print ( mean_squared_error ( y_train , regression . predict ( X_train ))) print ( 'Coefficients: \\n ' , regression . coef_ [ 0 ], regression . intercept_ ) In [ ]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( y_test , predicted_y , 'o' ) grid = np . linspace ( np . min ( dfcars . mpg ), np . max ( dfcars . mpg ), 100 ) ax . plot ( grid , grid , color = \"black\" ) # 45 degree line ax . set_xlabel ( \"actual y\" ) ax . set_ylabel ( \"predicted y\" ) fig1 , ax1 = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax1 . plot ( dfcars . wt , dfcars . mpg , 'o' ) xgrid = np . linspace ( np . min ( dfcars . wt ), np . max ( dfcars . wt ), 100 ) ax1 . plot ( xgrid , regression . predict ( xgrid . reshape ( 100 , 1 ))) 6 - $k$-nearest neighbors Now that you're familiar with sklearn , you're ready to do a KNN regression. Sklearn's regressor is called sklearn.neighbors.KNeighborsRegressor . Its main parameter is the number of nearest neighbors . There are other parameters such as the distance metric (default for 2 order is the Euclidean distance). For a list of all the parameters see the Sklearn kNN Regressor Documentation . Let's use $5$ nearest neighbors. In [ ]: # Import the library from sklearn.neighbors import KNeighborsRegressor In [ ]: # Set number of neighbors k = 5 knnreg = KNeighborsRegressor ( n_neighbors = k ) In [ ]: # Fit the regressor - make sure your numpy arrays are the right shape knnreg . fit ( X_train , y_train ) # Evaluate the outcome on the train set using R&#94;2 r2_train = knnreg . score ( X_train , y_train ) # Print results print ( f 'kNN model with {k} neighbors gives R&#94;2 on the train set: {r2_train:.5} ' ) In [ ]: knnreg . predict ( X_test ) Exercise Calculate and print the $R&#94;{2}$ score on the test set In [ ]: # Your code here Not so good? Lets vary the number of neighbors and see what we get. In [ ]: # Make our lives easy by storing the different regressors in a dictionary regdict = {} # Make our lives easier by entering the k values from a list k_list = [ 1 , 2 , 4 , 15 ] # Do a bunch of KNN regressions for k in k_list : knnreg = KNeighborsRegressor ( n_neighbors = k ) knnreg . fit ( X_train , y_train ) # Store the regressors in a dictionary regdict [ k ] = knnreg # Print the dictionary to see what we have regdict Now let's plot all the k values in same plot. In [ ]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( dfcars . wt , dfcars . mpg , 'o' , label = \"data\" ) xgrid = np . linspace ( np . min ( dfcars . wt ), np . max ( dfcars . wt ), 100 ) # let's unpack the dictionary to its elements (items) which is the k and Regressor for k , regressor in regdict . items (): predictions = regressor . predict ( xgrid . reshape ( - 1 , 1 )) ax . plot ( xgrid , predictions , label = \" {} -NN\" . format ( k )) ax . legend (); Exercise Explain what you see in the graph. Hint Notice how the $1$-NN goes through every point on the training set but utterly fails elsewhere. Lets look at the scores on the training set. In [ ]: ks = range ( 1 , 15 ) # Grid of k's scores_train = [] # R2 scores for k in ks : # Create KNN model knnreg = KNeighborsRegressor ( n_neighbors = k ) # Fit the model to training data knnreg . fit ( X_train , y_train ) # Calculate R&#94;2 score score_train = knnreg . score ( X_train , y_train ) scores_train . append ( score_train ) # Plot fig , ax = plt . subplots ( 1 , 1 , figsize = ( 12 , 8 )) ax . plot ( ks , scores_train , 'o-' ) ax . set_xlabel ( r '$k$' ) ax . set_ylabel ( r '$R&#94; {2} $' ) Exercise Why do we get a perfect $R&#94;2$ at k=1 for the training set? Make the same plot as above on the test set. What is the best $k$? In [ ]: # Your code here In [ ]: # %load solutions/knn_regression.py In [ ]: # solution to previous exercise r2_test = knnreg . score ( X_test , y_test ) print ( f 'kNN model with {k} neighbors gives R&#94;2 on the test set: {r2_test:.5} ' ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab03-ex/notebook/"},{"title":"Lab 03: Matplotlib, Simple Linear Regression, kNN, array reshape","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109A Introduction to Data Science Lab 3: plotting, K-NN Regression, Simple Linear Regression Harvard University Fall 2019 Instructors: Pavlos Protopapas, Kevin Rader, and Chris Tanner Material prepared by : David Sondak, Will Claybaugh, Pavlos Protopapas, and Eleni Kaxiras. In [34]: #RUN THIS CELL import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[34]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } span.sub-q { font-weight: bold; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Learning Goals By the end of this lab, you should be able to: Review numpy including 2-D arrays and understand array reshaping Use matplotlib to make plots Feel comfortable with simple linear regression Feel comfortable with $k$ nearest neighbors This lab corresponds to lectures 4 and 5 and maps on to homework 2 and beyond. Table of Contents HIGHLIGHTS FROM PRE-LAB 1 - Review of numpy 2 - Intro to matplotlib plus more LAB 3 MATERIAL 3 - Simple Linear Regression 4 - Building a model with statsmodels and sklearn 5 - Example: Simple linear regression with automobile data 6 - $k$Nearest Neighbors In [35]: import numpy as np import scipy as sp import matplotlib as mpl import matplotlib.cm as cm import matplotlib.pyplot as plt import pandas as pd import time pd . set_option ( 'display.width' , 500 ) pd . set_option ( 'display.max_columns' , 100 ) pd . set_option ( 'display.notebook_repr_html' , True ) #import seaborn as sns import warnings warnings . filterwarnings ( 'ignore' ) # Displays the plots for us. % matplotlib inline In [36]: # Use this as a variable to load solutions: %load PATHTOSOLUTIONS/exercise1.py. It will be substituted in the code # so do not worry if it disappears after you run the cell. PATHTOSOLUTIONS = 'solutions' 1 - Review of the numpy Python library In lab1 we learned about the numpy library (documentation) and its fast array structure, called the numpy array . In [37]: # import numpy import numpy as np In [38]: # make an array my_array = np . array ([ 1 , 4 , 9 , 16 ]) my_array Out[38]: array([ 1, 4, 9, 16]) In [39]: print ( f 'Size of my array: {my_array.size} , or length of my array: {len(my_array)}' ) print ( f 'Shape of my array: {my_array.shape} ' ) Size of my array: 4, or length of my array: 4 Shape of my array: (4,) Notice the way the shape appears in numpy arrays For a 1D array, .shape returns a tuple with 1 element (n,) For a 2D array, .shape returns a tuple with 2 elements (n,m) For a 3D array, .shape returns a tuple with 3 elements (n,m,p) In [118]: # How to reshape a 1D array to a 2D my_array . reshape ( - 1 , 2 ) Out[118]: array([[ 1, 4], [ 9, 16]]) Numpy arrays support the same operations as lists! Below we slice and iterate. In [41]: print ( \"array[2:4]:\" , my_array [ 2 : 4 ]) # A slice of the array # Iterate over the array for ele in my_array : print ( \"element:\" , ele ) array[2:4]: [ 9 16] element: 1 element: 4 element: 9 element: 16 Remember numpy gains a lot of its efficiency from being strongly typed (all elements are of the same type, such as integer or floating point). If the elements of an array are of a different type, numpy will force them into the same type (the longest in terms of bytes) In [42]: mixed = np . array ([ 1 , 2.3 , 'eleni' , True ]) print ( type ( 1 ), type ( 2.3 ), type ( 'eleni' ), type ( True )) mixed # all elements will become strings Out[42]: array(['1', '2.3', 'eleni', 'True'], dtype=' Next, we push ahead to two-dimensional arrays and begin to dive into some of the deeper aspects of numpy . In [43]: # create a 2d-array by handing a list of lists my_array2d = np . array ([ [ 1 , 2 , 3 , 4 ], [ 5 , 6 , 7 , 8 ], [ 9 , 10 , 11 , 12 ] ]) my_array2d Out[43]: array([[ 1, 2, 3, 4], [ 5, 6, 7, 8], [ 9, 10, 11, 12]]) Array Slicing (a reminder...) Numpy arrays can be sliced, and can be iterated over with loops. Below is a schematic illustrating slicing two-dimensional arrays. Notice that the list slicing syntax still works! array[2:,3] says \"in the array, get rows 2 through the end, column 3]\" array[3,:] says \"in the array, get row 3, all columns\". Pandas Slicing (a reminder...) .iloc is by position (position is unique), .loc is by label (label is not unique) In [44]: # import cast dataframe cast = pd . read_csv ( '../data/cast.csv' , encoding = 'utf_8' ) cast . head () Out[44]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } title year name type character n 0 Closet Monster 2015 Buffy #1 actor Buffy 4 31.0 1 Suuri illusioni 1985 Homo $ actor Guests 22.0 2 Battle of the Sexes 2017 $hutter actor Bobby Riggs Fan 10.0 3 Secret in Their Eyes 2015 $hutter actor 2002 Dodger Fan NaN 4 Steve Jobs 2015 $hutter actor 1988 Opera House Patron NaN In [45]: # get me rows 10 to 13 (python slicing style : exclusive of end) cast . iloc [ 10 : 13 ] Out[45]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } title year name type character n 10 When the Man Went South 2014 Taipaleti 'Atu'ake actor Two Palms - Ua'i Paame 8.0 11 Little Angel (Angelita) 2015 Michael 'babeepower' Viera actor Chico 9.0 12 Mixing Nia 1998 Michael 'babeepower' Viera actor Rapper NaN In [46]: # get me columns 0 to 2 but all rows - use head() cast . iloc [:, 0 : 2 ] . head () Out[46]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } title year 0 Closet Monster 2015 1 Suuri illusioni 1985 2 Battle of the Sexes 2017 3 Secret in Their Eyes 2015 4 Steve Jobs 2015 In [47]: # get me rows 10 to 13 AND only columns 0 to 2 cast . iloc [ 10 : 13 , 0 : 2 ] Out[47]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } title year 10 When the Man Went South 2014 11 Little Angel (Angelita) 2015 12 Mixing Nia 1998 In [48]: # COMPARE: get me rows 10 to 13 (pandas slicing style : inclusive of end) cast . loc [ 10 : 13 ] Out[48]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } title year name type character n 10 When the Man Went South 2014 Taipaleti 'Atu'ake actor Two Palms - Ua'i Paame 8.0 11 Little Angel (Angelita) 2015 Michael 'babeepower' Viera actor Chico 9.0 12 Mixing Nia 1998 Michael 'babeepower' Viera actor Rapper NaN 13 The Replacements 2000 Steven 'Bear'Boyd actor Defensive Tackle - Washington Sentinels NaN In [49]: # give me columns 'year' and 'type' by label but only for rows 5 to 10 cast . loc [ 5 : 10 ,[ 'year' , 'type' ]] Out[49]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } year type 5 2015 actor 6 2015 actor 7 2009 actor 8 2014 actor 9 2014 actor 10 2014 actor Python Trick of the Day In [1]: import re names = [ 'mayday' , 'springday' , 'horseday' , 'june' ] In [2]: # TODO : substitute these lines code with 1 line of code using list comprehension cleaned = [] for name in names : this = re . sub ( '[Dd]ay$' , '' , name ) cleaned . append ( this ) cleaned Out[2]: ['may', 'spring', 'horse', 'june'] In [3]: # your code here In [4]: # solution cleaned2 = [ re . sub ( '[Dd]ay$' , '' , name ) for name in names ] cleaned2 Out[4]: ['may', 'spring', 'horse', 'june'] 2 - Plotting with matplotlib and beyond matplotlib is a very powerful python library for making scientific plots. We will not focus too much on the internal aspects of matplotlib in today's lab. There are many excellent tutorials out there for matplotlib . For example, matplotlib homepage matplotlib tutorial Conveying your findings convincingly is an absolutely crucial part of any analysis. Therefore, you must be able to write well and make compelling visuals. Creating informative visuals is an involved process and we won't cover that in this lab. However, part of creating informative data visualizations means generating readable figures. If people can't read your figures or have a difficult time interpreting them, they won't understand the results of your work. Here are some non-negotiable commandments for any plot: Label $x$ and $y$ axes Axes labels should be informative Axes labels should be large enough to read Make tick labels large enough Include a legend if necessary Include a title if necessary Use appropriate line widths Use different line styles for different lines on the plot Use different markers for different lines There are other important elements, but that list should get you started on your way. We will work with matplotlib and seaborn for plotting in this class. matplotlib is a very powerful python library for making scientific plots. seaborn is a little more specialized in that it was developed for statistical data visualization. We will cover some seaborn later in class. In the meantime you can look at the seaborn documentation First, let's generate some data. Let's plot some functions We will use the following three functions to make some plots: Logistic function: \\begin{align*} f\\left(z\\right) = \\dfrac{1}{1 + be&#94;{-az}} \\end{align*} where $a$ and $b$ are parameters. Hyperbolic tangent: \\begin{align*} g\\left(z\\right) = b\\tanh\\left(az\\right) + c \\end{align*} where $a$, $b$, and $c$ are parameters. Rectified Linear Unit: \\begin{align*} h\\left(z\\right) = \\left{ \\begin{array}{lr} z, \\quad z > 0 \\\\ \\epsilon z, \\quad z\\leq 0 \\end{array} \\right. \\end{align*} where $\\epsilon < 0$ is a small, positive parameter. You are given the code for the first two functions. Notice that $z$ is passed in as a numpy array and that the functions are returned as numpy arrays. Parameters are passed in as floats. You should write a function to compute the rectified linear unit. The input should be a numpy array for $z$ and a positive float for $\\epsilon$. In [50]: import numpy as np def logistic ( z : np . ndarray , a : float , b : float ) -> np . ndarray : \"\"\" Compute logistic function Inputs: a: exponential parameter b: exponential prefactor z: numpy array; domain Outputs: f: numpy array of floats, logistic function \"\"\" den = 1.0 + b * np . exp ( - a * z ) return 1.0 / den def stretch_tanh ( z : np . ndarray , a : float , b : float , c : float ) -> np . ndarray : \"\"\" Compute stretched hyperbolic tangent Inputs: a: horizontal stretch parameter (a>1 implies a horizontal squish) b: vertical stretch parameter c: vertical shift parameter z: numpy array; domain Outputs: g: numpy array of floats, stretched tanh \"\"\" return b * np . tanh ( a * z ) + c def relu ( z : np . ndarray , eps : float = 0.01 ) -> np . ndarray : \"\"\" Compute rectificed linear unit Inputs: eps: small positive parameter z: numpy array; domain Outputs: h: numpy array; relu \"\"\" return np . fmax ( z , eps * z ) Now let's make some plots. First, let's just warm up and plot the logistic function. In [51]: x = np . linspace ( - 5.0 , 5.0 , 100 ) # Equally spaced grid of 100 pts between -5 and 5 f = logistic ( x , 1.0 , 1.0 ) # Generate data In [52]: plt . plot ( x , f ) plt . xlabel ( 'x' ) plt . ylabel ( 'f' ) plt . title ( 'Logistic Function' ) plt . grid ( True ) Figures with subplots Let's start thinking about the plots as objects. We have the figure object which is like a matrix of smaller plots named axes . You can use array notation when handling it. In [53]: fig , ax = plt . subplots ( 1 , 1 ) # Get figure and axes objects ax . plot ( x , f ) # Make a plot # Create some labels ax . set_xlabel ( 'x' ) ax . set_ylabel ( 'f' ) ax . set_title ( 'Logistic Function' ) # Grid ax . grid ( True ) Wow, it's exactly the same plot! Notice, however, the use of ax.set_xlabel() instead of plt.xlabel() . The difference is tiny, but you should be aware of it. I will use this plotting syntax from now on. What else do we need to do to make this figure better? Here are some options: Make labels bigger! Make line fatter Make tick mark labels bigger Make the grid less pronounced Make figure bigger Let's get to it. In [54]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) # Make figure bigger # Make line plot ax . plot ( x , f , lw = 4 ) # Update ticklabel size ax . tick_params ( labelsize = 24 ) # Make labels ax . set_xlabel ( r '$x$' , fontsize = 24 ) # Use TeX for mathematical rendering ax . set_ylabel ( r '$f(x)$' , fontsize = 24 ) # Use TeX for mathematical rendering ax . set_title ( 'Logistic Function' , fontsize = 24 ) ax . grid ( True , lw = 1.5 , ls = '--' , alpha = 0.75 ) Notice: lw stands for linewidth . We could also write ax.plot(x, f, linewidth=4) ls stands for linestyle . alpha stands for transparency. The only thing remaining to do is to change the $x$ limits. Clearly these should go from $-5$ to $5$. In [55]: #fig.savefig('logistic.png') # Put this in a markdown cell and uncomment this to check what you saved. # ![](../images/logistic.png) Resources If you want to see all the styles available, please take a look at the documentation. Line styles Marker styles Everything you could ever want We haven't discussed it yet, but you can also put a legend on a figure. You'll do that in the next exercise. Here are some additional resources: Legend Grid ax.legend(loc='best', fontsize=24); Exercise Do the following: Make a figure with the logistic function, hyperbolic tangent, and rectified linear unit. Use different line styles for each plot Put a legend on your figure Here's an example of a figure: In [56]: # your code here # First get the data f = logistic ( x , 2.0 , 1.0 ) g = stretch_tanh ( x , 2.0 , 0.5 , 0.5 ) h = relu ( x ) fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) # Create figure object # Make actual plots # (Notice the label argument!) ax . plot ( x , f , lw = 4 , ls = '-' , label = r '$L(x;1)$' ) ax . plot ( x , g , lw = 4 , ls = '--' , label = r '$\\tanh(2x)$' ) ax . plot ( x , h , lw = 4 , ls = '-.' , label = r '$relu(x; 0.01)$' ) # Make the tick labels readable ax . tick_params ( labelsize = 24 ) # Set axes limits to make the scale nice ax . set_xlim ( x . min (), x . max ()) ax . set_ylim ( h . min (), 1.1 ) # Make readable labels ax . set_xlabel ( r '$x$' , fontsize = 24 ) ax . set_ylabel ( r '$h(x)$' , fontsize = 24 ) ax . set_title ( 'Activation Functions' , fontsize = 24 ) # Set up grid ax . grid ( True , lw = 1.75 , ls = '--' , alpha = 0.75 ) # Put legend on figure ax . legend ( loc = 'best' , fontsize = 24 ); fig . savefig ( '../images/nice_plots.png' ) Exercise These figures look nice in the plot and it makes sense for comparison. Now let's put the 3 different figures in separate plots. Make a separate plot for each figure and line them up on the same row. In [57]: # your code here In [120]: # %load solutions/three_subplots.py # First get the data f = logistic ( x , 2.0 , 1.0 ) g = stretch_tanh ( x , 2.0 , 0.5 , 0.5 ) h = relu ( x ) fig , ax = plt . subplots ( 1 , 3 , figsize = ( 20 , 6 )) # Create figure object # Make actual plots ax [ 0 ] . plot ( x , f , lw = 4 , ls = '-' , label = r '$L(x;1)$' ) ax [ 1 ] . plot ( x , g , lw = 4 , ls = '--' , label = r '$\\tanh(2x)$' ) ax [ 2 ] . plot ( x , h , lw = 4 , ls = '-.' , label = r '$relu(x; 0.01)$' ) # Make the tick labels readable ax [ 0 ] . tick_params ( labelsize = 24 ) ax [ 1 ] . tick_params ( labelsize = 24 ) ax [ 2 ] . tick_params ( labelsize = 24 ) # Set axes limits to make the scale nice ax [ 0 ] . set_xlim ( x . min (), x . max ()) ax [ 0 ] . set_ylim ( h . min (), 1.1 ) ax [ 1 ] . set_xlim ( x . min (), x . max ()) ax [ 1 ] . set_ylim ( h . min (), 1.1 ) ax [ 2 ] . set_xlim ( x . min (), x . max ()) ax [ 2 ] . set_ylim ( h . min (), 1.1 ) # Make readable labels ax [ 0 ] . set_xlabel ( r '$x$' , fontsize = 24 ) ax [ 0 ] . set_ylabel ( r '$h(x)$' , fontsize = 24 ) ax [ 0 ] . set_title ( 'Activation Functions' , fontsize = 24 ) ax [ 1 ] . set_xlabel ( r '$x$' , fontsize = 24 ) ax [ 1 ] . set_ylabel ( r '$h(x)$' , fontsize = 24 ) ax [ 1 ] . set_title ( 'Activation Functions' , fontsize = 24 ) ax [ 2 ] . set_xlabel ( r '$x$' , fontsize = 24 ) ax [ 2 ] . set_ylabel ( r '$h(x)$' , fontsize = 24 ) ax [ 2 ] . set_title ( 'Activation Functions' , fontsize = 24 ) # Set up grid ax [ 0 ] . grid ( True , lw = 1.75 , ls = '--' , alpha = 0.75 ) ax [ 1 ] . grid ( True , lw = 1.75 , ls = '--' , alpha = 0.75 ) ax [ 2 ] . grid ( True , lw = 1.75 , ls = '--' , alpha = 0.75 ) # Put legend on figure ax [ 0 ] . legend ( loc = 'best' , fontsize = 24 ); ax [ 1 ] . legend ( loc = 'best' , fontsize = 24 ); ax [ 2 ] . legend ( loc = 'best' , fontsize = 24 ); #fig.savefig('../images/nice_sub_plots.png') Exercise Make a grid of 2 x 3 separate plots, 3 will be empty. Just plot the functions and do not worry about cosmetics. We just want you ro see the functionality. In [59]: # your code here In [123]: # %load solutions/six_subplots.py # First get the data f = logistic ( x , 2.0 , 1.0 ) g = stretch_tanh ( x , 2.0 , 0.5 , 0.5 ) h = relu ( x ) fig , ax = plt . subplots ( 2 , 3 , figsize = ( 20 , 6 )) # Create figure object # Make actual plots ax [ 0 ][ 0 ] . plot ( x , f , lw = 4 , ls = '-' , label = r '$L(x;1)$' ) ax [ 1 ][ 1 ] . plot ( x , g , lw = 4 , ls = '--' , label = r '$\\tanh(2x)$' ) ax [ 1 ][ 2 ] . plot ( x , h , lw = 4 , ls = '-.' , label = r '$relu(x; 0.01)$' ) ax [ 0 ][ 2 ] . plot ( x , h , lw = 4 , ls = '-.' , label = r '$relu(x; 0.01)$' ) Out[123]: [ ] 3 - Simple Linear Regression Linear regression and its many extensions are a workhorse of the statistics and data science community, both in application and as a reference point for other models. Most of the major concepts in machine learning can be and often are discussed in terms of various linear regression models. Thus, this section will introduce you to building and fitting linear regression models and some of the process behind it, so that you can 1) fit models to data you encounter 2) experiment with different kinds of linear regression and observe their effects 3) see some of the technology that makes regression models work. Linear regression with a toy dataset We first examine a toy problem, focusing our efforts on fitting a linear model to a small dataset with three observations. Each observation consists of one predictor $x_i$ and one response $y_i$ for $i = 1, 2, 3$, \\begin{align*} (x , y) = \\{(x_1, y_1), (x_2, y_2), (x_3, y_3)\\}. \\end{align*} To be very concrete, let's set the values of the predictors and responses. \\begin{equation*} (x , y) = \\{(1, 2), (2, 2), (3, 4)\\} \\end{equation*} There is no line of the form $\\beta_0 + \\beta_1 x = y$ that passes through all three observations, since the data are not collinear. Thus our aim is to find the line that best fits these observations in the least-squares sense , as discussed in lecture. Exercise (for home) Make two numpy arrays out of this data, x_train and y_train Check the dimentions of these arrays Try to reshape them into a different shape Make points into a very simple scatterplot Make a better scatterplot In [61]: # your code here In [62]: # solution x_train = np . array ([ 1 , 2 , 3 ]) y_train = np . array ([ 2 , 3 , 6 ]) type ( x_train ) Out[62]: numpy.ndarray In [63]: x_train . shape Out[63]: (3,) In [64]: x_train = x_train . reshape ( 3 , 1 ) x_train . shape Out[64]: (3, 1) In [65]: # %load solutions/simple_scatterplot.py # Make a simple scatterplot plt . scatter ( x_train , y_train ) # check dimensions print ( x_train . shape , y_train . shape ) (3, 1) (3,) In [66]: # %load solutions/nice_scatterplot.py def nice_scatterplot ( x , y , title ): # font size f_size = 18 # make the figure fig , ax = plt . subplots ( 1 , 1 , figsize = ( 8 , 5 )) # Create figure object # set axes limits to make the scale nice ax . set_xlim ( np . min ( x ) - 1 , np . max ( x ) + 1 ) ax . set_ylim ( np . min ( y ) - 1 , np . max ( y ) + 1 ) # adjust size of tickmarks in axes ax . tick_params ( labelsize = f_size ) # remove tick labels ax . tick_params ( labelbottom = False , bottom = False ) # adjust size of axis label ax . set_xlabel ( r '$x$' , fontsize = f_size ) ax . set_ylabel ( r '$y$' , fontsize = f_size ) # set figure title label ax . set_title ( title , fontsize = f_size ) # you may set up grid with this ax . grid ( True , lw = 1.75 , ls = '--' , alpha = 0.15 ) # make actual plot (Notice the label argument!) #ax.scatter(x, y, label=r'$my points$') #ax.scatter(x, y, label='$my points$') ax . scatter ( x , y , label = r '$my\\,points$' ) ax . legend ( loc = 'best' , fontsize = f_size ); return ax nice_scatterplot ( x_train , y_train , 'hello nice plot' ) Out[66]: Formulae Linear regression is special among the models we study because it can be solved explicitly. While most other models (and even some advanced versions of linear regression) must be solved itteratively, linear regression has a formula where you can simply plug in the data. For the single predictor case it is: \\begin{align} \\beta_1 &= \\frac{\\sum_{i=1}&#94;n{(x_i-\\bar{x})(y_i-\\bar{y})}}{\\sum_{i=1}&#94;n{(x_i-\\bar{x})&#94;2}}\\\\ \\beta_0 &= \\bar{y} - \\beta_1\\bar{x}\\ \\end{align} Where $\\bar{y}$ and $\\bar{x}$ are the mean of the y values and the mean of the x values, respectively. Building a model from scratch In this part, we will solve the equations for simple linear regression and find the best fit solution to our toy problem. The snippets of code below implement the linear regression equations on the observed predictors and responses, which we'll call the training data set. Let's walk through the code. We have to reshape our arrrays to 2D. We will see later why. Exercise make an array with shape (2,3) reshape it to a size that you want In [67]: # your code here In [68]: #solution xx = np . array ([[ 1 , 2 , 3 ],[ 4 , 6 , 8 ]]) xxx = xx . reshape ( - 1 , 2 ) xxx . shape Out[68]: (3, 2) In [69]: # Reshape to be a proper 2D array x_train = x_train . reshape ( x_train . shape [ 0 ], 1 ) y_train = y_train . reshape ( y_train . shape [ 0 ], 1 ) print ( x_train . shape ) (3, 1) In [70]: # first, compute means y_bar = np . mean ( y_train ) x_bar = np . mean ( x_train ) # build the two terms numerator = np . sum ( ( x_train - x_bar ) * ( y_train - y_bar ) ) denominator = np . sum (( x_train - x_bar ) ** 2 ) print ( numerator . shape , denominator . shape ) #check shapes () () Why the empty brackets? (The numerator and denominator are scalars, as expected.) In [71]: #slope beta1 beta_1 = numerator / denominator #intercept beta0 beta_0 = y_bar - beta_1 * x_bar print ( \"The best-fit line is {0:3.2f} + {1:3.2f} * x\" . format ( beta_0 , beta_1 )) print ( f 'The best fit is {beta_0} ' ) The best-fit line is -0.33 + 2.00 * x The best fit is -0.3333333333333335 Exercise Turn the code from the above cells into a function called simple_linear_regression_fit , that inputs the training data and returns beta0 and beta1 . To do this, copy and paste the code from the above cells below and adjust the code as needed, so that the training data becomes the input and the betas become the output. def simple_linear_regression_fit ( x_train : np . ndarray , y_train : np . ndarray ) -> np . ndarray : return Check your function by calling it with the training data from above and printing out the beta values. In [72]: # Your code here In [73]: # %load solutions/simple_linear_regression_fit.py def simple_linear_regression_fit ( x_train : np . ndarray , y_train : np . ndarray ) -> np . ndarray : \"\"\" Inputs: x_train: a (num observations by 1) array holding the values of the predictor variable y_train: a (num observations by 1) array holding the values of the response variable Returns: beta_vals: a (num_features by 1) array holding the intercept and slope coeficients \"\"\" # Check input array sizes if len ( x_train . shape ) < 2 : print ( \"Reshaping features array.\" ) x_train = x_train . reshape ( x_train . shape [ 0 ], 1 ) if len ( y_train . shape ) < 2 : print ( \"Reshaping observations array.\" ) y_train = y_train . reshape ( y_train . shape [ 0 ], 1 ) # first, compute means y_bar = np . mean ( y_train ) x_bar = np . mean ( x_train ) # build the two terms numerator = np . sum ( ( x_train - x_bar ) * ( y_train - y_bar ) ) denominator = np . sum (( x_train - x_bar ) ** 2 ) #slope beta1 beta_1 = numerator / denominator #intercept beta0 beta_0 = y_bar - beta_1 * x_bar return np . array ([ beta_0 , beta_1 ]) Let's run this function and see the coefficients In [74]: x_train = np . array ([ 1 , 2 , 3 ]) y_train = np . array ([ 2 , 2 , 4 ]) betas = simple_linear_regression_fit ( x_train , y_train ) beta_0 = betas [ 0 ] beta_1 = betas [ 1 ] print ( \"The best-fit line is {0:8.6f} + {1:8.6f} * x\" . format ( beta_0 , beta_1 )) Reshaping features array. Reshaping observations array. The best-fit line is 0.666667 + 1.000000 * x Exercise Do the values of beta0 and beta1 seem reasonable? Plot the training data using a scatter plot. Plot the best fit line with beta0 and beta1 together with the training data. In [75]: # Your code here In [76]: # %load solutions/best_fit_scatterplot.py fig_scat , ax_scat = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) # Plot best-fit line x_train = np . array ([[ 1 , 2 , 3 ]]) . T best_fit = beta_0 + beta_1 * x_train ax_scat . scatter ( x_train , y_train , s = 300 , label = 'Training Data' ) ax_scat . plot ( x_train , best_fit , ls = '--' , label = 'Best Fit Line' ) ax_scat . set_xlabel ( r '$x_ {train} $' ) ax_scat . set_ylabel ( r '$y$' ); The values of beta0 and beta1 seem roughly reasonable. They capture the positive correlation. The line does appear to be trying to get as close as possible to all the points. 4 - Building a model with statsmodels and sklearn Now that we can concretely fit the training data from scratch, let's learn two python packages to do it all for us: statsmodels and scikit-learn (sklearn) . Our goal is to show how to implement simple linear regression with these packages. For an important sanity check, we compare the $\\beta$ values from statsmodels and sklearn to the $\\beta$ values that we found from above with our own implementation. For the purposes of this lab, statsmodels and sklearn do the same thing. More generally though, statsmodels tends to be easier for inference [finding the values of the slope and intercept and dicussing uncertainty in those values], whereas sklearn has machine-learning algorithms and is better for prediction [guessing y values for a given x value]. (Note that both packages make the same guesses, it's just a question of which activity they provide more support for. Note: statsmodels and sklearn are different packages! Unless we specify otherwise, you can use either one. Below is the code for statsmodels . Statsmodels does not by default include the column of ones in the $X$ matrix, so we include it manually with sm.add_constant . In [77]: import statsmodels.api as sm In [78]: # create the X matrix by appending a column of ones to x_train X = sm . add_constant ( x_train ) # this is the same matrix as in our scratch problem! print ( X ) # build the OLS model (ordinary least squares) from the training data toyregr_sm = sm . OLS ( y_train , X ) # do the fit and save regression info (parameters, etc) in results_sm results_sm = toyregr_sm . fit () # pull the beta parameters out from results_sm beta0_sm = results_sm . params [ 0 ] beta1_sm = results_sm . params [ 1 ] print ( f 'The regression coef from statsmodels are: beta_0 = {beta0_sm:8.6f} and beta_1 = {beta1_sm:8.6f} ' ) [[1. 1.] [1. 2.] [1. 3.]] The regression coef from statsmodels are: beta_0 = 0.666667 and beta_1 = 1.000000 Besides the beta parameters, results_sm contains a ton of other potentially useful information. In [79]: import warnings warnings . filterwarnings ( 'ignore' ) print ( results_sm . summary ()) OLS Regression Results ============================================================================== Dep. Variable: y R-squared: 0.750 Model: OLS Adj. R-squared: 0.500 Method: Least Squares F-statistic: 3.000 Date: Thu, 19 Sep 2019 Prob (F-statistic): 0.333 Time: 16:11:35 Log-Likelihood: -2.0007 No. Observations: 3 AIC: 8.001 Df Residuals: 1 BIC: 6.199 Df Model: 1 Covariance Type: nonrobust ============================================================================== coef std err t P>|t| [0.025 0.975] ------------------------------------------------------------------------------ const 0.6667 1.247 0.535 0.687 -15.181 16.514 x1 1.0000 0.577 1.732 0.333 -6.336 8.336 ============================================================================== Omnibus: nan Durbin-Watson: 3.000 Prob(Omnibus): nan Jarque-Bera (JB): 0.531 Skew: -0.707 Prob(JB): 0.767 Kurtosis: 1.500 Cond. No. 6.79 ============================================================================== Warnings: [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. Now let's turn our attention to the sklearn library. In [80]: from sklearn import linear_model In [81]: # build the least squares model toyregr = linear_model . LinearRegression () # save regression info (parameters, etc) in results_skl results = toyregr . fit ( x_train , y_train ) # pull the beta parameters out from results_skl beta0_skl = toyregr . intercept_ beta1_skl = toyregr . coef_ [ 0 ] print ( \"The regression coefficients from the sklearn package are: beta_0 = {0:8.6f} and beta_1 = {1:8.6f} \" . format ( beta0_skl , beta1_skl )) The regression coefficients from the sklearn package are: beta_0 = 0.666667 and beta_1 = 1.000000 We should feel pretty good about ourselves now, and we're ready to move on to a real problem! The scikit-learn library and the shape of things Before diving into a \"real\" problem, let's discuss more of the details of sklearn . Scikit-learn is the main Python machine learning library. It consists of many learners which can learn models from data, as well as a lot of utility functions such as train_test_split() . Use the following to add the library into your code: import sklearn In scikit-learn , an estimator is a Python object that implements the methods fit(X, y) and predict(T) Let's see the structure of scikit-learn needed to make these fits. fit() always takes two arguments: estimator . fit ( Xtrain , ytrain ) We will consider two estimators in this lab: LinearRegression and KNeighborsRegressor . It is very important to understand that Xtrain must be in the form of a 2x2 array with each row corresponding to one sample, and each column corresponding to the feature values for that sample. ytrain on the other hand is a simple array of responses. These are continuous for regression problems. Practice with sklearn and a real dataset We begin by loading up the mtcars dataset. This data was extracted from the 1974 Motor Trend US magazine, and comprises of fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models). We will load this data to a dataframe with 32 observations on 11 (numeric) variables. Here is an explanation of the features: mpg is Miles/(US) gallon cyl is Number of cylinders, disp is Displacement (cu.in.), hp is Gross horsepower, drat is Rear axle ratio, wt is the Weight (1000 lbs), qsec is 1/4 mile time, vs is Engine (0 = V-shaped, 1 = straight), am is Transmission (0 = automatic, 1 = manual), gear is the Number of forward gears, carb is Number of carburetors. In [82]: import pandas as pd #load mtcars dfcars = pd . read_csv ( \"../data/mtcars.csv\" ) dfcars . head () Out[82]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unnamed: 0 mpg cyl disp hp drat wt qsec vs am gear carb 0 Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 1 Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 2 Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 3 Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 4 Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 In [83]: # Fix the column title dfcars = dfcars . rename ( columns = { \"Unnamed: 0\" : \"car name\" }) dfcars . head () Out[83]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } car name mpg cyl disp hp drat wt qsec vs am gear carb 0 Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 1 Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 2 Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 3 Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 4 Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 In [84]: dfcars . shape Out[84]: (32, 12) Searching for values: how many cars have 4 gears? In [85]: len ( dfcars [ dfcars . gear == 4 ] . drop_duplicates ( subset = 'car name' , keep = 'first' )) Out[85]: 12 Next, let's split the dataset into a training set and test set. In [86]: # split into training set and testing set from sklearn.model_selection import train_test_split #set random_state to get the same split every time traindf , testdf = train_test_split ( dfcars , test_size = 0.2 , random_state = 42 ) In [87]: # testing set is around 20% of the total data; training set is around 80% print ( \"Shape of full dataset is: {0} \" . format ( dfcars . shape )) print ( \"Shape of training dataset is: {0} \" . format ( traindf . shape )) print ( \"Shape of test dataset is: {0} \" . format ( testdf . shape )) Shape of full dataset is: (32, 12) Shape of training dataset is: (25, 12) Shape of test dataset is: (7, 12) Now we have training and test data. We still need to select a predictor and a response from this dataset. Keep in mind that we need to choose the predictor and response from both the training and test set. You will do this in the exercises below. However, we provide some starter code for you to get things going. In [88]: traindf . head () Out[88]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } car name mpg cyl disp hp drat wt qsec vs am gear carb 25 Fiat X1-9 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 12 Merc 450SL 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 0 Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 4 Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 16 Chrysler Imperial 14.7 8 440.0 230 3.23 5.345 17.42 0 0 3 4 In [89]: # Extract the response variable that we're interested in y_train = traindf . mpg y_train Out[89]: 25 27.3 12 17.3 0 21.0 4 18.7 16 14.7 5 18.1 13 15.2 11 16.4 23 13.3 1 21.0 2 22.8 26 26.0 3 21.4 21 15.5 27 30.4 22 15.2 18 30.4 31 21.4 20 21.5 7 24.4 10 17.8 14 10.4 28 15.8 19 33.9 6 14.3 Name: mpg, dtype: float64 Exercise Use slicing to get the same vector y_train Now, notice the shape of y_train . In [90]: y_train . shape , type ( y_train ) Out[90]: ((25,), pandas.core.series.Series) Array reshape This is a 1D array as should be the case with the Y array. Remember, sklearn requires a 2D array only for the predictor array. You will have to pay close attention to this in the exercises later. Sklearn doesn't care too much about the shape of y_train . The whole reason we went through that whole process was to show you how to reshape your data into the correct format. IMPORTANT: Remember that your response variable ytrain can be a vector but your predictor variable xtrain must be an array! 5 - Example: Simple linear regression with automobile data We will now use sklearn to predict automobile mileage per gallon (mpg) and evaluate these predictions. We already loaded the data and split them into a training set and a test set. We need to choose the variables that we think will be good predictors for the dependent variable mpg . Exercise in pairs Pick one variable to use as a predictor for simple linear regression. Discuss your reasons with the person next to you. Justify your choice with some visualizations. Is there a second variable you'd like to use? For example, we're not doing multiple linear regression here, but if we were, is there another variable you'd like to include if we were using two predictors? In [91]: x_wt = dfcars . wt x_wt . shape Out[91]: (32,) In [92]: # Your code here In [125]: # %load solutions/cars_simple_EDA.py y_mpg = dfcars . mpg x_wt = dfcars . wt x_hp = dfcars . hp fig_wt , ax_wt = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax_wt . scatter ( x_wt , y_mpg ) ax_wt . set_xlabel ( r 'Car Weight' ) ax_wt . set_ylabel ( r 'Car MPG' ) fig_hp , ax_hp = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax_hp . scatter ( x_hp , y_mpg ) ax_hp . set_xlabel ( r 'Car HP' ) ax_hp . set_ylabel ( r 'Car MPG' ) Out[125]: Text(0, 0.5, 'Car MPG') Exercise Use sklearn to fit the training data using simple linear regression. Use the model to make mpg predictions on the test set. Plot the data and the prediction. Print out the mean squared error for the training set and the test set and compare. In [94]: from sklearn.linear_model import LinearRegression from sklearn.model_selection import train_test_split from sklearn.metrics import mean_squared_error dfcars = pd . read_csv ( \"../data/mtcars.csv\" ) dfcars = dfcars . rename ( columns = { \"Unnamed: 0\" : \"name\" }) dfcars . head () Out[94]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name mpg cyl disp hp drat wt qsec vs am gear carb 0 Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 1 Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 2 Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 3 Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 4 Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 In [95]: traindf , testdf = train_test_split ( dfcars , test_size = 0.2 , random_state = 42 ) y_train = np . array ( traindf . mpg ) X_train = np . array ( traindf . wt ) X_train = X_train . reshape ( X_train . shape [ 0 ], 1 ) In [96]: y_test = np . array ( testdf . mpg ) X_test = np . array ( testdf . wt ) X_test = X_test . reshape ( X_test . shape [ 0 ], 1 ) In [97]: # Let's take another look at our data dfcars . head () Out[97]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name mpg cyl disp hp drat wt qsec vs am gear carb 0 Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 1 Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 2 Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 3 Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 4 Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 In [98]: # And out train and test sets y_train . shape , X_train . shape Out[98]: ((25,), (25, 1)) In [99]: y_test . shape , X_test . shape Out[99]: ((7,), (7, 1)) In [100]: #create linear model regression = LinearRegression () #fit linear model regression . fit ( X_train , y_train ) predicted_y = regression . predict ( X_test ) r2 = regression . score ( X_test , y_test ) print ( f 'R&#94;2 = {r2:.5} ' ) R&#94;2 = 0.68798 In [101]: print ( regression . score ( X_train , y_train )) print ( mean_squared_error ( predicted_y , y_test )) print ( mean_squared_error ( y_train , regression . predict ( X_train ))) print ( 'Coefficients: \\n ' , regression . coef_ [ 0 ], regression . intercept_ ) 0.7701379909791617 12.475985659918823 7.773697766387515 Coefficients: -5.336941400557082 36.93731031351842 In [102]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( y_test , predicted_y , 'o' ) grid = np . linspace ( np . min ( dfcars . mpg ), np . max ( dfcars . mpg ), 100 ) ax . plot ( grid , grid , color = \"black\" ) # 45 degree line ax . set_xlabel ( \"actual y\" ) ax . set_ylabel ( \"predicted y\" ) fig1 , ax1 = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax1 . plot ( dfcars . wt , dfcars . mpg , 'o' ) xgrid = np . linspace ( np . min ( dfcars . wt ), np . max ( dfcars . wt ), 100 ) ax1 . plot ( xgrid , regression . predict ( xgrid . reshape ( 100 , 1 ))) Out[102]: [ ] 6 - $k$-nearest neighbors Now that you're familiar with sklearn , you're ready to do a KNN regression. Sklearn's regressor is called sklearn.neighbors.KNeighborsRegressor . Its main parameter is the number of nearest neighbors . There are other parameters such as the distance metric (default for 2 order is the Euclidean distance). For a list of all the parameters see the Sklearn kNN Regressor Documentation . Let's use $5$ nearest neighbors. In [103]: # Import the library from sklearn.neighbors import KNeighborsRegressor In [104]: # Set number of neighbors k = 5 knnreg = KNeighborsRegressor ( n_neighbors = k ) In [105]: # Fit the regressor - make sure your numpy arrays are the right shape knnreg . fit ( X_train , y_train ) # Evaluate the outcome on the train set using R&#94;2 r2_train = knnreg . score ( X_train , y_train ) # Print results print ( f 'kNN model with {k} neighbors gives R&#94;2 on the train set: {r2_train:.5} ' ) kNN model with 5 neighbors gives R&#94;2 on the train set: 0.87181 In [106]: knnreg . predict ( X_test ) Out[106]: array([20.14, 14. , 15.3 , 26.3 , 19.56, 17.06, 16.88]) Exercise Calculate and print the $R&#94;{2}$ score on the test set In [107]: # Your code here Not so good? Lets vary the number of neighbors and see what we get. In [108]: # Make our lives easy by storing the different regressors in a dictionary regdict = {} # Make our lives easier by entering the k values from a list k_list = [ 1 , 2 , 4 , 15 ] # Do a bunch of KNN regressions for k in k_list : knnreg = KNeighborsRegressor ( n_neighbors = k ) knnreg . fit ( X_train , y_train ) # Store the regressors in a dictionary regdict [ k ] = knnreg # Print the dictionary to see what we have regdict Out[108]: {1: KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=None, n_neighbors=1, p=2, weights='uniform'), 2: KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=None, n_neighbors=2, p=2, weights='uniform'), 4: KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=None, n_neighbors=4, p=2, weights='uniform'), 15: KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=None, n_neighbors=15, p=2, weights='uniform')} Now let's plot all the k values in same plot. In [109]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( dfcars . wt , dfcars . mpg , 'o' , label = \"data\" ) xgrid = np . linspace ( np . min ( dfcars . wt ), np . max ( dfcars . wt ), 100 ) # let's unpack the dictionary to its elements (items) which is the k and Regressor for k , regressor in regdict . items (): predictions = regressor . predict ( xgrid . reshape ( - 1 , 1 )) ax . plot ( xgrid , predictions , label = \" {} -NN\" . format ( k )) ax . legend (); Exercise Explain what you see in the graph. Hint Notice how the $1$-NN goes through every point on the training set but utterly fails elsewhere. Lets look at the scores on the training set. In [110]: ks = range ( 1 , 15 ) # Grid of k's scores_train = [] # R2 scores for k in ks : # Create KNN model knnreg = KNeighborsRegressor ( n_neighbors = k ) # Fit the model to training data knnreg . fit ( X_train , y_train ) # Calculate R&#94;2 score score_train = knnreg . score ( X_train , y_train ) scores_train . append ( score_train ) # Plot fig , ax = plt . subplots ( 1 , 1 , figsize = ( 12 , 8 )) ax . plot ( ks , scores_train , 'o-' ) ax . set_xlabel ( r '$k$' ) ax . set_ylabel ( r '$R&#94; {2} $' ) Out[110]: Text(0, 0.5, '$R&#94;{2}$') Exercise Why do we get a perfect $R&#94;2$ at k=1 for the training set? Make the same plot as above on the test set. What is the best $k$? In [111]: # Your code here In [127]: # %load solutions/knn_regression.py ks = range ( 1 , 7 ) # Grid of k's scores_test = [] # R2 scores for k in ks : knnreg = KNeighborsRegressor ( n_neighbors = k ) # Create KNN model knnreg . fit ( X_train , y_train ) # Fit the model to training data score_test = knnreg . score ( X_test , y_test ) # Calculate R&#94;2 score scores_test . append ( score_test ) # Plot fig , ax = plt . subplots ( 1 , 1 , figsize = ( 12 , 8 )) ax . plot ( ks , scores_test , 'o-' , ms = 12 ) ax . set_xlabel ( r '$k$' ) ax . set_ylabel ( r '$R&#94; {2} $' ) Out[127]: Text(0, 0.5, '$R&#94;{2}$') In [ ]: # solution to previous exercise r2_test = knnreg . score ( X_test , y_test ) print ( f 'kNN model with {k} neighbors gives R&#94;2 on the test set: {r2_test:.5} ' ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab03/notebook/"},{"title":"Advanced Section 1: Linear Algebra and Hypothesis Testing","text":"Slides Advanced Section: Linear Algebra and Hypothesis Testing [pptx] Advanced Section: Linear Algebra and Hypothesis Testing [pdf]","tags":"A-section","url":"a-section/a-section1/"},{"title":"Lecture 5: Linear Regression","text":"Slides Lecture 5: Linear Regression [pptx] Lecture 5: Linear Regression [pdf]","tags":"lectures","url":"lectures/lecture5/"},{"title":"Lecture 4: Introduction to Regression","text":"Slides Lecture4: Introduction to Regression [pptx] Lecture 4: Introduction to Regression [pdf]","tags":"lectures","url":"lectures/lecture4/"},{"title":"S-Section 01: Introduction to Web Scraping","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109A Introduction to Data Science Standard Section 1: Introduction to Web Scraping Harvard University Fall 2019 Instructors : Pavlos Protopapas, Kevin Rader, and Chris Tanner Section Leaders : Marios Mattheakis, Abhimanyu (Abhi) Vasishth, Robbert (Rob) Struyven In [ ]: ## RUN THIS CELL TO GET THE RIGHT FORMATTING import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\" ) . text HTML ( styles ) When we're done today, you will approach messy real-world data with confidence that you can get it into a format that you can manipulate. Specifically, our learning objectives are: Understand the structure of an HTML document and use that structure to extract desired information Use Python data structures such as lists, dictionaries, and Pandas DataFrames to store and manipulate information Identify some other (semi-)structured formats commonly used for storing and transferring data, such as JSON and CSV Practice using Python packages such as BeautifulSoup and Pandas , including how to navigate their documentation to find functionality. In [ ]: % matplotlib inline import numpy as np import matplotlib.pyplot as plt import pandas as pd import seaborn as sns sns . set_style ( \"whitegrid\" ) sns . set_context ( \"notebook\" ) import json import requests from bs4 import BeautifulSoup from IPython.display import HTML In [ ]: # Setting up 'requests' to make HTTPS requests properly takes some extra steps... we'll skip them for now. requests . packages . urllib3 . disable_warnings () import warnings warnings . filterwarnings ( \"ignore\" ) Goals Is science becoming more collaborative over time? How about literature? Are there a few \"geniuses\" or lots of hard workers? One way we might answer those questions is by looking at Nobel Prizes. We could ask questions like: Has anyone won a prize more than once? How has the total number of recipients changed over time? How has the number of recipients per award changed over time? To answer these questions, we'll need data: who received what award when . Before we dive into acquiring this data the way we've been teaching in class, let's pause to ask: what are 5 different approaches we could take to acquiring Nobel Prize data ? When possible: find a structured dataset (.csv,.json,.xls) After a google search we stumble upon this dataset on github . It is also in the section folder named github-nobel-prize-winners.csv . We use pandas to read it: In [ ]: df = pd . read_csv ( \"../data/github-nobel-prize-winners.csv\" ) df . head () Or you may want to read an xlsx file: (Potential missing package; you might need to run the following command in your terminal first: !conda install xlrd ) In [ ]: df = pd . read_excel ( \"../data/github-nobel-prize-winners.xlsx\" ) df . head () QUIZ: Did anyone recieve the Nobel Prize more than once? How would you check if anyone recieved more than one nobel prize? In [ ]: # list storing all the names name_winners = [] for name in df . winner : # Check if we already encountered this name: if name in name_winners : # if so, print the name print ( name ) else : # otherwhise the name to the list name_winners . append ( name ) We don't want to print \"No Prize was Awarded\" all the time. In [ ]: # Your code here How can we make this into a oneligner? In [ ]: winners = [] [ print ( name ) if ( name in winners and name != \"No Prize was Awarded\" ) else winners . append ( name ) for name in df . winner ]; Otherwhise: WEB SCRAPING Turns out that https://www.nobelprize.org/prizes/lists/all-nobel-prizes/ has the data we want. Let's take a look at the website and to look at the underhood HTML: right-click and click on inspect . Try to find structure in the tree-structured HTML. But the nobelprize.org server is a little slow sometimes. Fortunately, the Internet Archive periodically crawls most of the Internet and saves what it finds. (That's a lot of data!) So let's grab the data from the Archive's \"Wayback Machine\" (great name!). We'll just give you the direct URL, but at the very end you'll see how we can get it out of a JSON response from the Wayback Machine API. In [ ]: snapshot_url = 'http://web.archive.org/web/20180820111639/https://www.nobelprize.org/prizes/lists/all-nobel-prizes/' In [ ]: snapshot = requests . get ( snapshot_url ) snapshot What is a this Response [200]? Let's google: response 200 meaning . All possible codes here . In [ ]: type ( snapshot ) Try to request \"www.xoogle.be\"? What happens? In [ ]: snapshot_url2 = 'http://web.archive.org/web/20180820111639/https://www.xoogle.be' snapshot = requests . get ( snapshot_url2 ) snapshot Always remember to \"not to be evil\" when scraping with requests! If downloading multiple pages (like you will be on HW1), always put a delay between requests (e.g, time.sleep(1) , with the time library) so you don't unwittingly hammer someone's webserver and/or get blocked. In [ ]: snapshot = requests . get ( snapshot_url ) raw_html = snapshot . text print ( raw_html [: 500 ]) Regular Expressions You can find specific patterns or strings in text by using Regular Expressions: This is a pattern matching mechanism used throughout Computer Science and programming (it's not just specific to Python). Some great resources that we recommend, if you are interested in them (could be very useful for a homework problem): https://docs.python.org/3.3/library/re.html https://regexone.com https://docs.python.org/3/howto/regex.html . Specify a specific sequence with the help of regex special characters. Some examples: \\S : Matches any character which is not a Unicode whitespace character \\d : Matches any Unicode decimal digit * : Causes the resulting RE to match 0 or more repetitions of the preceding RE, as many repetitions as are possible. Let's find all the occurances of 'Marie' in our raw_html: In [ ]: import re In [ ]: re . findall ( r 'Marie' , raw_html ) Using \\S to match 'Marie' + ' ' + 'any character which is not a Unicode whitespace character': In [ ]: re . findall ( r 'Marie \\S' , raw_html ) How would we find their lastnames that comes after Marie? In [ ]: # Your code here Now, we have all our data in the notebook. Unfortunately, it is the form of one really long string, which is hard to work with directly. This is where BeautifulSoup comes in. Parse the HTML with BeautifulSoup In [ ]: soup = BeautifulSoup ( raw_html , 'html.parser' ) Key BeautifulSoup functions we'll be using in this section: tag.prettify() : Returns cleaned-up version of raw HTML, useful for printing tag.select(selector) : Return a list of nodes matching a CSS selector tag.select_one(selector) : Return the first node matching a CSS selector tag.text/soup.get_text() : Returns visible text of a node (e.g.,\" Some text \" -> \"Some text\") tag.contents : A list of the immediate children of this node You can also use these functions to find nodes. tag.find_all(tag_name, attrs=attributes_dict) : Returns a list of matching nodes tag.find(tag_name, attrs=attributes_dict) : Returns first matching node BeautifulSoup is a very powerful library -- much more info here: https://www.crummy.com/software/BeautifulSoup/bs4/doc/ Let's practice some BeautifulSoup commands... Print a cleaned-up version of the raw HTML In [ ]: # Your code here Find the first \"title\" object In [ ]: # Your code here Extract the text of first \"title\" object In [ ]: # Your code here Extracting award data Let's use the structure of the HTML document to extract the data we want. From inspecting the page in DevTools, we found that each award is in a div with a by_year class. Let's get all of them. In [ ]: award_nodes = soup . select ( '.by_year' ) len ( award_nodes ) Let's pull out an example. In [ ]: award_node = award_nodes [ 200 ] In [ ]: HTML ( award_node . prettify ()) Let's practice getting data out of a BS Node The prize title In [ ]: award_node . select_one ( 'h3' ) . text How do we separate the title from the year? In [ ]: # Your code here How do we separate the year from the year? In [ ]: # Your code here Let's put them into functions: In [ ]: def get_award_title ( award_node ): return award_node . select_one ( 'h3' ) . text [: - 4 ] . strip () In [ ]: def get_award_year ( award_node ): return int ( award_node . select_one ( 'h3' ) . text [ - 4 :]) Make a list of titles for all awards In [ ]: list_awards = [] for award_node in award_nodes : list_awards . append ( get_award_title ( award_node )) list_awards Let's use list comprehension: In [ ]: # Your code here The recipients How do we handle there being more than one? In [ ]: [ node . text for node in award_node . select ( 'h6 a' )] We'll leave them as a list for now, to return to this later. The prize \"motivation\" How would you get the 'motivation'/reason of the prize from the following award_node ? In [ ]: award_node = award_nodes [ 200 ] award_node In [ ]: # Your code here Putting everything into functions: In [ ]: def get_award_motivation ( award_node ): award_node = award_node . select_one ( 'p' ) if not award_node : return None return award_node . text #.lstrip('\\u201c').rstrip('\\u201d') In [ ]: def get_recipients ( award_node ): return [ node . text for node in award_node . select ( 'h6 a' )] Let's create a Pandas dataframe Now let's get all of the awards. In [ ]: awards = [] for award_node in soup . select ( '.by_year' ): recipients = get_recipients ( award_node ) award = {} award [ 'title' ] = get_award_title ( award_node ) award [ 'year' ] = get_award_year ( award_node ) award [ 'recipients' ] = recipients award [ 'num_recipients' ] = len ( recipients ) award [ 'motivation' ] = get_award_motivation ( award_node ) awards . append ( award ) In [ ]: df_awards_raw = pd . DataFrame ( awards ) In [ ]: df_awards_raw Some quick EDA. In [ ]: df_awards_raw . info () In [ ]: df_awards_raw . year . min () Hm, that's suspiciously close to a round number. Are we missing some? How about recipients? In [ ]: df_awards_raw . head () In [ ]: df_awards_raw . num_recipients . value_counts () Why do some have no recipients? In [ ]: df_awards_raw [ df_awards_raw . num_recipients == 0 ] Ok: 2018 awards have no recipients because this is a 2018 archived version of nobel prize webpage. Some past years lack awards because there actually were none that year. Let's keep only meaningful data: In [ ]: df_awards_past = df_awards_raw [ df_awards_raw . year != 2018 ] df_awards_past . info () Hm, motivation has a different number of items... why? In [ ]: df_awards_past [ df_awards_past . motivation . isnull ()] Looks like it's fine that those motivations were missing. Sort the awards by year. In [ ]: df_awards_past . sort_values ( 'year' ) . head () How many awards of each type were given? In [ ]: df_awards_past . title . value_counts () But wait, that includes the years the awards weren't offered. In [ ]: df_awards_actually_offered = df_awards_past [ df_awards_past . num_recipients > 0 ] df_awards_actually_offered . title . value_counts () When was each award first given? In [ ]: df_awards_actually_offered . groupby ( 'title' ) . year . describe () How many recipients per year? Let's include the years with missing awards; if we were to analyze further, we'd have to decide whether to include them. In [ ]: df_awards_past . plot . scatter ( x = 'year' , y = 'num_recipients' ); It's hard to see a trend when there are multiple observations per year ( why? ). Let's try looking at total num recipients by year. In [ ]: plt . figure ( figsize = [ 16 , 6 ]) # plt.plot(df_awards_past.groupby('year').num_recipients.sum(), color = 'b', linewidth='2') plt . plot ( df_awards_past . groupby ( 'year' ) . num_recipients . sum (), '-ob' , linewidth = '2' , alpha = 0.75 ) plt . title ( 'Total Nobel Awards per year' ) plt . xlabel ( 'Year' ) plt . ylabel ( 'Number of recipients' ) plt . grid ( 'on' ) plt . show (); Check out the years 1940-43? Any comment? Any trends the last 25 years? In [ ]: plt . figure ( figsize = [ 16 , 6 ]) i = 0 for award in set ( df_awards_past . title ): i += 1 year = df_awards_past [ df_awards_past [ 'title' ] == award ] . year recips = df_awards_past [ df_awards_past [ 'title' ] == award ] . num_recipients index = year > 2019 - 25 years_filtered = year [ index ] . values recips_filtered = recips [ index ] . values plt . subplot ( 2 , 3 , i ) plt . bar ( years_filtered , recips_filtered , color = 'b' , alpha = 0.7 ) plt . title ( award ) plt . xlabel ( 'Year' ) plt . ylabel ( 'Number of Recipients' ) plt . ylim ( 0 , 3 ) plt . tight_layout () End of Standard Section Extra: Did anyone recieve the Nobel Prize more than once (based upon scraped data)? Here's where it bites us that our original DataFrame isn't \"tidy\". Let's make a tidy one. In [ ]: tidy_awards = [] for idx , row in df_awards_past . iterrows (): for recipient in row [ 'recipients' ]: tidy_awards . append ( dict ( recipient = recipient , year = row [ 'year' ])) tidy_awards_df = pd . DataFrame ( tidy_awards ) tidy_awards_df . info () Now we can look at each recipient individually. In [ ]: tidy_awards_df . recipient . value_counts () Extra: Other structured data formats: JSON and CSV CSV CSV is a lowest-common-denominator format for tabular data. In [ ]: df_awards_past . to_csv ( '../data/awards.csv' , index = False ) with open ( '../data/awards.csv' , 'r' ) as f : print ( f . read ()[: 1000 ]) It loses some info, though: the recipients list became a plain string, and the reader needs to guess whether each column is numeric or not. In [ ]: pd . read_csv ( '../data/awards.csv' ) . recipients . iloc [ 20 ] JSON JSON preserves structured data, but fewer data-science tools speak it. In [ ]: df_awards_past . to_json ( '../data/awards.json' , orient = 'records' ) with open ( '../data/awards.json' , 'r' ) as f : print ( f . read ()[: 1000 ]) Lists and other basic data types are preserved. (Custom data types aren't preserved, but you'll get an error when saving.) In [ ]: pd . read_json ( '../data/awards.json' ) . recipients . iloc [ 20 ] Extra: Pickle: handy for storing data For temporary data storage in a single version of Python, pickle s will preserve your data even more faithfully, even many custom data types. But don't count on it for exchanging data or long-term storage. (In fact, don't try to load untrusted pickle s -- they can run arbitrary code!) In [ ]: df_awards_past . to_pickle ( '../data/awards.pkl' ) with open ( '../data/awards.pkl' , 'r' , encoding = 'latin1' ) as f : print ( f . read ()[: 200 ]) Yup, lots of internal Python and Pandas stuff... In [ ]: pd . read_pickle ( '../data/awards.pkl' ) . recipients . iloc [ 20 ] Extra: Formatted data output Let's make a textual table of Physics laureates by year, earliest first: In [ ]: for idx , row in df_awards_past . sort_values ( 'year' ) . iterrows (): if 'Physics' in row [ 'title' ]: print ( ' {} : {} ' . format ( row [ 'year' ], ', ' . join ( row [ 'recipients' ]))) Extra: Parsing JSON to get the Wayback Machine URL We could go to http://archive.org , search for our URL, and get the URL for the archived version there. But since you'll often need to talk with APIs, let's take this opportunity to use the Wayback Machine's API . This will also give us a chance to practice working with JSON. In [ ]: url = \"https://www.nobelprize.org/prizes/lists/all-nobel-prizes/\" # All 3 of these do the same thing. The third is my (KCA's) favorite new feature of Python 3.6. wayback_query_url = 'http://archive.org/wayback/available?url= {} ' . format ( url ) wayback_query_url = 'http://archive.org/wayback/available?url= {url} ' . format ( url = url ) wayback_query_url = f 'http://archive.org/wayback/available?url= {url} ' r = requests . get ( wayback_query_url ) We got some kind of response... what is it? In [ ]: r . text Yay, JSON ! It's usually pretty easy to work with JSON, once we parse it. In [ ]: json . loads ( r . text ) Loading responses as JSON is so common that requests has a convenience method for it: In [ ]: response_json = r . json () response_json What kind of object is this? A little Python syntax review: How can we get the snapshot URL? In [ ]: snapshot_url = response_json [ 'archived_snapshots' ][ 'closest' ][ 'url' ] snapshot_url if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"sections","url":"sections/sec_1/notebook/"},{"title":"S-Section 01: Introduction to Web Scraping","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"sections","url":"sections/sec_1/notebook-sol/"},{"title":"S-Section 01: Introduction to Web Scraping","text":"Jupyter Notebooks S-Section 1: Introduction to Web Scraping","tags":"sections","url":"sections/section1/"},{"title":"Lab 2:","text":"Jupyter Notebooks Lab 2: Web Scraping with Beautiful Soup Lab 2: More Pandas (extra practice)","tags":"labs","url":"labs/lab02/"},{"title":"Lab 02: More Pandas","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109A Introduction to Data Science Lab 2: Pandas and Web Scraping with Beautiful Soup Harvard University Fall 2019 Instructors: Pavlos Protopapas, Kevin Rader, and Chris Tanner Lab Instructors: Chris Tanner and Eleni Kaxiras Authors: Rahul Dave, David Sondak, Will Claybaugh, Pavlos Protopapas, Chris Tanner, Eleni Kaxiras In [1]: ## RUN THIS CELL TO GET THE RIGHT FORMATTING from IPython.core.display import HTML def css_styling (): styles = open ( \"../../styles/cs109.css\" , \"r\" ) . read () return HTML ( styles ) css_styling () Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Table of Contents Learning Goals Loading and Cleaning with Pandas Parsing and Completing the Dataframe Grouping Learning Goals About 6,000 odd \"best books\" were fetched and parsed from Goodreads . The \"bestness\" of these books came from a proprietary formula used by Goodreads and published as a list on their web site. We parsed the page for each book and saved data from all these pages in a tabular format as a CSV file. In this lab we'll clean and further parse the data. We'll then do some exploratory data analysis to answer questions about these best books and popular genres. By the end of this lab, you should be able to: Load and systematically address missing values, ancoded as NaN values in our data set, for example, by removing observations associated with these values. Parse columns in the dataframe to create new dataframe columns. Use groupby to aggregate data on a particular feature column, such as author. This lab corresponds to lectures #1, #2, and #3 and maps on to homework #1 and further. Basic EDA workflow (From the lecture, repeated here for convenience). The basic workflow is as follows: Build a DataFrame from the data (ideally, put all data in this object) Clean the DataFrame. It should have the following properties: Each row describes a single object Each column describes a property of that object Columns are numeric whenever appropriate Columns contain atomic properties that cannot be further decomposed Explore global properties . Use histograms, scatter plots, and aggregation functions to summarize the data. Explore group properties . Use groupby and small multiples to compare subsets of the data. This process transforms your data into a format which is easier to work with, gives you a basic overview of the data's properties, and likely generates several questions for you to followup in subsequent analysis. Part 1: Loading and Cleaning with Pandas Read in the goodreads.csv file, examine the data, and do any necessary data cleaning. Here is a description of the columns (in order) present in this csv file: rating: the average rating on a 1-5 scale achieved by the book review_count: the number of Goodreads users who reviewed this book isbn: the ISBN code for the book booktype: an internal Goodreads identifier for the book author_url: the Goodreads (relative) URL for the author of the book year: the year the book was published genre_urls: a string with '|' separated relative URLS of Goodreads genre pages dir: a directory identifier internal to the scraping code rating_count: the number of ratings for this book (this is different from the number of reviews) name: the name of the book Let us see what issues we find with the data and resolve them. After loading appropriate libraries In [2]: % matplotlib inline import numpy as np import matplotlib.pyplot as plt import pandas as pd import seaborn as sns pd . set_option ( 'display.width' , 500 ) pd . set_option ( 'display.max_columns' , 100 ) Cleaning: Reading in the data We read in and clean the data from goodreads.csv . In [3]: #Read the data into a dataframe df = pd . read_csv ( \"data/goodreads.csv\" , encoding = 'utf-8' ) #Examine the first few rows of the dataframe df Out[3]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 4.40 136455 0439023483 good_reads:book https://www.goodreads.com/author/show/153394.Suzanne_Collins 2008 /genres/young-adult|/genres/science-fiction|/genres/dystopia|/genres/fantasy|/genres/science-fiction|/genres/romance|/genres/adventure|/genres/book-club|/genres/young-adult|/genres/teen|/genres/apocalyptic|/genres/post-apocalyptic|/genres/action dir01/2767052-the-hunger-games.html 2958974 The Hunger Games (The Hunger Games, #1) 0 4.41 16648 0439358078 good_reads:book https://www.goodreads.com/author/show/1077326.... 2003.0 /genres/fantasy|/genres/young-adult|/genres/fi... dir01/2.Harry_Potter_and_the_Order_of_the_Phoe... 1284478 Harry Potter and the Order of the Phoenix (Har... 1 3.56 85746 0316015849 good_reads:book https://www.goodreads.com/author/show/941441.S... 2005.0 /genres/young-adult|/genres/fantasy|/genres/ro... dir01/41865.Twilight.html 2579564 Twilight (Twilight, #1) 2 4.23 47906 0061120081 good_reads:book https://www.goodreads.com/author/show/1825.Har... 1960.0 /genres/classics|/genres/fiction|/genres/histo... dir01/2657.To_Kill_a_Mockingbird.html 2078123 To Kill a Mockingbird 3 4.23 34772 0679783261 good_reads:book https://www.goodreads.com/author/show/1265.Jan... 1813.0 /genres/classics|/genres/fiction|/genres/roman... dir01/1885.Pride_and_Prejudice.html 1388992 Pride and Prejudice 4 4.25 12363 0446675539 good_reads:book https://www.goodreads.com/author/show/11081.Ma... 1936.0 /genres/classics|/genres/historical-fiction|/g... dir01/18405.Gone_with_the_Wind.html 645470 Gone with the Wind 5 4.22 7205 0066238501 good_reads:book https://www.goodreads.com/author/show/1069006.... 1949.0 /genres/classics|/genres/young-adult|/genres/c... dir01/11127.The_Chronicles_of_Narnia.html 286677 The Chronicles of Narnia (Chronicles of Narnia... 6 4.38 10902 0060256656 good_reads:book https://www.goodreads.com/author/show/435477.S... 1964.0 /genres/childrens|/genres/young-adult|/genres/... dir01/370493.The_Giving_Tree.html 502891 The Giving Tree 7 3.79 20670 0452284244 good_reads:book https://www.goodreads.com/author/show/3706.Geo... 1945.0 /genres/classics|/genres/fiction|/genres/scien... dir01/7613.Animal_Farm.html 1364879 Animal Farm 8 4.18 12302 0345391802 good_reads:book https://www.goodreads.com/author/show/4.Dougla... 1979.0 /genres/science-fiction|/genres/humor|/genres/... dir01/11.The_Hitchhiker_s_Guide_to_the_Galaxy.... 724713 The Hitchhiker's Guide to the Galaxy (Hitchhik... 9 4.03 20937 0739326228 good_reads:book https://www.goodreads.com/author/show/614.Arth... 1997.0 /genres/fiction|/genres/historical-fiction|/ge... dir01/930.Memoirs_of_a_Geisha.html 1042679 Memoirs of a Geisha 10 3.72 34959 0307277674 good_reads:book https://www.goodreads.com/author/show/630.Dan_... 2003.0 /genres/mystery|/genres/thriller|/genres/suspe... dir01/968.The_Da_Vinci_Code.html 1220657 The Da Vinci Code (Robert Langdon, #2) 11 4.36 69524 0375831002 good_reads:book https://www.goodreads.com/author/show/11466.Ma... 2005.0 /genres/historical-fiction|/genres/young-adult... dir01/19063.The_Book_Thief.html 675431 The Book Thief 12 4.05 5516 0451527747 good_reads:book https://www.goodreads.com/author/show/8164.Lew... 1865.0 /genres/classics|/genres/childrens|/genres/you... dir01/24213.Alice_s_Adventures_in_Wonderland_T... 301702 Alice's Adventures in Wonderland & Through the... 13 3.72 10156 0743477111 good_reads:book https://www.goodreads.com/author/show/947.Will... 1597.0 /genres/classics|/genres/plays|/genres/fiction... dir01/18135.Romeo_and_Juliet.html 1211146 Romeo and Juliet 14 4.09 10082 0451525264 good_reads:book https://www.goodreads.com/author/show/13661.Vi... 1862.0 /genres/classics|/genres/historical-fiction|/g... dir01/24280.Les_Mis_rables.html 418004 Les MisÃ©rables 15 3.92 38061 NaN good_reads:book https://www.goodreads.com/author/show/498072.A... 2003.0 /genres/fiction|/genres/romance|/genres/fantas... dir01/18619684-the-time-traveler-s-wife.html 927254 The Time Traveler's Wife 16 4.58 1314 0345538374 good_reads:book https://www.goodreads.com/author/show/656983.J... 1973.0 /genres/fantasy|/genres/classics|/genres/scien... dir01/30.J_R_R_Tolkien_4_Book_Boxed_Set.html 68495 J.R.R. Tolkien 4-Book Boxed Set 17 3.60 18039 0140283331 good_reads:book https://www.goodreads.com/author/show/306.Will... 1954.0 /genres/classics|/genres/academic|/genres/scho... dir01/7624.Lord_of_the_Flies.html 1232126 Lord of the Flies 18 4.28 30815 0812550706 good_reads:book https://www.goodreads.com/author/show/589.Orso... 1985.0 /genres/science-fiction|/genres/young-adult|/g... dir01/375802.Ender_s_Game.html 624730 Ender's Game (The Ender Quintet, #1) 19 4.02 11942 0375751513 good_reads:book https://www.goodreads.com/author/show/3565.Osc... 1890.0 /genres/classics|/genres/fiction|/genres/horro... dir01/5297.The_Picture_of_Dorian_Gray.html 409478 The Picture of Dorian Gray 20 4.14 8681 0143058142 good_reads:book https://www.goodreads.com/author/show/3137322.... 1866.0 /genres/classics|/genres/cultural|/genres/russ... dir01/7144.Crime_and_Punishment.html 294297 Crime and Punishment 21 4.11 8897 0064410935 good_reads:book https://www.goodreads.com/author/show/988142.E... 1952.0 /genres/childrens|/genres/fiction|/genres/clas... dir01/24178.Charlotte_s_Web.html 662707 Charlotte's Web 22 4.20 8678 0451528824 good_reads:book https://www.goodreads.com/author/show/5350.L_M... 1908.0 /genres/fiction|/genres/young-adult|/genres/cl... dir01/8127.Anne_of_Green_Gables.html 393594 Anne of Green Gables (Anne of Green Gables, #1) 23 3.75 36955 0061122416 good_reads:book https://www.goodreads.com/author/show/566.Paul... 1988.0 /genres/fiction|/genres/classics|/genres/fanta... dir01/865.The_Alchemist.html 876518 The Alchemist 24 3.94 18581 0007491565 good_reads:book https://www.goodreads.com/author/show/1630.Ray... 1953.0 /genres/classics|/genres/fiction|/genres/scien... dir01/17470674-fahrenheit-451.html 783133 Fahrenheit 451 25 4.43 112279 0525478817 good_reads:book https://www.goodreads.com/author/show/1406384.... 2012.0 /genres/young-adult|/genres/book-club|/genres/... dir01/11870085-the-fault-in-our-stars.html 1150626 The Fault in Our Stars 26 3.79 15833 0142000671 good_reads:book https://www.goodreads.com/author/show/585.John... 1937.0 /genres/fiction|/genres/classics|/genres/acade... dir01/890.Of_Mice_and_Men.html 1070755 Of Mice and Men 27 4.04 13214 0440498058 good_reads:book https://www.goodreads.com/author/show/106.Made... 1962.0 /genres/fantasy|/genres/young-adult|/genres/cl... dir01/18131.A_Wrinkle_in_Time.html 420001 A Wrinkle in Time (A Wrinkle in Time Quintet, #1) 28 3.94 11736 0393970124 good_reads:book https://www.goodreads.com/author/show/6988.Bra... 1897.0 /genres/classics|/genres/horror|/genres/fictio... dir01/17245.Dracula.html 429079 Dracula 29 4.24 10614 0345418263 good_reads:book https://www.goodreads.com/author/show/12521.Wi... 1973.0 /genres/fantasy|/genres/classics|/genres/roman... dir01/21787.The_Princess_Bride.html 457219 The Princess Bride ... ... ... ... ... ... ... ... ... ... ... 5969 3.97 182 0399151311 good_reads:book https://www.goodreads.com/author/show/33987.La... 1985.0 /genres/romance|/genres/romance|/genres/contem... dir60/572626.Separate_Beds.html 3544 Separate Beds 5970 4.24 72 0413748308 good_reads:book https://www.goodreads.com/author/show/29185.Sa... 2000.0 /genres/plays|/genres/drama|/genres/plays|/gen... dir60/146548.4_48_Psychosis.html 1016 4.48 Psychosis 5971 4.19 1670 NaN good_reads:book https://www.goodreads.com/author/show/4586597.... 2011.0 /genres/romance|/genres/romance|/genres/contem... dir60/12351649-perfection.html 35197 Perfection (Neighbor from Hell, #2) 5972 4.17 789 1401324290 good_reads:book https://www.goodreads.com/author/show/4627059.... 2011.0 /genres/biography|/genres/animals|/genres/auto... dir60/10393675-until-tuesday.html 4685 Until Tuesday 5973 3.99 2944 0425267040 good_reads:book https://www.goodreads.com/author/show/24978.Ma... 2013.0 /genres/romance|/genres/adult-fiction|/genres/... dir60/16033902-rush.html 41287 Rush (Breathless, #1) 5974 4.07 10585 0061950726 good_reads:book https://www.goodreads.com/author/show/157146.C... 2013.0 /genres/historical-fiction|/genres/book-club|/... dir60/15818107-orphan-train.html 76606 Orphan Train 5975 4.23 1185 NaN good_reads:book https://www.goodreads.com/author/show/5160667.... 2014.0 /genres/romance|/genres/science-fiction|/genre... dir60/20504754-transcendence.html 4942 Transcendence 5976 4.03 218 NaN good_reads:book https://www.goodreads.com/author/show/5769580.... 1987.0 /genres/fiction|/genres/novels|/genres/literat... dir60/5948927.html 1607 Ø§ÙØªÙÙ 5977 3.99 27 1853408360 good_reads:book https://www.goodreads.com/author/show/851161.K... 2005.0 /genres/young-adult|/genres/romance|/genres/co... dir60/2274992.Tessa_in_Love.html 294 Tessa in Love 5978 2.77 800 0060988649 good_reads:book https://www.goodreads.com/author/show/7025.Gre... 2001.0 /genres/fantasy|/genres/fiction|/genres/myster... dir60/24929.Lost.html 11128 Lost 5979 3.84 165 0571207995 good_reads:book https://www.goodreads.com/author/show/16865.Ti... 1977.0 /genres/fiction|/genres/cultural|/genres/canad... dir60/29898.The_Wars.html 4160 The Wars 5980 3.36 1693 0312424442 good_reads:book https://www.goodreads.com/author/show/3083854.... 2003.0 /genres/fiction|/genres/novels|/genres/contemp... dir60/231.I_am_Charlotte_Simmons.html 17743 I am Charlotte Simmons 5981 4.09 362 1407103946 good_reads:book https://www.goodreads.com/author/show/81096.Ch... 2009.0 /genres/fantasy|/genres/horror|/genres/young-a... dir60/6364017-malice.html 2013 Malice (Malice, #1) 5982 4.23 137 1582430438 good_reads:book https://www.goodreads.com/author/show/8567.Wen... 1974.0 /genres/fiction|/genres/novels|/genres/literat... dir60/227274.The_Memory_of_Old_Jack.html 1085 The Memory of Old Jack 5983 4.02 531 0575085150 good_reads:book https://www.goodreads.com/author/show/81096.Ch... 2009.0 /genres/science-fiction|/genres/steampunk|/gen... dir60/6285903-retribution-falls.html 3878 Retribution Falls (Tales of the Ketty Jay, #1) 5984 3.61 109 1401360106 good_reads:book https://www.goodreads.com/author/show/183537.K... 2005.0 /genres/fiction|/genres/young-adult|/genres/bo... dir60/319403.Pigtopia.html 529 Pigtopia 5985 4.06 954 1606840584 good_reads:book https://www.goodreads.com/author/show/2891503.... 2010.0 /genres/young-adult|/genres/fantasy|/genres/pa... dir60/7831742-the-lost-saint.html 12690 The Lost Saint (The Dark Divine, #2) 5986 4.26 477 0517548233 good_reads:book https://www.goodreads.com/author/show/2062.Hen... 1946.0 /genres/economics|/genres/non-fiction|/genres/... dir60/3028.Economics_in_One_Lesson.html 5767 Economics in One Lesson 5987 4.34 93 0575070706 good_reads:book https://www.goodreads.com/author/show/58.Frank... 1977.0 /genres/science-fiction|/genres/fantasy|/genre... dir60/53764.The_Great_Dune_Trilogy.html 41378 The Great Dune Trilogy 5988 3.36 192 842534607X good_reads:book https://www.goodreads.com/author/show/3493970.... 2011.0 /genres/european-literature|/genres/spanish-li... dir60/10832326-si-t-me-dices-ven-lo-dejo-todo-... 1914 Si tÃº me dices ven lo dejo todo... pero dime ven 5989 4.12 1150 0140143459 good_reads:book https://www.goodreads.com/author/show/776.Mich... 1989.0 /genres/non-fiction|/genres/economics|/genres/... dir60/1171.Liar_s_Poker.html 32637 Liar's Poker 5990 4.20 650 NaN good_reads:book https://www.goodreads.com/author/show/1112683._ 2009.0 /genres/novels|/genres/fiction|/genres/religio... dir60/6976667.html 2899 Ø£ÙÙØ§Ø­ ÙØ¯Ø³Ø± 5991 3.89 132 1400303400 good_reads:book https://www.goodreads.com/author/show/5544.Fra... 2002.0 /genres/christian-fiction|/genres/christian|/g... dir60/65686.Nightmare_Academy.html 3531 Nightmare Academy (Veritas Project, #2) 5992 4.09 1256 0345515501 good_reads:book https://www.goodreads.com/author/show/18149.Te... 2011.0 /genres/mystery|/genres/mystery|/genres/crime|... dir60/9578677-the-silent-girl.html 16312 The Silent Girl (Rizzoli & Isles, #9) 5993 4.37 28 0393062260 good_reads:book https://www.goodreads.com/author/show/62157.Ro... 2007.0 /genres/poetry|/genres/religion|/genres/christ... dir60/1251125.The_Book_of_Psalms.html 242 The Book of Psalms 5994 4.17 2226 0767913736 good_reads:book https://www.goodreads.com/author/show/44565.Ca... 2005.0 /genres/history|/genres/non-fiction|/genres/bi... dir60/78508.The_River_of_Doubt.html 16618 The River of Doubt 5995 3.99 775 1416909427 good_reads:book https://www.goodreads.com/author/show/151371.J... 2006.0 /genres/young-adult|/genres/realistic-fiction|... dir60/259068.Shug.html 6179 Shug 5996 3.78 540 1620612321 good_reads:book https://www.goodreads.com/author/show/5761314.... 2012.0 /genres/contemporary|/genres/romance|/genres/y... dir60/13503247-flawed.html 2971 Flawed 5997 3.91 281 NaN good_reads:book https://www.goodreads.com/author/show/1201952.... 2006.0 /genres/religion|/genres/islam|/genres/religio... dir60/2750008.html 3083 Ø£Ø³Ø¹Ø¯ Ø§Ù Ø±Ø£Ø© ÙÙ Ø§ÙØ¹Ø§ÙÙ 5998 4.35 61 0786929081 good_reads:book https://www.goodreads.com/author/show/1023510.... 2001.0 /genres/fiction|/genres/fantasy|/genres/magic|... dir60/66677.Legacy_of_the_Drow_Collector_s_Edi... 3982 Legacy of the Drow Collector's Edition (Legacy... 5999 rows × 10 columns Oh dear. That does not quite seem to be right. We are missing the column names. We need to add these in! But what are they? Here is a list of them in order: [\"rating\", 'review_count', 'isbn', 'booktype','author_url', 'year', 'genre_urls', 'dir','rating_count', 'name'] Exercise Use these to load the dataframe properly! And then \"head\" the dataframe... (you will need to look at the read_csv docs) In [4]: # your code here df = pd . read_csv ( \"data/goodreads.csv\" , header = None , names = [ \"rating\" , 'review_count' , 'isbn' , 'booktype' , 'author_url' , 'year' , 'genre_urls' , 'dir' , 'rating_count' , 'name' ], ) #Examine the first few rows of the dataframe df . head () Out[4]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } rating review_count isbn booktype author_url year genre_urls dir rating_count name 0 4.40 136455 0439023483 good_reads:book https://www.goodreads.com/author/show/153394.S... 2008.0 /genres/young-adult|/genres/science-fiction|/g... dir01/2767052-the-hunger-games.html 2958974 The Hunger Games (The Hunger Games, #1) 1 4.41 16648 0439358078 good_reads:book https://www.goodreads.com/author/show/1077326.... 2003.0 /genres/fantasy|/genres/young-adult|/genres/fi... dir01/2.Harry_Potter_and_the_Order_of_the_Phoe... 1284478 Harry Potter and the Order of the Phoenix (Har... 2 3.56 85746 0316015849 good_reads:book https://www.goodreads.com/author/show/941441.S... 2005.0 /genres/young-adult|/genres/fantasy|/genres/ro... dir01/41865.Twilight.html 2579564 Twilight (Twilight, #1) 3 4.23 47906 0061120081 good_reads:book https://www.goodreads.com/author/show/1825.Har... 1960.0 /genres/classics|/genres/fiction|/genres/histo... dir01/2657.To_Kill_a_Mockingbird.html 2078123 To Kill a Mockingbird 4 4.23 34772 0679783261 good_reads:book https://www.goodreads.com/author/show/1265.Jan... 1813.0 /genres/classics|/genres/fiction|/genres/roman... dir01/1885.Pride_and_Prejudice.html 1388992 Pride and Prejudice Cleaning: Examing the dataframe - quick checks We should examine the dataframe to get a overall sense of the content. Exercise Lets check the types of the columns. What do you find? In [5]: # your code here ####### df . dtypes ####### Out[5]: rating float64 review_count object isbn object booktype object author_url object year float64 genre_urls object dir object rating_count object name object dtype: object your answer here Notice that review_count and rating_counts are objects instead of ints, and the year is a float! There are a couple more quick sanity checks to perform on the dataframe. In [6]: print ( df . shape ) df . columns (6000, 10) Out[6]: Index(['rating', 'review_count', 'isbn', 'booktype', 'author_url', 'year', 'genre_urls', 'dir', 'rating_count', 'name'], dtype='object') Cleaning: Examining the dataframe - a deeper look Beyond performing checking some quick general properties of the data frame and looking at the first $n$ rows, we can dig a bit deeper into the values being stored. If you haven't already, check to see if there are any missing values in the data frame. Let's see for a column which seemed OK to us. In [7]: #Get a sense of how many missing values there are in the dataframe. print ( np . sum ([ df . rating . isnull ()])) print ( np . sum ([ df . review_count . isnull ()])) print ( np . sum ([ df . isbn . isnull ()])) print ( np . sum ([ df . booktype . isnull ()])) print ( np . sum ([ df . author_url . isnull ()])) print ( np . sum ([ df . year . isnull ()])) print ( np . sum ([ df . genre_urls . isnull ()])) print ( np . sum ([ df . dir . isnull ()])) print ( np . sum ([ df . rating_count . isnull ()])) print ( np . sum ([ df . name . isnull ()])) 2 0 475 0 0 7 62 0 0 0 In [8]: #Try to locate where the missing values occur df [ df . rating . isnull ()] Out[8]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } rating review_count isbn booktype author_url year genre_urls dir rating_count name 3643 NaN None None None None NaN NaN dir37/9658936-harry-potter.html None None 5282 NaN None None None None NaN NaN dir53/113138.The_Winner.html None None How does pandas or numpy handle missing values when we try to compute with data sets that include them? We'll now check if any of the other suspicious columns have missing values. Let's look at year and review_count first. One thing you can do is to try and convert to the type you expect the column to be. If something goes wrong, it likely means your data are bad. Lets test for missing data: In [9]: df [ df . year . isnull ()] df . year . isnull () df . shape Out[9]: (6000, 10) Cleaning: Dealing with Missing Values How should we interpret 'missing' or 'invalid' values in the data (hint: look at where these values occur)? One approach is to simply exclude them from the dataframe. Is this appropriate for all 'missing' or 'invalid' values? In [10]: #Treat the missing or invalid values in your dataframe ####### df = df [ df . year . notnull ()] Ok so we have done some cleaning. What do things look like now? Notice the float has not yet changed. In [11]: df . dtypes Out[11]: rating float64 review_count object isbn object booktype object author_url object year float64 genre_urls object dir object rating_count object name object dtype: object In [12]: print ( np . sum ( df . year . isnull ())) df . shape # We removed seven rows 0 Out[12]: (5993, 10) Exercise Ok so lets fix those types. Convert them to ints. If the type conversion fails, we now know we have further problems. In [13]: # your code here df . rating_count = df . rating_count . astype ( int ) df . review_count = df . review_count . astype ( int ) df . year = df . year . astype ( int ) Once you do this, we seem to be good on these columns (no errors in conversion). Lets look: In [14]: df . dtypes Out[14]: rating float64 review_count int64 isbn object booktype object author_url object year int64 genre_urls object dir object rating_count int64 name object dtype: object Sweet! Some of the other colums that should be strings have NaN. In [15]: df . loc [ df . genre_urls . isnull (), 'genre_urls' ] = \"\" df . loc [ df . isbn . isnull (), 'isbn' ] = \"\" Part 2: Parsing and Completing the Data Frame We will parse the author column from the author_url and genres column from the genre_urls. Keep the genres column as a string separated by '|'. We will use panda's map to assign new columns to the dataframe. Examine an example author_url and reason about which sequence of string operations must be performed in order to isolate the author's name. In [16]: #Get the first author_url test_string = df . author_url [ 0 ] test_string Out[16]: 'https://www.goodreads.com/author/show/153394.Suzanne_Collins' In [17]: #Test out some string operations to isolate the author name test_string . split ( '/' )[ - 1 ] . split ( '.' )[ 1 :][ 0 ] Out[17]: 'Suzanne_Collins' Exercise Lets wrap the above code into a function which we will then use In [18]: # Write a function that accepts an author url and returns the author's name based on your experimentation above def get_author ( url ): # your code here name = url . split ( '/' )[ - 1 ] . split ( '.' )[ 1 :][ 0 ] ####### return name In [19]: #Apply the get_author function to the 'author_url' column using '.map' #and add a new column 'author' to store the names df [ 'author' ] = df . author_url . map ( get_author ) df . author [ 0 : 5 ] Out[19]: 0 Suzanne_Collins 1 J_K_Rowling 2 Stephenie_Meyer 3 Harper_Lee 4 Jane_Austen Name: author, dtype: object Exercise Now parse out the genres from genre_url . This is a little more complicated because there be more than one genre. In [20]: df . genre_urls . head () Out[20]: 0 /genres/young-adult|/genres/science-fiction|/g... 1 /genres/fantasy|/genres/young-adult|/genres/fi... 2 /genres/young-adult|/genres/fantasy|/genres/ro... 3 /genres/classics|/genres/fiction|/genres/histo... 4 /genres/classics|/genres/fiction|/genres/roman... Name: genre_urls, dtype: object In [21]: # your code here #Examine some examples of genre_urls #Test out some string operations to isolate the genre name test_genre_string = df . genre_urls [ 0 ] genres = test_genre_string . strip () . split ( '|' ) for e in genres : print ( e . split ( '/' )[ - 1 ]) \"|\" . join ( genres ) young-adult science-fiction dystopia fantasy science-fiction romance adventure book-club young-adult teen apocalyptic post-apocalyptic action Exercise Write a function that accepts a genre url and returns the genre name based on your experimentation above In [22]: def split_and_join_genres ( url ): # your code here genres = url . strip () . split ( '|' ) genres = [ e . split ( '/' )[ - 1 ] for e in genres ] return \"|\" . join ( genres ) Test your function In [23]: split_and_join_genres ( \"/genres/young-adult|/genres/science-fiction\" ) Out[23]: 'young-adult|science-fiction' In [24]: split_and_join_genres ( \"\" ) Out[24]: '' Exercise Use map again to create a new \"genres\" column In [25]: df [ 'genres' ] = df . genre_urls . map ( split_and_join_genres ) df . head () Out[25]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } rating review_count isbn booktype author_url year genre_urls dir rating_count name author genres 0 4.40 136455 0439023483 good_reads:book https://www.goodreads.com/author/show/153394.S... 2008 /genres/young-adult|/genres/science-fiction|/g... dir01/2767052-the-hunger-games.html 2958974 The Hunger Games (The Hunger Games, #1) Suzanne_Collins young-adult|science-fiction|dystopia|fantasy|s... 1 4.41 16648 0439358078 good_reads:book https://www.goodreads.com/author/show/1077326.... 2003 /genres/fantasy|/genres/young-adult|/genres/fi... dir01/2.Harry_Potter_and_the_Order_of_the_Phoe... 1284478 Harry Potter and the Order of the Phoenix (Har... J_K_Rowling fantasy|young-adult|fiction|fantasy|magic|chil... 2 3.56 85746 0316015849 good_reads:book https://www.goodreads.com/author/show/941441.S... 2005 /genres/young-adult|/genres/fantasy|/genres/ro... dir01/41865.Twilight.html 2579564 Twilight (Twilight, #1) Stephenie_Meyer young-adult|fantasy|romance|paranormal|vampire... 3 4.23 47906 0061120081 good_reads:book https://www.goodreads.com/author/show/1825.Har... 1960 /genres/classics|/genres/fiction|/genres/histo... dir01/2657.To_Kill_a_Mockingbird.html 2078123 To Kill a Mockingbird Harper_Lee classics|fiction|historical-fiction|academic|s... 4 4.23 34772 0679783261 good_reads:book https://www.goodreads.com/author/show/1265.Jan... 1813 /genres/classics|/genres/fiction|/genres/roman... dir01/1885.Pride_and_Prejudice.html 1388992 Pride and Prejudice Jane_Austen classics|fiction|romance|historical-fiction|li... Finally, let's pick an author at random so we can see the results of the transformations. Scroll to see the author and genre columns that we added to the dataframe. In [26]: df [ df . author == \"Marguerite_Yourcenar\" ] Out[26]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } rating review_count isbn booktype author_url year genre_urls dir rating_count name author genres 1014 4.23 483 0374529264 good_reads:book https://www.goodreads.com/author/show/7732.Mar... 1951 /genres/historical-fiction|/genres/fiction|/ge... dir11/12172.Memoirs_of_Hadrian.html 6258 Memoirs of Hadrian Marguerite_Yourcenar historical-fiction|fiction|cultural|france|cla... 5620 4.11 74 2070367983 good_reads:book https://www.goodreads.com/author/show/7732.Mar... 1968 /genres/fiction|/genres/historical-fiction|/ge... dir57/953435.L_uvre_au_noir.html 1601 L'Åuvre au noir Marguerite_Yourcenar fiction|historical-fiction|cultural|france|eur... Let us delete the genre_urls column. In [28]: del df [ 'genre_urls' ] And then save the dataframe out! In [29]: df . to_csv ( \"data/cleaned-goodreads.csv\" , index = False , header = True ) Part 3: Grouping It appears that some books were written in negative years! Print out the observations that correspond to negative years. What do you notice about these books? In [30]: # your code here df [ df . year < 0 ] . name #These are books written before the Common Era (BCE, equivalent to BC). Out[30]: 47 The Odyssey 246 The Iliad/The Odyssey 455 The Republic 596 The Aeneid 629 Oedipus Rex 674 The Art of War 746 The Bhagavad Gita 777 Antigone 1233 The Oedipus Cycle 1397 Aesop's Fables 1398 The Epic of Gilgamesh 1428 Medea 1815 The Oresteia 1882 The Trial and Death of Socrates 2078 The History of the Peloponnesian War 2527 The Histories 3133 Complete Works 3274 The Nicomachean Ethics 3757 Lysistrata 4402 The Symposium 4475 Apology 5367 Five Dialogues Name: name, dtype: object We can determine the \"best book\" by year! For this we use Panda's groupby() . Groupby() allows grouping a dataframe by any (usually categorical) variable. Would it make sense to ever groupby integer variables? Floating point variables? In [31]: dfgb_author = df . groupby ( 'author' ) type ( dfgb_author ) Out[31]: pandas.core.groupby.generic.DataFrameGroupBy Perhaps we want the number of books each author wrote In [32]: dfgb_author . count () Out[32]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } rating review_count isbn booktype author_url year dir rating_count name genres author A_A_Milne 6 6 6 6 6 6 6 6 6 6 A_G_Howard 1 1 1 1 1 1 1 1 1 1 A_J_Cronin 1 1 1 1 1 1 1 1 1 1 A_J_Jacobs 1 1 1 1 1 1 1 1 1 1 A_J_Salt 1 1 1 1 1 1 1 1 1 1 A_Meredith_Walters 2 2 2 2 2 2 2 2 2 2 A_N_Roquelaure 2 2 2 2 2 2 2 2 2 2 A_S_Byatt 1 1 1 1 1 1 1 1 1 1 A_S_King 1 1 1 1 1 1 1 1 1 1 A_id_al_Qarni 2 2 2 2 2 2 2 2 2 2 Abbi_Glines 14 14 14 14 14 14 14 14 14 14 Abdul_Rahman_Munif 1 1 1 1 1 1 1 1 1 1 Abigail_Gibbs 1 1 1 1 1 1 1 1 1 1 Abigail_Roux 4 4 4 4 4 4 4 4 4 4 Abigail_Thomas 1 1 1 1 1 1 1 1 1 1 Abolqasem_Ferdowsi 1 1 1 1 1 1 1 1 1 1 Abraham_Verghese 1 1 1 1 1 1 1 1 1 1 Abul_Hasan_Ali_Nadwi 1 1 1 1 1 1 1 1 1 1 Adam_Hochschild 1 1 1 1 1 1 1 1 1 1 Adam_Johnson 1 1 1 1 1 1 1 1 1 1 Adam_Levin 1 1 1 1 1 1 1 1 1 1 Adam_Rex 1 1 1 1 1 1 1 1 1 1 Adam_Smith 1 1 1 1 1 1 1 1 1 1 Addison_Moore 1 1 1 1 1 1 1 1 1 1 Adeline_Yen_Mah 1 1 1 1 1 1 1 1 1 1 Adolf_Hitler 1 1 1 1 1 1 1 1 1 1 Adolfo_Bioy_Casares 1 1 1 1 1 1 1 1 1 1 Aeschylus 1 1 1 1 1 1 1 1 1 1 Aesop 1 1 1 1 1 1 1 1 1 1 Agatha_Christie 11 11 11 11 11 11 11 11 11 11 ... ... ... ... ... ... ... ... ... ... ... William_Strunk_Jr_ 1 1 1 1 1 1 1 1 1 1 William_Styron 3 3 3 3 3 3 3 3 3 3 William_Wharton 2 2 2 2 2 2 2 2 2 2 William_Wordsworth 1 1 1 1 1 1 1 1 1 1 Willow_Aster 1 1 1 1 1 1 1 1 1 1 Wilson_Rawls 2 2 2 2 2 2 2 2 2 2 Winston_Groom 1 1 1 1 1 1 1 1 1 1 Witold_Gombrowicz 2 2 2 2 2 2 2 2 2 2 Wm_Paul_Young 1 1 1 1 1 1 1 1 1 1 Woody_Allen 1 1 1 1 1 1 1 1 1 1 Wu_Cheng_en 1 1 1 1 1 1 1 1 1 1 Yamamoto_Tsunetomo 1 1 1 1 1 1 1 1 1 1 Yana_Toboso 1 1 1 1 1 1 1 1 1 1 Yann_Martel 2 2 2 2 2 2 2 2 2 2 Yasunari_Kawabata 1 1 1 1 1 1 1 1 1 1 Yevgeny_Zamyatin 1 1 1 1 1 1 1 1 1 1 Young_Kim 1 1 1 1 1 1 1 1 1 1 Yuehai_Xiao 1 1 1 1 1 1 1 1 1 1 Yukio_Mishima 2 2 2 2 2 2 2 2 2 2 Yukito_Kishiro 1 1 1 1 1 1 1 1 1 1 Yvonne_Woon 1 1 1 1 1 1 1 1 1 1 Zack_Love 1 1 1 1 1 1 1 1 1 1 Zadie_Smith 2 2 2 2 2 2 2 2 2 2 Zilpha_Keatley_Snyder 1 1 1 1 1 1 1 1 1 1 Zora_Neale_Hurston 1 1 1 1 1 1 1 1 1 1 _ 42 42 42 42 42 42 42 42 42 42 _gota_Krist_f 1 1 1 1 1 1 1 1 1 1 _mile_Zola 4 4 4 4 4 4 4 4 4 4 _ric_Emmanuel_Schmitt 1 1 1 1 1 1 1 1 1 1 _sne_Seierstad 1 1 1 1 1 1 1 1 1 1 2645 rows × 10 columns Lots of useless info there. One column should suffice Exercise: Group the dataframe by author . Include the following columns: rating , name , author . For the aggregation of the name column which includes the names of the books create a list with the strings containing the name of each book. Make sure that the way you aggregate the rest of the columns make sense! Create a new column with number of books for each author and find the most prolific author! In [33]: ###### Before we start : what do we do about these titles where 'name' is unreadable? Try different encodings? auth_name = 'A_id_al_Qarni' df [ df . author == auth_name ] . head () Out[33]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } rating review_count isbn booktype author_url year dir rating_count name author genres 2213 4.19 1169 good_reads:book https://www.goodreads.com/author/show/1201952.... 2003 dir23/2750180.html 15781 ÙØ§ ØªØ­Ø²Ù A_id_al_Qarni religion|religion|islam|self-help|non-fiction|... 5998 3.91 281 good_reads:book https://www.goodreads.com/author/show/1201952.... 2006 dir60/2750008.html 3083 Ø£Ø³Ø¹Ø¯ Ø§Ù Ø±Ø£Ø© ÙÙ Ø§ÙØ¹Ø§ÙÙ A_id_al_Qarni religion|islam|religion|self-help|spirituality... In [34]: df [ df . author == auth_name ] . iat [ 0 , 8 ] . encode ( 'UTF-16' ) Out[34]: b'\\xff\\xfe\\xd9\\x00\\x84\\x00\\xd8\\x00\\xa7\\x00 \\x00\\xd8\\x00\\xaa\\x00\\xd8\\x00\\xad\\x00\\xd8\\x00\\xb2\\x00\\xd9\\x00\\x86\\x00' In [35]: # let's examine the columns we have df . columns Out[35]: Index(['rating', 'review_count', 'isbn', 'booktype', 'author_url', 'year', 'dir', 'rating_count', 'name', 'author', 'genres'], dtype='object') Create the GroupBy table In [36]: authors = df . copy () authors = authors [[ 'rating' , 'name' , 'author' ]] . groupby ( 'author' ) . agg ({ 'rating' : np . mean , 'name' : '|' . join }) In [37]: authors = authors . reset_index () authors . head () Out[37]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } author rating name 0 A_A_Milne 4.365 Winnie-the-Pooh|The House at Pooh Corner|The H... 1 A_G_Howard 4.020 Splintered (Splintered, #1) 2 A_J_Cronin 4.220 The Keys of the Kingdom 3 A_J_Jacobs 3.750 The Year of Living Biblically 4 A_J_Salt 4.940 Nik Nassa & the Mark of Destiny In [38]: # split the column string and make a list of string book names authors [ 'name' ] = authors . name . str . split ( '|' ) authors . head () Out[38]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } author rating name 0 A_A_Milne 4.365 [Winnie-the-Pooh, The House at Pooh Corner, Th... 1 A_G_Howard 4.020 [Splintered (Splintered, #1)] 2 A_J_Cronin 4.220 [The Keys of the Kingdom] 3 A_J_Jacobs 3.750 [The Year of Living Biblically] 4 A_J_Salt 4.940 [Nik Nassa & the Mark of Destiny] In [39]: # count the books - create new column len ( authors . name [ 0 ]) Out[39]: 6 In [40]: authors [ 'num_books' ] = authors [ 'name' ] . str . len () authors Out[40]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } author rating name num_books 0 A_A_Milne 4.365000 [Winnie-the-Pooh, The House at Pooh Corner, Th... 6 1 A_G_Howard 4.020000 [Splintered (Splintered, #1)] 1 2 A_J_Cronin 4.220000 [The Keys of the Kingdom] 1 3 A_J_Jacobs 3.750000 [The Year of Living Biblically] 1 4 A_J_Salt 4.940000 [Nik Nassa & the Mark of Destiny] 1 5 A_Meredith_Walters 4.150000 [Find You in the Dark (Find You in the Dark, #... 2 6 A_N_Roquelaure 3.450000 [Beauty's Punishment (Sleeping Beauty, #2), Th... 2 7 A_S_Byatt 3.860000 [Possession] 1 8 A_S_King 3.930000 [Please Ignore Vera Dietz] 1 9 A_id_al_Qarni 4.050000 [ÙØ§ ØªØ­Ø²Ù, Ø£Ø³Ø¹Ø¯ Ø§Ù Ø±Ø£Ø© ÙÙ Ø§ÙØ... 2 10 Abbi_Glines 4.179286 [Fallen Too Far (Too Far, #1), Existence (Exis... 14 11 Abdul_Rahman_Munif 4.030000 [Ø§ÙØªÙÙ] 1 12 Abigail_Gibbs 3.820000 [Dinner With a Vampire (Dark Heroine, #1)] 1 13 Abigail_Roux 4.470000 [Cut & Run (Cut & Run, #1), Fish & Chips (Cut ... 4 14 Abigail_Thomas 3.680000 [A Three Dog Life] 1 15 Abolqasem_Ferdowsi 4.520000 [Shahnameh] 1 16 Abraham_Verghese 4.260000 [Cutting for Stone] 1 17 Abul_Hasan_Ali_Nadwi 4.150000 [Ù Ø§Ø°Ø§ Ø®Ø³Ø± Ø§ÙØ¹Ø§ÙÙ Ø¨Ø§ÙØ­Ø·Ø§Ø· Ø... 1 18 Adam_Hochschild 4.140000 [King Leopold's Ghost] 1 19 Adam_Johnson 4.030000 [The Orphan Master's Son] 1 20 Adam_Levin 4.040000 [The Instructions] 1 21 Adam_Rex 4.140000 [The True Meaning of Smekday] 1 22 Adam_Smith 3.820000 [The Wealth of Nations] 1 23 Addison_Moore 3.780000 [Ethereal (Celestra, #1)] 1 24 Adeline_Yen_Mah 4.010000 [Chinese Cinderella] 1 25 Adolf_Hitler 2.970000 [Mein Kampf] 1 26 Adolfo_Bioy_Casares 4.060000 [The Invention of Morel] 1 27 Aeschylus 3.960000 [The Oresteia] 1 28 Aesop 4.030000 [Aesop's Fables] 1 29 Agatha_Christie 3.977273 [And Then There Were None, Murder on the Orien... 11 ... ... ... ... ... 2615 William_Strunk_Jr_ 4.170000 [The Elements of Style] 1 2616 William_Styron 4.043333 [Sophie's Choice, The Confessions of Nat Turne... 3 2617 William_Wharton 4.090000 [Birdy, A Midnight Clear] 2 2618 William_Wordsworth 3.920000 [Lyrical Ballads] 1 2619 Willow_Aster 4.140000 [True Love Story] 1 2620 Wilson_Rawls 3.990000 [Where the Red Fern Grows, Summer of the Monkeys] 2 2621 Winston_Groom 3.970000 [Forrest Gump (Forrest Gump, #1)] 1 2622 Witold_Gombrowicz 3.975000 [Ferdydurke, Cosmos] 2 2623 Wm_Paul_Young 3.660000 [The Shack] 1 2624 Woody_Allen 4.030000 [Without Feathers] 1 2625 Wu_Cheng_en 4.040000 [Monkey] 1 2626 Yamamoto_Tsunetomo 4.090000 [Hagakure] 1 2627 Yana_Toboso 4.340000 [Black Butler, Vol. 01 (Black Butler, #1)] 1 2628 Yann_Martel 3.470000 [Life of Pi, Beatrice and Virgil] 2 2629 Yasunari_Kawabata 3.740000 [Snow Country] 1 2630 Yevgeny_Zamyatin 3.970000 [We] 1 2631 Young_Kim 3.660000 [Twilight (Twilight: The Graphic Novel, #1)] 1 2632 Yuehai_Xiao 4.560000 [Crossing the Seas] 1 2633 Yukio_Mishima 4.030000 [The Sailor Who Fell from Grace with the Sea, ... 2 2634 Yukito_Kishiro 4.150000 [Battle Angel Alita, Volume 01] 1 2635 Yvonne_Woon 3.950000 [Dead Beautiful (Dead Beautiful, #1)] 1 2636 Zack_Love 3.550000 [Sex in the Title] 1 2637 Zadie_Smith 3.655000 [White Teeth, On Beauty] 2 2638 Zilpha_Keatley_Snyder 4.110000 [The Changeling] 1 2639 Zora_Neale_Hurston 3.820000 [Their Eyes Were Watching God] 1 2640 _ 3.988095 [Ø¹Ø²Ø§Ø²ÙÙ, Ø«ÙØ§Ø«ÙØ© ØºØ±ÙØ§Ø·Ø©, ØªØ±... 42 2641 _gota_Krist_f 4.340000 [The Notebook, The Proof, The Third Lie] 1 2642 _mile_Zola 3.990000 [Germinal (Les Rougon-Macquart, #13), L'Assomm... 4 2643 _ric_Emmanuel_Schmitt 4.160000 [Oscar et la dame rose] 1 2644 _sne_Seierstad 3.740000 [The Bookseller of Kabul] 1 2645 rows × 4 columns In [41]: # sort for more prolific authors . sort_values ( by = 'num_books' , ascending = False ) . iloc [ 0 ] Out[41]: author Stephen_King rating 3.91875 name [The Stand, The Shining (The Shining #1), It, ... num_books 56 Name: 2349, dtype: object Winner is Stephen King with 56 books! OMG!!! Perhaps you want more detailed info... In [ ]: dfgb_author [[ 'rating' , 'rating_count' , 'review_count' , 'year' ]] . describe () You can also access a groupby dictionary style. In [ ]: ratingdict = {} for author , subset in dfgb_author : ratingdict [ author ] = ( subset [ 'rating' ] . mean (), subset [ 'rating' ] . std ()) ratingdict Exercise Lets get the best-rated book(s) for every year in our dataframe. In [ ]: #Using .groupby, we can divide the dataframe into subsets by the values of 'year'. #We can then iterate over these subsets # your code here for year , subset in df . groupby ( 'year' ): #Find the best book of the year bestbook = subset [ subset . rating == subset . rating . max ()] if bestbook . shape [ 0 ] > 1 : print ( year , bestbook . name . values , bestbook . rating . values ) else : print ( year , bestbook . name . values [ 0 ], bestbook . rating . values [ 0 ]) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab02-pandas/notebook/"},{"title":"Lab 02: Scraping","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } Accessibility links Skip to main content Keyboard shortcuts for audio player NPR Shop Open Navigation Menu Close Navigation Menu Home News Expand/collapse submenu for News National World Politics Business Health Science Technology Race & Culture Arts & Life Expand/collapse submenu for Arts & Life Books Movies Television Pop Culture Food Art & Design Performing Arts Music Expand/collapse submenu for Music Tiny Desk All Songs Considered Turning The Tables Music News New Music Best Music Of 2019 Shows & Podcasts Expand/collapse submenu for Shows & Podcasts Daily Morning Edition Weekend Edition Saturday Weekend Edition Sunday All Things Considered Fresh Air Up First Featured How I Built This with Guy Raz Wait Wait...Don't Tell Me! Planet Money Hidden Brain More Shows & Podcasts Search NPR Shop Tiny Desk All Songs Considered Turning The Tables Music News New Music Best Music Of 2019 About NPR Overview Support Careers Connect Press Ethics What If The Polls Are Wrong Again? 4 Scenarios For What Might Happen In The Elections The polls show a Democratic advantage in the House and a Republican one in the Senate. But be ready for anything because surprises in politics always happen. What If The Polls Are Wrong Again? 4 Scenarios For What Might Happen In The Elections Elections What If The Polls Are Wrong Again? 4 Scenarios For What Might Happen In The Elections Facebook Twitter Flipboard Email November 5, 2018 4:49 PM ET Domenico Montanaro Twitter Enlarge this image Supporters of Missouri Democratic Sen. Claire McCaskill wait for her to arrive at a campaign stop in St. Louis on Monday. Scott Olson/Getty Images hide caption toggle caption Scott Olson/Getty Images Supporters of Missouri Democratic Sen. Claire McCaskill wait for her to arrive at a campaign stop in St. Louis on Monday. Scott Olson/Getty Images There's a lot that can happen Tuesday, the culmination of a long midterm election campaign that will provide the first nationwide measure of the U.S. electorate since Donald Trump was elected president. One narrative has become dominant: that Democrats are likely to gain control of the House and Republicans hold the Senate, if not expand their majority there. That narrative is based largely on national polls, and caution should be urged. Pollsters have made a lot of adjustments to hopefully correct what they got wrong in 2016, but they can't tell you precisely who is going to show up to vote. Analysis Key Questions The 2018 Election Will Answer What's more, there have been far fewer statewide and district-specific surveys than in past midterm elections. And, as it is, there are data both parties can take solace in that buoy their respective cases. So everyone should be prepared for surprises — because there always are some. That's the beauty of campaigns and voting. Here are four scenarios for how election night might play out and what each could mean. 1. Democrats win the House, and Republicans hold the Senate This is the most likely outcome, based not just on the polls but also on conversations with strategists in both parties. But they urge caution, because the races in the many districts across the country that are up for grabs are still very close. Politics Here's Why Democrats Are Confident They'll Win The House How it would happen: Forget the polls; Democrats are favored to take back the House for more reasons than that. There have been a record number of retirements, reducing the built-in advantage incumbents tend to have; record numbers of candidates, especially Democratic women , have run for public office; Democrats won the off-year elections in Virginia and New Jersey; they won or fared better than expected in special elections across the country; there was high primary turnout for Democrats in many states; and there is very high early voting turnout. Elections Female Democratic House Candidates Set For A Much Easier Election Day Than GOP Women And just look at how wide the playing field is — Democrats need to pick up 23 seats to take back the House, and they are targeting some 80 Republican-held seats. Republicans are competing in just eight held by Democrats. That right there is and has been a huge flashing red light for the GOP. So many of those races are running through the suburbs, where independents and wealthy, college-educated women live, both of which have consistently in polling said they disapproved of the job the president is doing and prefer to vote for a Democrat in their district. Elections Poll: Nearly 4 In 5 Voters Concerned Incivility Will Lead To Violence One other overlooked number from the last NPR/PBS NewsHour/Marist poll : Just 54 percent of Republican women who are registered voters said they were very enthusiastic about voting in this election. Compare that with 78 percent of Republican men who are registered voters. And where do a lot of those women live? The suburbs. If GOP women, an important group that Republicans need to bolster them, stay home, that's one way Democrats clean up in the House. Politics Battle For The Senate: 10 Races That Will Determine Control In the Senate, on the other hand, Republicans have a very favorable landscape and are competing in conservative states held by Democrats . The fundamentals favor the GOP in these states, and if Republicans win where they should win, they will hold the Senate. Politics As Dems Prepare Investigative Barrage, Key White House Lawyer Jobs Remain Vacant What it would mean: This would be a huge win for Democrats, as they'd be able to gum up Trump's agenda and begin to investigate his administration , something the GOP has not done very much of. In the Senate, Republicans could still approve federal judges and Trump Supreme Court nominees , but if they want to get any big legislation done they're going to have to negotiate with Democrats in the House, and possibly a Speaker Nancy Pelosi. Democrats feel they need to limit the losses in the Senate. If they can hold Republicans to net even, keeping the Senate at 51-49, or maybe lose a net of one seat, then they will be very happy. They have a much more favorable Senate landscape in 2020 and believe they will be able to take back the Senate then. 2. Republicans hold the House and Senate This would be a huge win for the GOP. Shots - Health News NPR Poll: Rural Americans Are Worried About Addiction And Jobs, But Remain Optimistic How it would happen: A record turnout is expected Tuesday — perhaps higher than any time in the past 50 years for a midterm — but, as in 2016, Trump voters would have to dominate. Rural voters would have to turn out at higher-than-expected rates, causing the polls to be wrong (again). Meanwhile, young voters and Latinos would have to stay home. ( It is supposed to rain on the East Coast Tuesday , which could depress low-propensity-voter turnout.) Elections Taking Back The House Could Be 'Life And Death' For Democrats All of those close House races would have to tip Republicans' way, something that's very possible given the conservative lean of those districts and the distrust of the media, purposefully stoked by the president. And who pays for polls for the most part? Big media organizations. Enlarge this image President Trump acknowledges supporters during a campaign rally for Rep. Marsha Blackburn, R-Tenn., and other Tennessee Republican candidates on Monday in Chattanooga, Tenn. Alex Wong/Getty Images hide caption toggle caption Alex Wong/Getty Images President Trump acknowledges supporters during a campaign rally for Rep. Marsha Blackburn, R-Tenn., and other Tennessee Republican candidates on Monday in Chattanooga, Tenn. Alex Wong/Getty Images What it would mean: President Trump and Republicans would step on the gas, validated by an election cycle dominated by negative news coverage and polling that said the GOP had its back against the wall. The Affordable Care Act (aka Obamacare) would very likely be repealed once and for all. And Trump could set his sights on ousting Attorney General Jeff Sessions and other key figures at the Justice Department, possibly ending the department's investigation of Russia's attack on the 2016 election. National FACT CHECK: Migrants Are Not Overwhelming The Southwest Border What's more, Trump's strategy of demonizing immigrants would have worked — again. That was rewarded, and what message would that send? He is only going to do more of it between Wednesday and November 2020 when he stands for re-election. Politics How To Make Sense Of Exit Polls On Election Night It would also be yet another reckoning for pollsters and media organizations that pay for the surveys. The polls currently show Democrats with a razor-thin, but consistent advantage heading into Election Day. But if the polls are wrong, it should induce more than a shoulder shrug from outlets that conduct them and the news media organizations that report on them. 3. Democrats win both the House and Senate This is not seen as the likeliest of scenarios, but it's not out of the realm of possibility either. It would very likely mean a massive wave and a massive shift against Trump and Republicans tied to him nationally. A lot would have to happen, especially in the Senate, for this to happen. Elections 'Miserable And Emboldened': If Republicans Lose The House, They'll Be On Defense How it would happen: The path for Democrats in the House is through the suburbs, as in Scenario 1. That doesn't change. But for Democrats to pull this off in the Senate, not only would voters have to side with Democratic incumbents in conservative states, but Democratic challengers would have to win in places like Nevada and Arizona, and possibly Tennessee and Texas. What it would mean: It would be a repudiation of Trump and the Republicans tied to him nationwide. It would have to trigger a degree of soul-searching — in at least some Republican corners. Trump would be faced with the choice of moderating and working with Democrats or being a lame-duck president starting in January 2019 when a new Democratic Congress is sworn in — as talk ramps up about Democratic 2020 challengers. 4. Overtime It's very possible control of both the House and Senate will not be clear on election night. Enlarge this image A number of races are so close that it may not be possible to declare a winner on election night, leaving control of the House and Senate up in the air. Joe Sohm/Visions of America/UIG via Getty Images hide caption toggle caption Joe Sohm/Visions of America/UIG via Getty Images A number of races are so close that it may not be possible to declare a winner on election night, leaving control of the House and Senate up in the air. Joe Sohm/Visions of America/UIG via Getty Images How it would happen: There are a half-dozen congressional races in California, for example, that are very close heading into Election Day. It's possible those races are so close they will not be called on election night. They might not be called for days and possibly weeks later, especially because the vote there is counted slowly. Politics Voter Purges Are Up, But Most Americans Won't See Problems At The Polls Additionally, early and absentee ballots can get counted slowly and there is growing concern that many voters' absentee and mailed ballots could be rejected. In 2016, to the surprise of many, 319,000 absentee ballots were rejected for one reason or another. In the Senate, depending on how results from other races shake out, there is the possibility that control is not known on election night or for weeks after. Specifically, it could all come down to Mississippi. There, no candidate is polling above 50 percent heading into Election Day, and if no one gets at least 50 percent, the race heads to a runoff three weeks later. What it would mean: Imagine a scenario in which Democrats lead 50-49 on Election Day in the Senate, and the eyes of the country — and the deep pockets of out-of-state money — descend on Mississippi. The consequences would be enormous, the rancor pitched and the tension thick. 2018 election day 2016 trump election night 2020 polling Senate House Democrats GOP Republican election Facebook Twitter Flipboard Email Read & Listen Home News Arts & Life Music Podcasts Programs Connect Newsletters Facebook Twitter Instagram Contact Help About NPR Overview Finances People Press Public Editor Corrections Get Involved Support Public Radio Sponsor NPR NPR Careers NPR Shop NPR Events Visit NPR Terms of Use Privacy Your Privacy Choices Text Only NPR thanks our sponsors Become an NPR sponsor (function () { var loadPageJs = function () { webpackJsonp([82,25],{0:function(n,t,c){n.exports=c(1823)},1823:function(n,t,c){\"use strict\";c.p=NPR.serverVars.webpackPublicPath,function(){var n=2,t=function(){--n<1&&function(n){c(45),c(2232),c(366),c(373),c(263),c(794),c(408),c(2237),c(407),c(2236),c(2235),c(1402),c(589),c(2229),c(1563),c(2222),c(355)}(c)}.bind(this);c.e(0,t),c.e(4,t)}.call(this)}}); }; if (document.readyState === 'complete') { loadPageJs(); } else { window.addEventListener('load', function load() { window.removeEventListener('load', load, false); loadPageJs(); }); } })(); var _sf_async_config = _sf_async_config || {}; /** CONFIGURATION START **/ _sf_async_config.uid = '18888'; _sf_async_config.domain = NPR.ServerConstants.cbHost; _sf_async_config.useCanonical = true; /** CONFIGURATION END **/ (function() { function loadChartbeat() { // Wait until the metric for chartbeat have been setup // in templates/javascript/metrics/chartbeat.js if( !!NPR.ChartbeatLoaded) { var e = document.createElement('script'); e.setAttribute('language', 'javascript'); e.setAttribute('type', 'text/javascript'); e.setAttribute('src', 'https://static.chartbeat.com/js/chartbeat.js'); document.body.appendChild(e); } else { setTimeout(loadChartbeat, 1000); } } var oldonload = window.onload; window.onload = (typeof window.onload != 'function') ? loadChartbeat : function() { oldonload(); window._sf_endpt = (new Date()).getTime(); loadChartbeat(); }; })(); if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"pages","url":"pages/lab02-scraping-notebook/"},{"title":"Lecture 3: Code Pandas + Beautiful Soup","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109A Introduction to Data Science Lecture 3 (Pandas + Beautiful Soup) Harvard University Fall 2019 Instructors: Pavlos Protopapas, Kevin Rader, and Chris Tanner Authors: Rahul Dave, David Sondak, Will Claybaugh, Pavlos Protopapas, Chris Tanner In [1]: ## RUN THIS CELL TO GET THE RIGHT FORMATTING from IPython.core.display import HTML from IPython.display import Image def css_styling (): styles = open ( \"../../../styles/cs109.css\" , \"r\" ) . read () return HTML ( styles ) css_styling () Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Table of Contents Learning Goals Loading and Cleaning with Pandas Parsing and Completing the Dataframe Grouping Learning Goals This Jupyter notebook accompanies Lecture 3. By the end of this lecture, you should be able to: Understand why and how Pandas can be useful. Use Pandas to: Load data into a DataFrame Access subsets of data based on column and row values Address missing values (e.g., NaN ) Use groupby() to select sections of data. Plot DataFrames (e.g., barplot()) Use Beautiful Soup to download a webpage and all of its links Part 1: Processing Data without Pandas ../data/top50.csv is a dataset found online (Kaggle.com) that contains information about the 50 most popular songs on Spotify in 2019. Each row represents a distinct song. The columns (in order) are: ID: a unique ID (i.e., 1-50) TrackName: Name of the Track ArtistName: Name of the Artist Genre: the genre of the track BeatsPerMinute: The tempo of the song. Energy: The energy of a song - the higher the value, the more energetic. song Danceability: The higher the value, the easier it is to dance to this song. Loudness: The higher the value, the louder the song. Liveness: The higher the value, the more likely the song is a live recording. Valence: The higher the value, the more positive mood for the song. Length: The duration of the song (in seconds). Acousticness: The higher the value, the more acoustic the song is. Speechiness: The higher the value, the more spoken words the song contains. Popularity: The higher the value, the more popular the song is. In [174]: Image ( \"fig/top50_screenshot.png\" ) # sample of the data Out[174]: Read and store ../data/top50.csv Q1: Read in the ../data/top50.csv file and store all of its contents into any data structure(s) that make the most sense to you, keeping in mind that you'd want to easily access any row or column. What data structure(s) make the most sense to use? In [183]: f = open ( \"../data/top50.csv\" ) column_names = f . readline () . strip () . split ( \",\" )[ 1 :] # puts names in a list cleaned_column_names = [ name for name in column_names ] # removes the extraneous quotes cleaned_column_names . insert ( 0 , \"ID\" ) dataset = [] # iterates through each line of the .csv file for line in f : attributes = line . strip () . split ( \",\" ) # constructs a new dictionary for each line, and # appends this dictionary to the `dataset`; # thus, the dataset is a list of dictionaries (1 dictionary per song) dataset . append ( dict ( zip ( cleaned_column_names , attributes ))) Q2: Write code to print all songs (Artist and Track name) that are longer than 4 minutes (240 seconds): In [184]: for song in dataset : if int ( song [ \"Length\" ]) > 240 : print ( song [ \"ArtistName\" ], \"-\" , song [ \"TrackName\" ], \"is\" , song [ \"Length\" ], \"seconds long\" ) Anuel AA - China is 302 seconds long Bad Bunny - Callaita is 251 seconds long Sech - Otro Trago - Remix is 288 seconds long Chris Brown - No Guidance (feat. Drake) is 261 seconds long J Balvin - LA CANCIÓN is 243 seconds long Jhay Cortez - No Me Conoce - Remix is 309 seconds long Lunay - Soltera - Remix is 266 seconds long Q3: Write code to print the most popular song (or song(s) if there is a tie): In [383]: max_score = - 1 most_populars = set () for song in dataset : if int ( song [ \"Popularity\" ]) > max_score : most_populars = set ([ str ( song [ \"ArtistName\" ] + \"-\" + song [ \"TrackName\" ])]) max_score = int ( song [ \"Popularity\" ]) elif int ( song [ \"Popularity\" ]) == max_score : most_populars . add ( str ( song [ \"ArtistName\" ] + \"-\" + song [ \"TrackName\" ])) #print(most_populars) Q4: Write code to print the songs (and their attributes), if we sorted by their popularity (highest scoring ones first). In [186]: # This gets tricky. How would you do it? Q5: How could you check for null/empty entries? This is only 50 entries. Imagine if we had 500,000. In [187]: # you would need to iterate through every single value and check # that's O(N*M), where N is the # of rows, and M is the # of columns. # NOTE: what if you wished to impute any given non-value with the column's mean? # you would need another N checks Often times, one dataset doesn't contain all of the information you are interested in -- in which case, you need to combine data from multiple files. Q6: Imagine we had another table (i.e., .csv file) below. How could we combine its data with our already-existing dataset ? Part 2: Processing Data with Pandas Pandas is an open-source Python library designed for data analysis and processing. Being open-sourced means that anyone can contribute to it (don't worry, a team of people vett all official updates to the library). Pandas allows for high-performance, easy-to-use data structures. Namely, instead of using N-dimensional arrays like NumPy (which are extremely fast, though), Pandas provides a 2D-table object calleda DataFrame . As a very gross simplification: NumPy is great for performing math operations with matrices, whereas Pandas is excellent for wrangling, processing, and understanding 2D data like spreadsheets (2D data like spreadsheets is very common and great). Let's get started with simple examples of how to use Pandas. We will continue with our top50.csv Spotify music data. First, we need to import pandas so that we have access to it. For typing convenience, we choose to rename it as pd , which is common practice. In [2]: % matplotlib inline import numpy as np import matplotlib.pyplot as plt import pandas as pd import seaborn as sns pd . set_option ( 'display.width' , 500 ) pd . set_option ( 'display.max_columns' , 100 ) Reading in the data Pandas allows us to read in various structured files (e.g., .csv, .json, .html, etc) with just one line: In [4]: # we don't always need to specify the encoding, but this particular # file has special characters that we need to handle top50 = pd . read_csv ( \"../data/top50.csv\" ) High-level view of the data We can view the data frame by simply printing it: In [381]: top50 Instead of printing the entire dataframe (e.g., print(top50) ), we can also inspect the file by looking at just the first N rows or last N rows. In [380]: #top50.head(3) # first 3 rows #top50.tail(3)) # last 3 rows That's cool, but we can't see all of the columns too well. To get a list of all columns: In [379]: #top50.columns Remember, Pandas is in Python, so you can write regular Python code with it. For example, if you want to know how many columns there are, you can use Python's len() function. In [378]: #len(top50.columns) Fortunately, many of the features in our dataset are numeric. Conveniently, Pandas' describe() function calculates basic statistics for our columns. It's pretty amazing, as it allows us a very coarse-grain approach to understanding our data and checking for errors. That is, if we notice any summary statistics that are drastically different than what we deem reasonable, we should dive deeper and figure out why the values are what they are. In [377]: #top50.describe() Notice, it calculated statistics only for the columns that are of numeric data types. What about the textual ones (e.g., Track name and Artist)? Pandas is smart enough to infer the data types. Don't forget to inspect the columns that are text-based though, as we need to ensure they are sound, too. To view the data type of each column: In [376]: #top50.dtypes Exploring the data I agree with Pandas' handling of the data. If any column contained floating point numbers, we would expect to see such here, too. Now that we've viewed our dataset at a high-level, let's actually use and explore it. We can access a column of data the same way we access dictionary by its keys: In [374]: #top50[\"Length\"] We could have also used this syntax (identical results): In [373]: #top50.Length If we want just the highest or lowest value of a given column, we can use the functions max() and min() , respectively. In [372]: #top50['Length'].max() In [371]: #top50['Length'].min() If we want the row index that corresponds to a column's max or min value, we can use idxmax() and idxmin() , respectively. In [370]: #top50['Length'].idxmax() In [369]: #top50['Length'].idxmin() We can also add conditional statements (e.g., >, <, ==) for columns, which yields a boolean vector: In [368]: #top50['Length'] > 240 This is useful, as it allows us to process only the rows with the True values. The loc() function allows us to access data via labels: A single scalar label A list of labels A slice object A Boolean array A single scalar: In [367]: # single scalar label #top50.loc[0] # prints the (unnamed) row that has a label of 0 (the 1st row) In [366]: # list of labels #top50.loc[[0,2]] # prints the (unnamed) rows that have the labels of 0 and 2 (the 1st and 3rd rows) In [365]: # a slice of the dataframe, based on the passed-in booleans; # picture it's like a filter overlaying the DataFrame, and the filter # dictates which values will be emitted/make it through to us #top50.loc[top50['Length'] > 240] # prints all rows that have Length > 240 Note, this returns a DataFrame . Everything we've learned so far concerns how to use DataFrames, so we can tack on additional syntax to this command if we wish to do further processing. For example, if we want to index just select columns (e.g., ArtistName, TrackName, and Length) of this returned DataFrame: In [364]: #top50.loc[top50['Length'] > 240][['ArtistName', 'TrackName', 'Length']] Note, the above solves our original Q2: (Write code to print all songs (Artist and Track name) that are longer than 4 minutes (240 seconds)) Q3: Write code to print the most popular song (or song(s) if there is a tie): In [6]: ## [TODO] TO BE FILLED IN DURING CLASS PARTICIPATION # FEEL FREE TO WORK WITH A NEIGHBOR top50 . iloc [ top50 [ 'Popularity' ] . idxmax ()] We can also sort our data by a single column! This pertains to our original Q4! Q4: Write code to print the songs (and their attributes), if we sorted by their popularity (highest scoring ones first). In [314]: #top50.sort_values(\"Popularity\", ascending=False) While .loc() allows us to index based on passed-in labels, .iloc() allows us to access data based on 0-based indices. The syntax is .iloc[ , ] , where and can be scalars, lists, or slices of indices. In [363]: #top50.iloc[5:6] # prints all columns for the 6th row In [316]: #top50.iloc[:,2] # prints all rows for the 3rd column In [317]: #top50.iloc[[0,2,3], [2,1]] # prints the 1st, 3rd, and 4th rows of the 3rd and 2nd columns (artist and track) Inspecting/cleaning the data As mentioned, it is imperative to ensure the data is sound to use: Did it come from a trustworthy, authoritative source? Is the data a complete sample? Does the data seem correct? (optional) Is the data stored efficiently or does it have redundancies? Let's walk through each of these points now: Did it come from a trustworthy, authoritative source? The data came from Kaggle.com, which anyone can publish to. However, the author claims that he/she used Spotify.com's official API to query songs in 2019. There are no public comments for it so far. It's potentially credible. Is the data a complete sample? Pandas has functions named isnull() and notnull() , which return DataFrames corresponding to any null or non-null entries, respectively. For example: In [319]: #top50[top50.ArtistName.isnull()] # returns an empty DataFrame In [329]: #top50[top50.ArtistName.notnull()] # returns the complete DataFrame since there are no null Artists If we run this for all of our features/columns, we will see there are no nulls. Since this dataset is manageable in size, you can also just scroll through it and notice no nulls. This answers our original Q5: Q5: How could you check for null/empty entries? Continuing with our data sanity check list: Does the data seem correct? A quick scroll through the data, and we see a song by Maluma titled 0.95833333 . This is possibly a song about probability, but I think the chances are slim. The song is 176 seconds long (2m56s). Looking on Spotify, we see Maluma's most popular song is currently 11PM which is 2m56s in length! Somehow, during the creation of the dataset, 11PM became 0.95833333. Bonus points if you can figure out where this pointing number could have come from. In [362]: #Image(\"fig/maluma.png\") # sample of the data Since only one song seems obviously wrong, we can manually fix it. And it's worth noting such to ourselves and to whomever else would see our results or receive a copy of our data. If there were many more wrong values, we'd potentialy not fix them, as we'd explore other options. (optional) Is the data stored efficiently or does it have redundancies? Everything seems fine. No repeated data. Combining multiple DataFrames As mentioned, often times one dataset doesn't contain all of the information you are interested in -- in which case, you need to combine data from multiple files. This also means you need to verify the accuracy (per above) of each dataset. Pandas' groupby() function splits the DataFrame into different groups, depending on the passed-in variable. For example, we can group our data by the genres: In [360]: grouped_df = top50 . groupby ( 'Genre' ) #for key, item in grouped_df: # print(\"Genre:\", key, \"(\", len(grouped_df.get_group(key)), \"items):\", grouped_df.get_group(key), \"\\n\\n\") ../data/spotify_aux.csv contains the same 50 songs as top50.csv ; however, it only contains 3 columns: Track Name Artist Name Explicit Language (boolean valued) Note, that 3rd column is just random values, but pretend as if it's correct. The point of this section is to demonstrate how to merge columns together. Let's load ../data/spotify_aux.csv into a DataFrame: In [357]: explicit_lyrics = pd . read_csv ( \"../data/spotify_aux.csv\" ) #explicit_lyrics Let's merge it with our top50 DataFrame. .merge() is a Pandas function that stitches together DataFrames by their columns. .concat() is a Pandas function that stitches together DataFrames by their rows (if you pass axis=1 as a flag, it will be column-based) In [356]: # 'on='' specifies the column used as the shared key df_combined = pd . merge ( explicit_lyrics , top50 , on = 'TrackName' ) #df_combined We see that all columns from both DataFrames have been added. That's nice, but having duplicate ArtistName and TrackName is unecessary. Since merge() uses DataFrames as the passed-in objects, we can simply pass merge() a stripped-down copy of ExplicitLanguage , which helps merge() not add any redundant fields. In [355]: df_combined = pd . merge ( explicit_lyrics [[ 'TrackName' , 'ExplicitLanguage' ]], top50 , on = 'TrackName' ) #df_combined This answers our original Q6: Q6: Imagine we had another table (i.e., .csv file) below. How could we combine its data with our already-existing dataset ? While we do not exhaustively illustrate Pandas' joining/splitting functionality, you may find the following functions useful: merge() concat() aggregate() append() Plotting DataFrames As a very simple example of how one can plot elements of a DataFrame, we turn to Pandas' built-in plotting: In [242]: scatter_plot = top50 . plot . scatter ( x = 'Danceability' , y = 'Popularity' , c = 'DarkBlue' ) This shows the lack of a correlation between the Danceability of a song and its popularity, based on just the top 50 songs, of course. Please feel free to experiment with plotting other items of interest, and we recommend using Seaborn. Practice Problems with a Partner (or individually if you prefer) P1. Print the shortest song (all features): In [7]: # [TODO] TO BE FILLED IN DURING CLASS PARTICIPATION top50 . iloc [ top50 [ 'Length' ] . idxmin ()] Out[7]: Unnamed: 0 22 TrackName Panini ArtistName Lil Nas X Genre country rap BeatsPerMinute 154 Energy 59 Danceability 70 Loudness -6 Liveness 12 Valence 48 Length 115 Acousticness 34 Speechiness 8 Popularity 91 Name: 21, dtype: object P2. Print the 5 shortest songs (all features): In [334]: # [TODO] TO BE FILLED IN DURING CLASS PARTICIPATION top50 . sort_values ( \"Length\" , ascending = True )[ 0 : 5 ] P3. What is the average length of the 5 shortest songs? In [343]: # [TODO] TO BE FILLED IN DURING CLASS PARTICIPATION top50 . sort_values ( \"Length\" , ascending = True )[ 0 : 5 ][ 'Length' ] . mean () P4. Write a function that accepts a DataFrame as an input and returns True if there exists any null values in the DataSet. Otherwise, returns False. Pass top50 to the function in order to test it. In [22]: # [TODO] TO BE FILLED IN DURING CLASS PARTICIPATION #print(top50['Genre'].isnull()) def contains_nulls ( df ): for col in df . columns : if np . sum ( df [ col ] . isnull ()) > 0 : return True return False contains_nulls ( top50 ) Out[22]: False P5. How many distinct genres are present in the top 50 songs? In [23]: # [TODO] TO BE FILLED IN DURING CLASS PARTICIPATION len ( top50 [ 'Genre' ] . unique ()) Out[23]: 21 P6. Print the songs that have a Danceability score above 80 and a popularity above 86. HINT: you can combine conditional statements with the & operator, and each item must be surrounded with ( ) brackets. In [24]: # [TODO] TO BE FILLED IN DURING CLASS PARTICIPATION top50 [( top50 [ 'Danceability' ] > 80 ) & ( top50 [ 'Popularity' ] > 86 )] Out[24]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unnamed: 0 TrackName ArtistName Genre BeatsPerMinute Energy Danceability Loudness Liveness Valence Length Acousticness Speechiness Popularity 8 9 Old Town Road - Remix Lil Nas X country rap 136 62 88 -6 11 64 157 5 10 87 14 15 Money In The Grave (Drake ft. Rick Ross) Drake canadian hip hop 101 50 83 -4 12 10 205 10 5 92 18 19 Lalala Y2K canadian hip hop 130 39 84 -8 14 50 161 18 8 88 44 45 Con Altura ROSALÍA r&b en espanol 98 69 88 -4 5 75 162 39 12 88 P7. Print the songs that are faster than the average Top 50 and more popular than the average Top 50? In [25]: # [TODO] TO BE FILLED IN DURING CLASS PARTICIPATION avg_speed = top50 [ 'BeatsPerMinute' ] . mean () avg_popularity = top50 [ 'Popularity' ] . mean () top50 [( top50 [ 'BeatsPerMinute' ] > avg_speed ) & ( top50 [ 'Popularity' ] > avg_popularity )] Out[25]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unnamed: 0 TrackName ArtistName Genre BeatsPerMinute Energy Danceability Loudness Liveness Valence Length Acousticness Speechiness Popularity 4 5 Goodbyes (Feat. Young Thug) Post Malone dfw rap 150 65 58 -4 11 18 175 45 7 94 6 7 Ransom Lil Tecca trap music 180 64 75 -6 7 23 131 2 29 92 9 10 bad guy Billie Eilish electropop 135 43 70 -11 10 56 194 33 38 95 10 11 Callaita Bad Bunny reggaeton 176 62 61 -5 24 24 251 60 31 93 16 17 LA CANCIÓN J Balvin latin 176 65 75 -6 11 43 243 15 32 90 18 19 Lalala Y2K canadian hip hop 130 39 84 -8 14 50 161 18 8 88 19 20 Truth Hurts Lizzo escape room 158 62 72 -3 12 41 173 11 11 91 20 21 Piece Of Your Heart MEDUZA pop house 124 74 68 -7 7 63 153 4 3 91 21 22 Panini Lil Nas X country rap 154 59 70 -6 12 48 115 34 8 91 24 25 bad guy (with Justin Bieber) Billie Eilish electropop 135 45 67 -11 12 68 195 25 30 89 31 32 7 rings Ariana Grande dance pop 140 32 78 -11 9 33 179 59 33 89 36 37 Otro Trago Sech panamanian pop 176 70 75 -5 11 62 226 14 34 91 46 47 Te Robaré Nicky Jam latin 176 75 67 -4 8 80 202 24 6 88 P8. Plot a histogram of the Genre counts (x-axis is the Genres, y-axis is the # of songs with that Genre) In [26]: # [TODO] TO BE FILLED IN DURING CLASS PARTICIPATION P9. (open ended) Think of a subset of the data that you're interested in. Think of an interesting plot that could be shown to illustrate that data. With a partner, discuss whose would be easier to create. Together, create that plot. Then, try to create the harder plot. In [354]: # [TODO] TO BE FILLED IN DURING CLASS PARTICIPATION if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"pages","url":"pages/lecture-3/notebook/"},{"title":"Lecture 3: Pandas and Web Scraping","text":"Slides Lecture 3: Pandas and Web Scraping [pptx] Lecture 3: Pandas and Web Scraping [pdf] Lecture Notebook Lecture 3: Pandas Tutorial","tags":"lectures","url":"lectures/lecture3/"},{"title":"Lecture 2: Data Science Demo (repeat from Lecture 1)","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109A Introduction to Data Science Lecture 2: Example Harvard University Fall 2019 Instructors : Protopapas, Rader, and Tanner In [ ]: import pandas as pd import numpy as np import scipy as sp import matplotlib.pyplot as plt from math import radians , cos , sin , asin , sqrt import datetime from sklearn.linear_model import LinearRegression import seaborn as sns sns . set ( style = \"ticks\" ) % matplotlib inline Download the data from https://drive.google.com/open?id=0B28c493CP9GtMzN1emFoMkJNNlU First Look At The Data In [ ]: hubway_data = pd . read_csv ( 'hubway_trips.csv' , low_memory = False ) hubway_data . head () In [ ]: hubway_data . shape A little data manipulation In [ ]: check_out_year = hubway_data [ 'start_date' ] . apply ( lambda s : int ( s [ - 13 : - 9 ])) year_to_age = ( check_out_year - hubway_data [ 'birth_date' ]) Who In [ ]: fig , ax = plt . subplots ( 1 , 2 , figsize = ( 15 , 6 )) #And now for our first plot: a barplot of gender gender_counts = np . unique ( hubway_data [ 'gender' ] . replace ( np . nan , 'NaN' , regex = True ) . values , return_counts = True ) ax [ 0 ] . bar ( range ( 3 ), gender_counts [ 1 ], align = 'center' , color = [ 'black' , 'green' , 'teal' ], alpha = 0.5 ) ax [ 0 ] . set_xticks ([ 0 , 1 , 2 ]) ax [ 0 ] . set_xticklabels ([ 'none' , 'male' , 'female' , ' ' ]) ax [ 0 ] . set_title ( 'Users by Gender' ) #And a histogram of ages ax [ 1 ] . hist ( year_to_age . dropna (), bins = 30 ) ax [ 1 ] . set_title ( 'Histogram of User Ages by Checkout' ) ax [ 1 ] . axvline ( x = np . mean ( year_to_age . dropna ()), color = 'red' , label = 'Average Age' ) ax [ 1 ] . legend () plt . show () In [ ]: #And now for a second plot: scatter plot of age with duration plt . yscale ( 'log' ) plt . scatter ( year_to_age , hubway_data . duration + 1 ) plt . title ( 'Scatter plot of Duration by User Ages' ) plt . xlabel ( 'Age in years' ) plt . ylabel ( 'Duration (in seconds)' ) plt . show () Where In [ ]: station_data = pd . read_csv ( 'hubway_stations.csv' , low_memory = False )[[ 'id' , 'lat' , 'lng' ]] station_data . head () In [ ]: hubway_data_with_gps = hubway_data . join ( station_data . set_index ( 'id' ), on = 'strt_statn' ) hubway_data_with_gps . head () When In [ ]: #check_out_times = pd.to_datetime(hubway_data['start_date']) check_out_hours = hubway_data [ 'start_date' ] . apply ( lambda s : int ( s [ - 8 : - 6 ])) In [ ]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 5 )) check_out_counts = np . unique ( check_out_hours , return_counts = True ) ax . bar ( check_out_counts [ 0 ], check_out_counts [ 1 ], align = 'center' , width = 0.4 , alpha = 0.6 ) ax . set_xlim ([ - 1 , 24 ]) ax . set_xticks ( range ( 24 )) ax . set_xlabel ( 'Hour of Day' ) ax . set_ylabel ( 'Number of Checkouts' ) ax . set_title ( 'Time of Day vs Checkouts' ) plt . show () How In [ ]: def haversine ( pt , lat2 = 42.355589 , lon2 =- 71.060175 ): \"\"\" Calculate the great circle distance between two points on the earth (specified in decimal degrees) \"\"\" lon1 = pt [ 0 ] lat1 = pt [ 1 ] # convert decimal degrees to radians lon1 , lat1 , lon2 , lat2 = map ( radians , [ lon1 , lat1 , lon2 , lat2 ]) # haversine formula dlon = lon2 - lon1 dlat = lat2 - lat1 a = sin ( dlat / 2 ) ** 2 + cos ( lat1 ) * cos ( lat2 ) * sin ( dlon / 2 ) ** 2 c = 2 * asin ( sqrt ( a )) r = 3956 # Radius of earth in miles return c * r In [ ]: station_counts = np . unique ( hubway_data_with_gps [ 'strt_statn' ] . dropna (), return_counts = True ) counts_df = pd . DataFrame ({ 'id' : station_counts [ 0 ], 'checkouts' : station_counts [ 1 ]}) counts_df = counts_df . join ( station_data . set_index ( 'id' ), on = 'id' ) #add distance counts_df . loc [:, 'dist_to_center' ] = list ( map ( haversine , counts_df [[ 'lng' , 'lat' ]] . values )) counts_df . head () In [ ]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 5 )) ax . scatter ( counts_df [ 'dist_to_center' ] . values , counts_df [ 'checkouts' ] . values ) reg_line = LinearRegression () reg_line . fit ( counts_df [ 'dist_to_center' ] . values . reshape (( len ( counts_df [ 'dist_to_center' ]), 1 )), counts_df [ 'checkouts' ] . values ) distances = np . linspace ( counts_df [ 'dist_to_center' ] . min (), counts_df [ 'dist_to_center' ] . max (), 50 ) ax . plot ( distances , reg_line . predict ( distances . reshape (( len ( distances ), 1 ))), color = 'red' , label = 'Regression Line' ) ax . set_xlabel ( 'Distance to City Center (Miles)' ) ax . set_ylabel ( 'Number of Checkouts' ) ax . set_title ( 'Distance to City Center vs Checkouts' ) ax . legend () plt . savefig ( 'How.png' , dpi = 300 ) In [ ]: #let's look at some subgroups print ( np . unique ( hubway_data . subsc_type , return_counts = True )) In [ ]: #And now for a plot of histograms across registration type duration_registered = ( hubway_data . duration [ hubway_data . subsc_type == 'Registered' ]) duration_casual = ( hubway_data . duration [ hubway_data . subsc_type == 'Casual' ]) print ( np . mean ( duration_registered )) print ( np . mean ( duration_casual )) logduration_registered = np . log ( duration_registered + 1 ) logduration_casual = np . log ( duration_casual + 1 ) plt . hist ( logduration_registered . dropna (), alpha =. 5 , bins = 30 ) plt . hist ( logduration_casual . dropna (), alpha =. 5 , bins = 30 ) #plt.hist(duration_registered.dropna()+1, alpha=.5) #plt.hist(duration_casual.dropna()+1, alpha=.5) plt . title ( 'Histograms of duration split by Checkouts' ) plt . xlabel ( 'Duration (in log(seconds))' ) plt . ylabel ( 'Number of Checkouts' ) #plt.xscale('log') plt . show () if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lecture-2/notebook/"},{"title":"Lab 1: Python basics, YAML environments, Numpy","text":"Jupyter Notebooks Lab 1: Introduction to Python and its Libraries","tags":"labs","url":"labs/lab-1/"},{"title":"Lab 01: YAML Environments, Python basics, Numpy","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS-109A Introduction to Data Science Lab 1: Introduction to Python and its Numerical Stack Harvard University Fall 2019 Instructors: Pavlos Protopapas, Kevin Rader, and Chris Tanner Lab Instructor: Eleni Kaxiras Authors: Rahul Dave, David Sondak, Will Claybaugh, Pavlos Protopapas, Chris Tanner, and Eleni Kaxiras In [1]: ## RUN THIS CELL TO GET THE RIGHT FORMATTING import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } span.sub-q { font-weight: bold; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } In [2]: PATHTOSOLUTIONS = '../solutions' Programming Expectations All assignments for this class will use Python and the browser-based iPython notebook format you are currently viewing. Programming at the level of CS 50 is a prerequisite for this course. If you have concerns about this, come speak with any of the instructors. We will refer to the Python 3 documentation in this lab and throughout the course. Learning Goals This introductory lab is a condensed introduction to Python numerical programming. By the end of this lab, you will feel more comfortable: Learn about anconda environments and setup your own with the necessary dependencies Writing short Python code using functions, loops, lists, numpy arrays, and dictionaries. Manipulating Python lists and numpy arrays and understanding the difference between them. Introducing the stats libraries scipy.stats and statsmodels Part 1: Set up a Conda Python Environment and Clone the Class Repository On Python installation packages There are two main installing packages for Python, conda and pip . Pip is the Python Packaging Authority's recommended tool for installing packages from the Python Package Index (PyPI) . Conda is a cross platform package and environment manager that installs and manages conda packages from the Anaconda repository and Anaconda Cloud . Conda does not assume any specific configuration in your computer and will install the Python interpreter along with the other Python packages, whereas pip assumes that you have installed the Python interpreter in your computer. Given the fact that most operating systems do include Python this is not a problem. If I could summarize their differences into a sentence it would be that conda has the ability to create isolated environments that can contain different versions of Python and/or the packages installed in them. This can be extremely useful when working with data science tools as different tools may contain conflicting requirements which could prevent them all being installed into a single environment. You can have environments with pip but would have to install a tool such as virtualenv or venv. You may use either, we recommend conda because in our experience it leads to fewer incompatibilities between packages and thus fewer broken environments. Conclusion: Use Both. Most often in our data science environments we want to combining pip with conda when one or more packages are only available to install via pip. Although thousands of packages are available in the Anaconda repository, including the most popular data science, machine learning, and AI frameworks but a lot more are available on PyPI. Even if you have your environment installed via conda you can use pip to install individual packages ( source: anaconda site ) Installing Conda - First check if you have conda In MacOS or Linux open a Terminal window and at the prompt type conda –V If you get the version number (e.g. conda 4.6.14 ) you are all set! If you get an error, that means you do not have Anaconda and would be a good idea to install it. - If you do not have it, you can install it by following the instructions: Mac : https://docs.anaconda.com/anaconda/install/mac-os/ Windows : https://docs.anaconda.com/anaconda/install/windows (Note: #8 is important: DO NOT add to your path. The reason is that Windows contains paths that may include spaces and that clashes with the way conda understands paths.) - If you do have anaconda consider upgrading it so you get the latest version of the packages: conda update conda Conda allows you to work in 'computing sandboxes' called environments. You may have environments installed on your computer to access different versions of Python and different libraries to avoid conflict between libraries which can cause errors. NOTE (Sept.6, 2019): If you are still having issues please check the Announcements and the Discussion Forum (Ed) via the 2019-CS109a Canvas site Also please check the latest version of the cs109a.yml file. We have edited it as of today. What are environments and do I need them? Environments in Python are like sandboxes that have different versions of Python and/or packages installed in them. You can create, export, list, remove, and update environments. Switching or moving between environments is called activating the environment. When you are done with an environments you may deactivate it. For this class we want to have a bit more control on the packages that will be installed with the enviromnent so we will create an environment with a so called YAML file called cs109a.yml . Originally YAML was said to mean Yet Another Markup Language referencing its purpose as a markup language with the yet another construct, but it was then repurposed as YAML Ain't Markup Language [source:wikipedia]. This is included in the Lab directory in the class git repository. Creating an environment from an environment.yml file Using your browser, visit the class git repository https://github.com/Harvard-IACS/2019-CS109A Go to content --> labs/ --> lab1 and look for the cs109a.yml file. Download it to a local directory in your computer. Then in the Terminal again type conda env create -f {PATH-TO-FILE}/cs109a.yml Activate the new environment: source activate cs109a You should see the name of the environment at the start of your command prompth in parenthesis. Verify that the new environment was installed correctly: conda list This will give you a list of the packages installed in this environment. References Manage conda environments Clone the class repository In the Terminal type: git clone https://github.com/Harvard-IACS/2019-CS109A.git Starting the Jupyter Notebook Once all is installed go in the Terminal and type jupyter notebook to start the jupyter notebook server. This will spawn a process that will be running in the Terminal window until you are done working with the notebook. In that case press control-C to stop it. Starting the notebook will bring up a browser window with your file structure. Look for the 2019-CS109A folder. It should be where you cloned it previously. When you visit this folder in the future, and while in the top folder of it, type git pull This will update the contents of the folder with whatever is new. Make sure you are at the top part of the folder by typing pwd which should give you /2019-CS109A/ For more on using the Notebook see : https://jupyter-notebook.readthedocs.io/en/latest/ Part 2: Getting Started with Python Importing modules All notebooks should begin with code that imports modules , collections of built-in, commonly-used Python functions. Below we import the Numpy module, a fast numerical programming library for scientific computing. Future labs will require additional modules, which we'll import with the same syntax. import MODULE_NAME as MODULE_NICKNAME In [3]: import numpy as np #imports a fast numerical programming library Now that Numpy has been imported, we can access some useful functions. For example, we can use mean to calculate the mean of a set of numbers. In [4]: my_list = [ 1.2 , 2 , 3.3 ] np . mean ( my_list ) Out[4]: 2.1666666666666665 Calculations and variables In [5]: # // is integer division 1 / 2 , 1 // 2 , 1.0 / 2 , 3 * 3.2 Out[5]: (0, 0, 0.5, 9.600000000000001) The last line in a cell is returned as the output value, as above. For cells with multiple lines of results, we can display results using print , as can be seen below. In [6]: print ( 1 + 3.0 , \" \\n \" , 9 , 7 ) 5 / 3 (4.0, '\\n', 9, 7) Out[6]: 1 We can store integer or floating point values as variables. The other basic Python data types -- booleans, strings, lists -- can also be stored as variables. In [7]: a = 1 b = 2.0 Here is the storing of a list In [1]: a = [ 1 , 2 , 3 ] Think of a variable as a label for a value, not a box in which you put the value (image: Fluent Python by Luciano Ramalho) In [2]: b = a b Out[2]: [1, 2, 3] This DOES NOT create a new copy of a . It merely puts a new label on the memory at a, as can be seen by the following code: In [3]: print ( \"a\" , a ) print ( \"b\" , b ) a [ 1 ] = 7 print ( \"a after change\" , a ) print ( \"b after change\" , b ) a [1, 2, 3] b [1, 2, 3] a after change [1, 7, 3] b after change [1, 7, 3] Tuples Multiple items on one line in the interface are returned as a tuple , an immutable sequence of Python objects. See the end of this notebook for an interesting use of tuples . In [10]: a = 1 b = 2.0 a + a , a - b , b * b , 10 * a Out[10]: (2, -1.0, 4.0, 10) type() We can obtain the type of a variable, and use boolean comparisons to test these types. VERY USEFUL when things go wrong and you cannot understand why this method does not work on a specific variable! In [11]: type ( a ) == float Out[11]: False In [12]: type ( a ) == int Out[12]: True In [13]: type ( a ) Out[13]: int For reference, below are common arithmetic and comparison operations. EXERCISE 1: Create a tuple called `tup` with the following seven objects: The first element is an integer of your choice The second element is a float of your choice The third element is the sum of the first two elements The fourth element is the difference of the first two elements The fifth element is the first element divided by the second element Display the output of tup . What is the type of the variable tup ? What happens if you try and chage an item in the tuple? In [6]: # your code here tup = ( 1 , 1.1 , 1 + 1.1 , 1 - 1.1 , 1 / 1.1 ) print ( tup ) print ( type ( tup )) (1, 1.1, 2.1, -0.10000000000000009, 0.9090909090909091) In [73]: # TO RUN THE SOLUTIONS # 1. uncomment the first line of the cell below so you have just %load # 2. Run the cell AGAIN to execute the python code, it will not run when you execute the %load command!! In [8]: # %load ../solutions/exercise1.py a = 3 b = 4.0 c = a + b d = a - b e = a / b tup = ( a , b , c , d , e ) tup Out[8]: (3, 4.0, 7.0, -1.0, 0.75) Lists Much of Python is based on the notion of a list. In Python, a list is a sequence of items separated by commas, all within square brackets. The items can be integers, floating points, or another type. Unlike in C arrays, items in a Python list can be different types, so Python lists are more versatile than traditional arrays in C or other languages. Let's start out by creating a few lists. In [16]: empty_list = [] float_list = [ 1. , 3. , 5. , 4. , 2. ] int_list = [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 ] mixed_list = [ 1 , 2. , 3 , 4. , 5 ] print ( empty_list ) print ( int_list ) print ( mixed_list , float_list ) [] [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] ([1, 2.0, 3, 4.0, 5], [1.0, 3.0, 5.0, 4.0, 2.0]) Lists in Python are zero-indexed, as in C. The first entry of the list has index 0, the second has index 1, and so on. In [17]: print ( int_list [ 0 ]) print ( float_list [ 1 ]) 1 3.0 What happens if we try to use an index that doesn't exist for that list? Python will complain! In [18]: print ( float_list [ 10 ]) --------------------------------------------------------------------------- IndexError Traceback (most recent call last) in () ----> 1 print ( float_list [ 10 ] ) IndexError : list index out of range You can find the length of a list using the built-in function len : In [19]: print ( float_list ) len ( float_list ) [1.0, 3.0, 5.0, 4.0, 2.0] Out[19]: 5 Indexing on lists plus Slicing And since Python is zero-indexed, the last element of float_list is In [20]: float_list [ len ( float_list ) - 1 ] Out[20]: 2.0 It is more idiomatic in Python to use -1 for the last element, -2 for the second last, and so on In [21]: float_list [ - 1 ] Out[21]: 2.0 We can use the : operator to access a subset of the list. This is called slicing. In [22]: print ( float_list [ 1 : 5 ]) print ( float_list [ 0 : 2 ]) [3.0, 5.0, 4.0, 2.0] [1.0, 3.0] Below is a summary of list slicing operations: In [24]: lst = [ 'hi' , 7 , 'c' , 'cat' , 'hello' , 8 ] lst [: 2 ] Out[24]: ['hi', 7] You can slice \"backwards\" as well: In [25]: float_list [: - 2 ] # up to second last Out[25]: [1.0, 3.0, 5.0] In [26]: float_list [: 4 ] # up to but not including 5th element Out[26]: [1.0, 3.0, 5.0, 4.0] You can also slice with a stride: In [27]: float_list [: 4 : 2 ] # above but skipping every second element Out[27]: [1.0, 5.0] We can iterate through a list using a loop. Here's a for loop. In [28]: for ele in float_list : print ( ele ) 1.0 3.0 5.0 4.0 2.0 What if you wanted the index as well? Use the built-in python method enumerate , which can be used to create a list of tuples with each tuple of the form (index, value) . In [29]: for i , ele in enumerate ( float_list ): print ( i , ele ) (0, 1.0) (1, 3.0) (2, 5.0) (3, 4.0) (4, 2.0) Appending and deleting We can also append items to the end of the list using the + operator or with append . In [30]: float_list + [ . 333 ] Out[30]: [1.0, 3.0, 5.0, 4.0, 2.0, 0.333] In [31]: float_list . append ( . 444 ) In [32]: print ( float_list ) len ( float_list ) [1.0, 3.0, 5.0, 4.0, 2.0, 0.444] Out[32]: 6 Now, run the cell with float_list.append() a second time. Then run the subsequent cell. What happens? To remove an item from the list, use del. In [33]: del ( float_list [ 2 ]) print ( float_list ) [1.0, 3.0, 4.0, 2.0, 0.444] You may also add an element (elem) in a specific position (index) in the list In [34]: elem = '3.14' index = 1 float_list . insert ( index , elem ) float_list Out[34]: [1.0, '3.14', 3.0, 4.0, 2.0, 0.444] List Comprehensions Lists can be constructed in a compact way using a list comprehension . Here's a simple example. In [35]: squaredlist = [ i * i for i in int_list ] squaredlist Out[35]: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] And here's a more complicated one, requiring a conditional. In [36]: comp_list1 = [ 2 * i for i in squaredlist if i % 2 == 0 ] print ( comp_list1 ) [8, 32, 72, 128, 200] This is entirely equivalent to creating comp_list1 using a loop with a conditional, as below: In [37]: comp_list2 = [] for i in squaredlist : if i % 2 == 0 : comp_list2 . append ( 2 * i ) print ( comp_list2 ) [8, 32, 72, 128, 200] The list comprehension syntax [expression for item in list if conditional] is equivalent to the syntax for item in list: if conditional: expression Exercise 2: (do at home) Build a list that contains every prime number between 1 and 100, in two different ways: 2.1 Using for loops and conditional if statements. 2.2 (Stretch Goal) Using a list comprehension. You should be able to do this in one line of code. Hint: it might help to look up the function all() in the documentation. In [14]: primes = [] for i in range ( 1 , 101 ): if sum ([( i % p ) == 0 for p in primes ]) > 0 : continue if i != 1 : primes . append ( i ) primes Out[14]: [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97] In [18]: [ i for i in range ( 2 , 101 ) if all ( i % j != 0 for j in range ( 2 , i ))] Out[18]: [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97] In [ ]: # %load ../solutions/exercise2_1.py N = 100 ; # using loops and if statements primes = []; for j in range ( 2 , N ): count = 0 ; for i in range ( 2 , j ): if j % i == 0 : count = count + 1 ; if count == 0 : primes . append ( j ) print ( primes ) In [ ]: # %load ../solutions/exercise2_2.py primes_lc = [ j for j in range ( 2 , N ) if all ( j % i != 0 for i in range ( 2 , j ))] print ( primes ) print ( primes_lc ) Simple Functions A function object is a reusable block of code that does a specific task. Functions are commonplace in Python, either on their own or as they belong to other objects. To invoke a function func , you call it as func(arguments) . We've seen built-in Python functions and methods (details below). For example, len() and print() are built-in Python functions. And at the beginning, you called np.mean() to calculate the mean of three numbers, where mean() is a function in the numpy module and numpy was abbreviated as np . This syntax allows us to have multiple \"mean\" functions in different modules; calling this one as np.mean() guarantees that we will execute numpy's mean function, as opposed to a mean function from a different module. User-defined functions We'll now learn to write our own user-defined functions. Below is the syntax for defining a basic function with one input argument and one output. You can also define functions with no input or output arguments, or multiple input or output arguments. def name_of_function(arg): ... return(output) We can write functions with one input and one output argument. Here are two such functions. In [42]: def square ( x ): x_sqr = x * x return ( x_sqr ) def cube ( x ): x_cub = x * x * x return ( x_cub ) square ( 5 ), cube ( 5 ) Out[42]: (25, 125) What if you want to return two variables at a time? The usual way is to return a tuple: In [43]: def square_and_cube ( x ): x_cub = x * x * x x_sqr = x * x return ( x_sqr , x_cub ) square_and_cube ( 5 ) Out[43]: (25, 125) Lambda functions Often we quickly define mathematical functions with a one-line function called a lambda function. Lambda functions are great because they enable us to write functions without having to name them, ie, they're anonymous . No return statement is needed. In [44]: # create an anonymous function and assign it to the variable square square = lambda x : x * x print ( square ( 3 )) hypotenuse = lambda x , y : x * x + y * y ## Same as # def hypotenuse(x, y): # return(x*x + y*y) hypotenuse ( 3 , 4 ) 9 Out[44]: 25 Methods A function that belongs to an object is called a method . By \"object,\" we mean an \"instance\" of a class (e.g., list, integer, or floating point variable). For example, when we invoke append() on an existing list, append() is a method. In other words, a method is a function on a specific instance of a class (i.e., object ). In this example, our class is a list. float_list is an instance of a list (thus, an object), and the append() function is technically a method since it pertains to the specific instance float_list . In [45]: float_list = [ 1.0 , 2.09 , 4.0 , 2.0 , 0.444 ] print ( float_list ) float_list . append ( 56.7 ) float_list [1.0, 2.09, 4.0, 2.0, 0.444] Out[45]: [1.0, 2.09, 4.0, 2.0, 0.444, 56.7] Exercise 3: (do at home) generated a list of the prime numbers between 1 and 100 In Exercise 2, above, you wrote code that generated a list of the prime numbers between 1 and 100. Now, write a function called isprime() that takes in a positive integer $N$, and determines whether or not it is prime. Return True if it's prime and return False if it isn't. Then, using a list comprehension and isprime() , create a list myprimes that contains all the prime numbers less than 100. In [19]: # your code here def isprime ( n ): return all ([ n % i != 0 for i in range ( 2 , n )]) In [26]: [ n for n in range ( 2 , 100 ) if isprime ( n )] Out[26]: [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97] In [ ]: # %load ../solutions/exercise3.py def isprime ( N ): count = 0 ; if not isinstance ( N , int ): return False if N <= 1 : return False for i in range ( 2 , N ): if N % i == 0 : count = count + 1 ; if count == 0 : return ( True ) else : return ( False ) print ( isprime ( 3.0 ), isprime ( \"pavlos\" ), isprime ( 0 ), isprime ( - 1 ), isprime ( 1 ), isprime ( 2 ), isprime ( 93 ), isprime ( 97 )) myprimes = [ j for j in range ( 1 , 100 ) if isprime ( j )] print ( myprimes ) Introduction to Numpy Scientific Python code uses a fast array structure, called the numpy array. Those who have programmed in Matlab will find this very natural. For reference, the numpy documention can be found here . Let's make a numpy array: In [48]: my_array = np . array ([ 1 , 2 , 3 , 4 ]) my_array Out[48]: array([1, 2, 3, 4]) In [49]: # works as it would with a standard list len ( my_array ) Out[49]: 4 The shape array of an array is very useful (we'll see more of it later when we talk about 2D arrays -- matrices -- and higher-dimensional arrays). In [50]: my_array . shape Out[50]: (4,) Numpy arrays are typed . This means that by default, all the elements will be assumed to be of the same type (e.g., integer, float, String). In [51]: my_array . dtype Out[51]: dtype('int64') Numpy arrays have similar functionality as lists! Below, we compute the length, slice the array, and iterate through it (one could identically perform the same with a list). In [52]: print ( len ( my_array )) print ( my_array [ 2 : 4 ]) for ele in my_array : print ( ele ) 4 [3 4] 1 2 3 4 There are two ways to manipulate numpy arrays a) by using the numpy module's methods (e.g., np.mean() ) or b) by applying the function np.mean() with the numpy array as an argument. In [53]: print ( my_array . mean ()) print ( np . mean ( my_array )) 2.5 2.5 A constructor is a general programming term that refers to the mechanism for creating a new object (e.g., list, array, String). There are many other efficient ways to construct numpy arrays. Here are some commonly used numpy array constructors. Read more details in the numpy documentation. In [54]: np . ones ( 10 ) # generates 10 floating point ones Out[54]: array([ 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]) Numpy gains a lot of its efficiency from being typed. That is, all elements in the array have the same type, such as integer or floating point. The default type, as can be seen above, is a float. (Each float uses either 32 or 64 bits of memory, depending on if the code is running a 32-bit or 64-bit machine, respectively). In [55]: np . dtype ( float ) . itemsize # in bytes (remember, 1 byte = 8 bits) Out[55]: 8 In [56]: np . ones ( 10 , dtype = 'int' ) # generates 10 integer ones Out[56]: array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) In [57]: np . zeros ( 10 ) Out[57]: array([ 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) Often, you will want random numbers. Use the random constructor! In [58]: np . random . random ( 10 ) # uniform from [0,1] Out[58]: array([ 0.85115672, 0.37346821, 0.3298871 , 0.47496563, 0.69940192, 0.97207796, 0.91488615, 0.36063927, 0.81240722, 0.16128617]) You can generate random numbers from a normal distribution with mean 0 and variance 1: In [59]: normal_array = np . random . randn ( 1000 ) print ( \"The sample mean and standard devation are %f and %f , respectively.\" % ( np . mean ( normal_array ), np . std ( normal_array ))) The sample mean and standard devation are 0.025195 and 1.026880, respectively. In [60]: len ( normal_array ) Out[60]: 1000 You can sample with and without replacement from an array. Let's first construct a list with evenly-spaced values: In [61]: grid = np . arange ( 0. , 1.01 , 0.1 ) grid Out[61]: array([ 0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]) Without replacement In [62]: np . random . choice ( grid , 5 , replace = False ) Out[62]: array([ 0.3, 0.8, 0.7, 1. , 0. ]) In [63]: np . random . choice ( grid , 20 , replace = False ) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) in () ----> 1 np . random . choice ( grid , 20 , replace = False ) mtrand.pyx in mtrand.RandomState.choice () ValueError : Cannot take a larger sample than population when 'replace=False' With replacement: In [64]: np . random . choice ( grid , 20 , replace = True ) Out[64]: array([ 0. , 1. , 0.3, 1. , 0. , 0.9, 1. , 0.7, 0.2, 0.7, 0.4, 0.6, 0.1, 0.6, 0.4, 0.3, 0.6, 0.3, 0.8, 1. ]) Tensors We can think of tensors as a name to include multidimensional arrays of numerical values. While tensors first emerged in the 20th century, they have since been applied to numerous other disciplines, including machine learning. In this class you will only be using scalars , vectors , and 2D arrays , so you do not need to worry about the name 'tensor'. We will use the following naming conventions: scalar = just a number = rank 0 tensor ($a$ ∈ $F$,) vector = 1D array = rank 1 tensor ( $x = (\\;x_1,...,x_i\\;)⊤$ ∈ $F&#94;n$ ) matrix = 2D array = rank 2 tensor ( $\\textbf{X} = [a_{ij}] ∈ F&#94;{m×n}$ ) 3D array = rank 3 tensor ( $\\mathscr{X} =[t_{i,j,k}]∈F&#94;{m×n×l}$ ) $\\mathscr{N}$D array = rank $\\mathscr{N}$ tensor ( $\\mathscr{T} =[t_{i1},...,t_{i\\mathscr{N}}]∈F&#94;{n_1×...×n_\\mathscr{N}}$ ) Slicing a 2D array source:oreilly In [ ]: # how do we get just the second row of the above array? Numpy supports vector operations What does this mean? It means that instead of adding two arrays, element by element, you can just say: add the two arrays. In [ ]: first = np . ones ( 5 ) second = np . ones ( 5 ) first + second # adds in-place Note that this behavior is very different from python lists where concatenation happens. In [ ]: first_list = [ 1. , 1. , 1. , 1. , 1. ] second_list = [ 1. , 1. , 1. , 1. , 1. ] first_list + second_list # concatenation On some computer chips, this numpy addition actually happens in parallel and can yield significant increases in speed. But even on regular chips, the advantage of greater readability is important. Broadcasting Numpy supports a concept known as broadcasting , which dictates how arrays of different sizes are combined together. There are too many rules to list here, but importantly, multiplying an array by a number multiplies each element by the number. Adding a number adds the number to each element. In [ ]: first + 1 In [ ]: first * 5 This means that if you wanted the distribution $N(5, 7)$ you could do: In [ ]: normal_5_7 = 5 + 7 * normal_array np . mean ( normal_5_7 ), np . std ( normal_5_7 ) Multiplying two arrays multiplies them element-by-element In [ ]: ( first + 1 ) * ( first * 5 ) You might have wanted to compute the dot product instead: In [ ]: np . dot (( first + 1 ) , ( first * 5 )) Probabilitiy Distributions from scipy.stats and statsmodels Two useful statistics libraries in python are scipy and statsmodels . For example to load the z_test: In [ ]: import statsmodels from statsmodels.stats.proportion import proportions_ztest In [ ]: x = np . array ([ 74 , 100 ]) n = np . array ([ 152 , 266 ]) zstat , pvalue = statsmodels . stats . proportion . proportions_ztest ( x , n ) print ( \"Two-sided z-test for proportions: \\n \" , \"z =\" , zstat , \", pvalue =\" , pvalue ) In [ ]: #The `%matplotlib inline` ensures that plots are rendered inline in the browser. % matplotlib inline import matplotlib.pyplot as plt Let's get the normal distribution namespace from scipy.stats . See here for Documentation . In [ ]: from scipy.stats import norm Let's create 1,000 points between -10 and 10 In [ ]: x = np . linspace ( - 10 , 10 , 1000 ) # linspace() returns evenly-spaced numbers over a specified interval x [ 0 : 10 ], x [ - 10 :] Let's get the pdf of a normal distribution with a mean of 1 and standard deviation 3, and plot it using the grid points computed before: In [ ]: pdf_x = norm . pdf ( x , 1 , 3 ) plt . plot ( x , pdf_x ); And you can get random variables using the rvs function. Referencies A useful book by Jake Vanderplas: PythonDataScienceHandbook . You may also benefit from using Chris Albon's web site as a reference. It contains lots of useful information. Dictionaries A dictionary is another data structure (aka storage container) -- arguably the most powerful. Like a list, a dictionary is a sequence of items. Unlike a list, a dictionary is unordered and its items are accessed with keys and not integer positions. Dictionaries are the closest data structure we have to a database. Let's make a dictionary with a few Harvard courses and their corresponding enrollment numbers. In [ ]: enroll2017_dict = { 'CS50' : 692 , 'CS109A / Stat 121A / AC 209A' : 352 , 'Econ1011a' : 95 , 'AM21a' : 153 , 'Stat110' : 485 } enroll2017_dict One can obtain the value corresponding to a key via: In [ ]: enroll2017_dict [ 'CS50' ] If you try to access a key that isn't present, your code will yield an error: In [ ]: enroll2017_dict [ 'CS630' ] Alternatively, the .get() function allows one to gracefully handle these situations by providing a default value if the key isn't found: In [ ]: enroll2017_dict . get ( 'CS630' , 5 ) Note, this does not store a new value for the key; it only provides a value to return if the key isn't found. In [ ]: enroll2017_dict [ 'CS630' ] In [ ]: enroll2017_dict . get ( 'C730' , None ) All sorts of iterations are supported: In [ ]: enroll2017_dict . values () In [ ]: enroll2017_dict . items () We can iterate over the tuples obtained above: In [ ]: for key , value in enroll2017_dict . items (): print ( \" %s : %d \" % ( key , value )) Simply iterating over a dictionary gives us the keys. This is useful when we want to do something with each item: In [ ]: second_dict = {} for key in enroll2017_dict : second_dict [ key ] = enroll2017_dict [ key ] second_dict The above is an actual copy of _enroll2017 dict's allocated memory, unlike, second_dict = enroll2017_dict which would have made both variables label the same memory location. In the previous dictionary example, the keys were strings corresponding to course names. Keys don't have to be strings, though; they can be other immutable data type such as numbers or tuples (not lists, as lists are mutable). Dictionary comprehension: \"Do not try this at home\" You can construct dictionaries using a dictionary comprehension , which is similar to a list comprehension. Notice the brackets {} and the use of zip (see next cell for more on zip ) In [ ]: float_list = [ 1. , 3. , 5. , 4. , 2. ] int_list = [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 ] my_dict = { k : v for ( k , v ) in zip ( int_list , float_list )} my_dict Creating tuples with zip zip is a Python built-in function that returns an iterator that aggregates elements from each of the iterables. This is an iterator of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables. The iterator stops when the shortest input iterable is exhausted. The set() built-in function returns a set object, optionally with elements taken from another iterable. By using set() you can make zip printable. In the example below, the iterables are the two lists, float_list and int_list . We can have more than two iterables. In [ ]: float_list = [ 1. , 3. , 5. , 4. , 2. ] int_list = [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 ] viz_zip = set ( zip ( int_list , float_list )) viz_zip In [ ]: type ( viz_zip ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab01/"},{"title":"Lecture 1: Data Science Demo","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109A Introduction to Data Science Lecture 1: Example Harvard University Fall 2019 Instructors : Pavlos Protopapas, Kevin Rader, and Chris Tanner In [5]: ## RUN THIS CELL TO GET THE RIGHT FORMATTING from IPython.core.display import HTML def css_styling (): styles = open ( \"../../../styles/cs109.css\" , \"r\" ) . read () return HTML ( styles ) css_styling () Out[5]: h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } In [6]: import pandas as pd import sys import numpy as np import scipy as sp import matplotlib.pyplot as plt from math import radians , cos , sin , asin , sqrt import datetime from sklearn.linear_model import LinearRegression import seaborn as sns sns . set ( style = \"ticks\" ) % matplotlib inline Download the data from https://drive.google.com/open?id=0B28c493CP9GtMzN1emFoMkJNNlU First Look At The Data In [7]: hubway_data_file = '~/Downloads/hubway_data/hubway_trips.csv' hubway_data = pd . read_csv ( hubway_data_file , low_memory = False ) hubway_data . head () Out[7]: .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } seq_id hubway_id status duration start_date strt_statn end_date end_statn bike_nr subsc_type zip_code birth_date gender 0 1 8 Closed 9 7/28/2011 10:12:00 23.0 7/28/2011 10:12:00 23.0 B00468 Registered '97217 1976.0 Male 1 2 9 Closed 220 7/28/2011 10:21:00 23.0 7/28/2011 10:25:00 23.0 B00554 Registered '02215 1966.0 Male 2 3 10 Closed 56 7/28/2011 10:33:00 23.0 7/28/2011 10:34:00 23.0 B00456 Registered '02108 1943.0 Male 3 4 11 Closed 64 7/28/2011 10:35:00 23.0 7/28/2011 10:36:00 23.0 B00554 Registered '02116 1981.0 Female 4 5 12 Closed 12 7/28/2011 10:37:00 23.0 7/28/2011 10:37:00 23.0 B00554 Registered '97214 1983.0 Female Who? In [8]: year_to_age = lambda s : 0 if 'N' in s else 2017 - int ( s ) In [9]: fig , ax = plt . subplots ( 1 , 2 , figsize = ( 15 , 6 )) gender_counts = np . unique ( hubway_data [ 'gender' ] . replace ( np . nan , 'NaN' , regex = True ) . values , return_counts = True ) ax [ 0 ] . bar ( range ( 3 ), gender_counts [ 1 ], align = 'center' , color = [ 'black' , 'green' , 'teal' ], alpha = 0.5 ) ax [ 0 ] . set_xticks ([ 0 , 1 , 2 ]) ax [ 0 ] . set_xticklabels ([ 'none' , 'male' , 'female' , ' ' ]) ax [ 0 ] . set_title ( 'Users by Gender' ) age_col = 2017.0 - hubway_data [ 'birth_date' ] . dropna () . values age_counts = np . unique ( age_col , return_counts = True ) ax [ 1 ] . bar ( age_counts [ 0 ], age_counts [ 1 ], align = 'center' , width = 0.4 , alpha = 0.6 ) ax [ 1 ] . axvline ( x = np . mean ( age_col ), color = 'red' , label = 'average age' ) ax [ 1 ] . axvline ( x = np . percentile ( age_col , 25 ), color = 'red' , linestyle = '--' , label = 'lower quartile' ) ax [ 1 ] . axvline ( x = np . percentile ( age_col , 75 ), color = 'red' , linestyle = '--' , label = 'upper quartile' ) ax [ 1 ] . set_xlim ([ 1 , 90 ]) ax [ 1 ] . set_xlabel ( 'Age' ) ax [ 1 ] . set_ylabel ( 'Number of Checkouts' ) ax [ 1 ] . legend () ax [ 1 ] . set_title ( 'Users by Age' ) plt . tight_layout () plt . savefig ( 'Who.png' , dpi = 300 ) Where In [11]: station_data = pd . read_csv ( 'hubway_stations.csv' , low_memory = False )[[ 'id' , 'lat' , 'lng' ]] station_data . head () Out[11]: .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } id lat lng 0 3 42.340021 -71.100812 1 4 42.345392 -71.069616 2 5 42.341814 -71.090179 3 6 42.361285 -71.065140 4 7 42.353412 -71.044624 In [12]: hubway_data_with_gps = hubway_data . join ( station_data . set_index ( 'id' ), on = 'strt_statn' ) hubway_data_with_gps . head () Out[12]: .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } seq_id hubway_id status duration start_date strt_statn end_date end_statn bike_nr subsc_type zip_code birth_date gender lat lng 0 1 8 Closed 9 7/28/2011 10:12:00 23 7/28/2011 10:12:00 23.0 B00468 Registered '97217 1976.0 Male 42.359677 -71.059364 1 2 9 Closed 220 7/28/2011 10:21:00 23 7/28/2011 10:25:00 23.0 B00554 Registered '02215 1966.0 Male 42.359677 -71.059364 2 3 10 Closed 56 7/28/2011 10:33:00 23 7/28/2011 10:34:00 23.0 B00456 Registered '02108 1943.0 Male 42.359677 -71.059364 3 4 11 Closed 64 7/28/2011 10:35:00 23 7/28/2011 10:36:00 23.0 B00554 Registered '02116 1981.0 Female 42.359677 -71.059364 4 5 12 Closed 12 7/28/2011 10:37:00 23 7/28/2011 10:37:00 23.0 B00554 Registered '97214 1983.0 Female 42.359677 -71.059364 When In [13]: #check_out_times = pd.to_datetime(hubway_data['start_date']) check_out_hours = hubway_data [ 'start_date' ] . apply ( lambda s : int ( s [ - 8 : - 6 ])) In [14]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 5 )) check_out_counts = np . unique ( check_out_hours , return_counts = True ) ax . bar ( check_out_counts [ 0 ], check_out_counts [ 1 ], align = 'center' , width = 0.4 , alpha = 0.6 ) ax . set_xlim ([ - 1 , 24 ]) ax . set_xticks ( range ( 24 )) ax . set_xlabel ( 'Hour of Day' ) ax . set_ylabel ( 'Number of Checkouts' ) ax . set_title ( 'Time of Day vs Checkouts' ) plt . show () How In [15]: def haversine ( pt , lat2 = 42.355589 , lon2 =- 71.060175 ): \"\"\" Calculate the great circle distance between two points on the earth (specified in decimal degrees) \"\"\" lon1 = pt [ 0 ] lat1 = pt [ 1 ] # convert decimal degrees to radians lon1 , lat1 , lon2 , lat2 = map ( radians , [ lon1 , lat1 , lon2 , lat2 ]) # haversine formula dlon = lon2 - lon1 dlat = lat2 - lat1 a = sin ( dlat / 2 ) ** 2 + cos ( lat1 ) * cos ( lat2 ) * sin ( dlon / 2 ) ** 2 c = 2 * asin ( sqrt ( a )) r = 3956 # Radius of earth in miles return c * r In [16]: station_counts = np . unique ( hubway_data_with_gps [ 'strt_statn' ] . dropna (), return_counts = True ) counts_df = pd . DataFrame ({ 'id' : station_counts [ 0 ], 'checkouts' : station_counts [ 1 ]}) counts_df = counts_df . join ( station_data . set_index ( 'id' ), on = 'id' ) counts_df . head () Out[16]: .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } checkouts id lat lng 0 9734 3 42.340021 -71.100812 1 18058 4 42.345392 -71.069616 2 10630 5 42.341814 -71.090179 3 23322 6 42.361285 -71.065140 4 9163 7 42.353412 -71.044624 In [17]: counts_df . loc [:, 'dist_to_center' ] = list ( map ( haversine , counts_df [[ 'lng' , 'lat' ]] . values )) counts_df . head () Out[17]: .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } checkouts id lat lng dist_to_center 0 9734 3 42.340021 -71.100812 2.335706 1 18058 4 42.345392 -71.069616 0.853095 2 10630 5 42.341814 -71.090179 1.802423 3 23322 6 42.361285 -71.065140 0.467803 4 9163 7 42.353412 -71.044624 0.807582 In [18]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 5 )) ax . scatter ( counts_df [ 'dist_to_center' ] . values , counts_df [ 'checkouts' ] . values ) reg_line = LinearRegression () reg_line . fit ( counts_df [ 'dist_to_center' ] . values . reshape (( len ( counts_df [ 'dist_to_center' ]), 1 )), counts_df [ 'checkouts' ] . values ) distances = np . linspace ( counts_df [ 'dist_to_center' ] . min (), counts_df [ 'dist_to_center' ] . max (), 50 ) ax . plot ( distances , reg_line . predict ( distances . reshape (( len ( distances ), 1 ))), color = 'red' , label = 'Regression Line' ) ax . set_xlabel ( 'Distance to City Center (Miles)' ) ax . set_ylabel ( 'Number of Checkouts' ) ax . set_title ( 'Distance to City Center vs Checkouts' ) ax . legend () plt . savefig ( 'How.png' , dpi = 300 ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lecture-1/notebook/"},{"title":"Lecture 1: Introduction","text":"Slides Lecture 1: Introduction [pptx] Lecture 1: Introduction [pdf] Lecture Notebook Lecture 1: Data Science Demo","tags":"lectures","url":"lectures/lecture1/"},{"title":"Lecture 2: Data and Data Exploration","text":"Slides Lecture 2: Data [pptx] Lecture 2: Data [pdf] Lecture Notebook Lecture 2: Data Science Demo","tags":"lectures","url":"lectures/lecture2/"},{"title":"CS109a: Introduction to Data Science","text":"Fall 2019 Pavlos Protopapas , Kevin A. Rader , and Chris Tanner pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } .contentA { flex: 1; flex-direction:column; } .contentB { flex: 3; } Lab Leaders: Chris Tanner and Eleni Kaxiras Welcome to CS109a/STAT121a/AC209a, also offered by the DCE as CSCI E-109a, Introduction to Data Science. This course is the first half of a one‐year course to data science. We will focus on the analysis of data to perform predictions using statistical and machine learning methods. Topics include data scraping, data management, data visualization, regression and classification methods, and deep neural networks. You will get ample practice through weekly homework assignments. The class material integrates the five key facets of an investigation using data: 1. data collection ‐ data wrangling, cleaning, and sampling to get a suitable data set 2. data management ‐ accessing data quickly and reliably 3. exploratory data analysis – generating hypotheses and building intuition 4. prediction or statistical learning 5. communication – summarizing results through visualization, stories, and interpretable summaries Only one of CS 109a, AC 209a, or Stat 121a can be taken for credit. Students who have previously taken CS 109, AC 209, or Stat 121 cannot take CS 109a, AC 209a, or Stat 121a for credit. Helpline: cs109a2019@gmail.com Announcement: HW0 is now available. Lectures: Mon and Wed 1:30‐2:45 pm in Harvard Northwest Building, NW B-103 Labs : Thur 4:30-5:45 pm in Pierce 301 Head TFs : Chris Gumb - DCE Head TF : Sol Girouard Office Hours: IACS student lobby in Maxwell-Dworkin's ground. Just follow the signs. Online Office Hours zoom link: https://harvard-dce.zoom.us/j/7607382317 Course material can be viewed in the public GitHub repository . STANDARD SECTIONS Friday 10/18 10:30-11:45 am 1 Story St. Room 306 Monday 10/21 4:30-5:45 pm Science Center 110 Cover the material presented in class. Both standard sections are identical. ADVANCED SECTIONS Wednesday 10/23 4:30-5:45 pm Maxwell Dworkin G115 Cover a different topic each week and are required for 209a students. Instructor Office Hours Pavlos & Kevin : Monday 3-5 pm, IACS Lobby Chris : Wednesday 3-4 pm, Maxwell-Dworkin B125 TF Office Hours (On-Campus) Monday: 6-9 pm Tuesday: 4-8:30 pm Wednesday: 4-7:30 pm Friday: 1:30-3 pm TF Hours are held in the IACS lobby. Note: Monday & Tuesday the first 1/2 hour of OH will be in the Maxwell-Dworkin main lobby before moving into the IACS lobby. Online Office Hours Tuesday: 3-6 pm Wednesday: 6:30-8 pm Friday: 12-1:30 pm Saturday: 10:30-12 pm Online office hours are held via zoom: https://harvard-dce.zoom.us/j/7607382317 Please be aware, that we will not publicly release the homework assignments this year. If you want to follow the course online without registering, you can use the assignments from 2013 and 2014, available at the links below. Additionally, the material from 2015 is also available. Previous Material 2018 2017 2015 2014 . 2013","tags":"pages","url":"pages/cs109a-introduction-to-data-science/"},{"title":"Advanced Sections 4:","text":"Slides","tags":"a-section","url":"a-section/a-section4/"},{"title":"Advanced Sections 5:","text":"Slides","tags":"a-section","url":"a-section/a-section5/"},{"title":"Advanced Sections 6:","text":"Slides","tags":"a-section","url":"a-section/a-section6/"},{"title":"Lab 10:","text":"Slides","tags":"labs","url":"labs/lab10/"},{"title":"Lab 11:","text":"Slides","tags":"labs","url":"labs/lab11/"},{"title":"Lab 12:","text":"Slides","tags":"labs","url":"labs/lab12/"},{"title":"Lab 13:","text":"Slides","tags":"labs","url":"labs/lab13/"},{"title":"Lab 7:","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS-109A Introduction to Data Science Lab 7: $k$-NN Classification and Imputation Harvard University Fall 2019 Instructors: Pavlos Protopapas, Kevin Rader, Chris Tanner Lab Instructors: Chris Tanner and Eleni Kaxiras. Contributors: Kevin Rader In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } span.sub-q { font-weight: bold; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Learning Goals In this lab, we'll explore classification models to predict the health status of survey respondents and be able to build a classification decision boundary to predict the resultsing unbalanced classes. By the end of this lab, you should: Be familiar with the sklearn implementations of $k$-NN Regression ROC curves and classification metrics Be able to optimize some loss function based on misclassification rates Be able to impute for missing values Be comfortable in the different approaches in handling missingness In [10]: import numpy as np import pandas as pd import matplotlib import matplotlib.pyplot as plt import statsmodels.api as sm from statsmodels.api import OLS import sklearn as sk from sklearn.decomposition import PCA from sklearn.linear_model import LogisticRegression from sklearn.linear_model import LogisticRegressionCV from sklearn.utils import resample from sklearn.model_selection import cross_val_score from sklearn.metrics import accuracy_score # %matplotlib inline import seaborn.apionly as sns Part 1: General Social Survey Data + EDA The dataset contains a subset of data from the General Social Survey (GSS) that is a bi-annual survey of roughly 2000 Americans. We will be using a small subset of the approx 4000 questions they ask. Specifically we'll use: id: respondant's unique ID health: self-reported health level with 4 categories: poor, fair, good, excellent partyid: political party affiliation with categories dem, rep, or other age: age in years sex: male or female sexornt: sexual orientation with categories hetero, gay, or bisexual/other educ: number of years of formal education (capped at 20 years) marital: marital status with categories married, never married, and no longer married race: with categories black, white, and other income: in thousands of dollars Our goal is to predict whether or not someone is in poor health based on the other measures. For this task, we will exercise our normal data science pipeline -- from EDA to modeling and visualization. In particular, we will show the performance of 2 classifiers: Logistic Regression $k$-NN Regression So without further ado... EDA Do the following basic EDA (always good ideas): Determine the dimensions of the data set. Get a glimpse of the data set. Calculate basic summary/descriptive statistics of the variables. We also ask that you do the following: Create a binary called poorhealth . Explore the distribution of the responses, health and poorhealth , Explore what variables may be related to whether or not some is of poor health. In [32]: gssdata = pd . read_csv ( \"../data/gsshealth18.csv\" ) ##### # You code here: EDA # 1. Determine the dimensions of the data set. # 2. Get a glimpse of the data set. # 3. Calculate basic summary/descriptive statistics of the variables. #### gssdata . head () Out[32]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id health partyid age sex sexornt educ marital race income 0 1 good rep 43.0 male bisexual/other 14.0 never married white NaN 1 2 excellent dem 74.0 female hetero 10.0 no longer married white NaN 2 5 excellent rep 71.0 male hetero 18.0 no longer married black NaN 3 6 good dem 67.0 female bisexual/other 16.0 no longer married white NaN 4 7 good dem 59.0 female bisexual/other 13.0 no longer married black 18.75 In [33]: gssdata . isna () . sum () Out[33]: id 0 health 0 partyid 0 age 2 sex 0 sexornt 0 educ 2 marital 2 race 0 income 661 dtype: int64 In [34]: I_test = gssdata [ gssdata [ 'marital' ] . isna ()] In [35]: y_test = I_test [ 'marital' ] I_test = I_test . drop ( columns = [ 'marital' ]) In [36]: I_test Out[36]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id health partyid age sex sexornt educ race income 25 40 good other 50.0 female bisexual/other 12.0 black NaN 1478 2222 fair other 65.0 male bisexual/other 19.0 white NaN In [37]: y_test Out[37]: 25 NaN 1478 NaN Name: marital, dtype: object In [39]: I_train = gssdata . dropna ( subset = [ 'marital' ]) I_train . head () Out[39]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id health partyid age sex sexornt educ marital race income 0 1 good rep 43.0 male bisexual/other 14.0 never married white NaN 1 2 excellent dem 74.0 female hetero 10.0 no longer married white NaN 2 5 excellent rep 71.0 male hetero 18.0 no longer married black NaN 3 6 good dem 67.0 female bisexual/other 16.0 no longer married white NaN 4 7 good dem 59.0 female bisexual/other 13.0 no longer married black 18.75 In [42]: y_train = I_train [ 'marital' ] y_train . head ( 10 ) Out[42]: 0 never married 1 no longer married 2 no longer married 3 no longer married 4 no longer married 5 never married 6 no longer married 7 no longer married 8 married 9 no longer married Name: marital, dtype: object In [40]: I_train . isna () . sum () Out[40]: id 0 health 0 partyid 0 age 2 sex 0 sexornt 0 educ 2 marital 0 race 0 income 659 dtype: int64 In [43]: logit = LogisticRegression ( C = 1000000 ) logit . fit ( I_train , y_train ) print ( logit . score ( I_test , y_test )) logit . coef_ /Users/eleni/anaconda2/envs/bunny/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning. FutureWarning) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) in 1 logit = LogisticRegression ( C = 1000000 ) ----> 2 logit . fit ( I_train , y_train ) 3 print ( logit . score ( I_test , y_test ) ) 4 logit . coef_ ~/anaconda2/envs/bunny/lib/python3.6/site-packages/sklearn/linear_model/logistic.py in fit (self, X, y, sample_weight) 1530 1531 X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\", -> 1532 accept_large_sparse=solver != 'liblinear') 1533 check_classification_targets ( y ) 1534 self . classes_ = np . unique ( y ) ~/anaconda2/envs/bunny/lib/python3.6/site-packages/sklearn/utils/validation.py in check_X_y (X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator) 717 ensure_min_features = ensure_min_features , 718 warn_on_dtype = warn_on_dtype , --> 719 estimator=estimator) 720 if multi_output : 721 y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False, ~/anaconda2/envs/bunny/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array (array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator) 494 try : 495 warnings . simplefilter ( 'error' , ComplexWarning ) --> 496 array = np . asarray ( array , dtype = dtype , order = order ) 497 except ComplexWarning : 498 raise ValueError(\"Complex data not supported\\n\" ~/anaconda2/envs/bunny/lib/python3.6/site-packages/numpy/core/numeric.py in asarray (a, dtype, order) 536 537 \"\"\" --> 538 return array ( a , dtype , copy = False , order = order ) 539 540 ValueError : could not convert string to float: 'white' In [12]: pd . crosstab ( gssdata [ 'health' ], gssdata [ 'sex' ]) Out[12]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sex female male health excellent 198 161 fair 188 167 good 442 329 poor 44 40 In [13]: ##### # You code here: EDA # 4. Create a binary called `poorhealth`. # 5. Explore the distribution of the responses, `health` and `poorhealth`, # 6. Explore what variables may be related to whether or not some is of poor health. #### Question : What classification accuracy could you achieve if you simply predicted poorhealth without a model? What classification accuracy would you get if you were to predict the multi-class health variable? Is accuracy the correct metric? your answer here Data Cleaning - Basic Handling of Missingness Let's begin by fitting an unregularized logistic regression model to predict poor health based on all the other predictors in the model and three $k$-NN models with $k=5,10,20$. First we need to do a small amount of data clean-up. Determine the amount of missingness in each variable. If there is a lot , we will drop the variable from the predictor set (not quite yet). If there is a little, we will impute. Drop any variables with lots of missingnes (in a new data set). Do simple imputations for variables with a little bit of missingness. Create dummies for categorical predictors. In [ ]: ######### # 1. Determine the amount of missingness in each variable. # Use is.na() in combination with .sum() ######## # Your code here In [ ]: ####### # And then build your predictor set # 2. Drop any variables with lots of missingnes (in a new data set). # 3. Do simple imputations for variables with a little bit of missingness. # 4. Create dummies for categorical predictors. ######### X = gssdata [[ 'partyid' , 'age' , 'sex' , 'sexornt' , 'educ' , 'marital' , 'race' , 'income' ]] In [ ]: from IPython.core.display import HTML display ( HTML ( gssdata . to_html ())) In [ ]: #create dummies (lots of ways to do it, two ways will be in the solutions #print(X.shape) Part 2: Fit Basic Models In this section we ask you to: Split the data into 70-30 train-test splits (use the code provided...should have been done before EDA :( ) Fit an unregularize logistic regression model to predict poorhealth from all predictors except income. 2b. If you have time: use 'LogisticRegressionCV' to find a well-tuned L2 regularized model. Fit $k$-NN classification models with $k=1,15,25$ to predict poorhealth from all predictors except income. Report classification accuracy on both train and test set for all models. In [ ]: ####### # Use the following train_test_split code to: # 1. Split the data into 70-30 train-test splits ####### from sklearn.model_selection import train_test_split itrain , itest = train_test_split ( range ( gssdata . shape [ 0 ]), train_size = 0.70 ) from sklearn.neighbors import KNeighborsClassifier KNeighborsClassifier In [ ]: ###### # 2. Fit an unregularize logistic regression model to predict `poorhealth` # from all predictors except income. # 2b. If you have time: use 'LogisticRegressionCV' to find a well-tuned L2 regularized model. # 3. Fit $k$-NN classification models with k=1,15,25 to predict `poorhealth` # from all predictors except income. ###### In [ ]: ###### # 4. Report classification accuracy on both train and test set for all models. ###### Part 3: Evaluate Models via Confusion matrices and ROC Curves In this part we ask that you: Plot the histograms of predicted probabilities for your favorite model from above Create the confusion matrices for (a) the default threshold for classification and (b) a well-chosen threshold for classification to balance errors more equally. Make ROC curves to evaluate a model's overall useability. Use the ROC curves to select a threshold to balance the two types of errors. As a reminder of Confustion Matrices: the samples that are +ive and the classifier predicts as +ive are called True Positives (TP) the samples that are -ive and the classifier predicts (wrongly) as +ive are called False Positives (FP) the samples that are -ive and the classifier predicts as -ive are called True Negatives (TN) the samples that are +ive and the classifier predicts as -ive are called False Negatives (FN) A classifier produces a confusion matrix which looks like this: IMPORTANT NOTE: In sklearn, to obtain the confusion matrix in the form above, always have the observed y first, i.e.: use as confusion_matrix(y_true, y_pred) In [ ]: ##### # 1. Plot the histograms of predicted probabilities on train for your favorite # model from above ##### In [ ]: ##### # 2. Create the confusion matrices for (a) the default threshold for classification and # (b) a well-chosen threshold for classification to balance errors more equally. ##### from sklearn.metrics import confusion_matrix # this function may help to manually make confusion table from a different threshold def t_repredict ( est , t , xtest ): probs = est . predict_proba ( xtest ) p0 = probs [:, 0 ] p1 = probs [:, 1 ] ypred = ( p1 > t ) * 1 return ypred In [ ]: ##### # 3. Make ROC curves to evaluate a model's overall useability. ##### from sklearn.metrics import roc_curve , auc # a function to make 'pretty' ROC curves for this model def make_roc ( name , clf , ytest , xtest , ax = None , labe = 5 , proba = True , skip = 0 ): initial = False if not ax : ax = plt . gca () initial = True if proba : #for stuff like logistic regression fpr , tpr , thresholds = roc_curve ( ytest , clf . predict_proba ( xtest )[:, 1 ]) else : #for stuff like SVM fpr , tpr , thresholds = roc_curve ( ytest , clf . decision_function ( xtest )) roc_auc = auc ( fpr , tpr ) if skip : l = fpr . shape [ 0 ] ax . plot ( fpr [ 0 : l : skip ], tpr [ 0 : l : skip ], '.-' , alpha = 0.3 , label = 'ROC curve for %s (area = %0.2f )' % ( name , roc_auc )) else : ax . plot ( fpr , tpr , '.-' , alpha = 0.3 , label = 'ROC curve for %s (area = %0.2f )' % ( name , roc_auc )) label_kwargs = {} label_kwargs [ 'bbox' ] = dict ( boxstyle = 'round,pad=0.3' , alpha = 0.2 , ) if labe != None : for k in range ( 0 , fpr . shape [ 0 ], labe ): #from https://gist.github.com/podshumok/c1d1c9394335d86255b8 threshold = str ( np . round ( thresholds [ k ], 2 )) ax . annotate ( threshold , ( fpr [ k ], tpr [ k ]), ** label_kwargs ) if initial : ax . plot ([ 0 , 1 ], [ 0 , 1 ], 'k--' ) ax . set_xlim ([ 0.0 , 1.0 ]) ax . set_ylim ([ 0.0 , 1.05 ]) ax . set_xlabel ( 'False Positive Rate' ) ax . set_ylabel ( 'True Positive Rate' ) ax . set_title ( 'ROC' ) ax . legend ( loc = \"lower right\" ) return ax sns . set_context ( \"poster\" ) Use the ROC curves to select a threshold to balance the two types of errors. your answer here Part 4: Imputation In this part we ask that you explore the effects of imputation: Plot the histogram of income . Create a new variable income_imp that imputes the median or mean income for all the missing values and plot the histogram for this new variable. Compare the histograms above. Update your poorhealth prediction model(s) by incorporating income_imp . Compare the accuracy of this new model. And if there is time: Create a new variable income_imp2 that imputes the value via a model. Update your poorhealth prediction model(s) by incorporating income_imp2 . Compare the accuracy of this newest model. In [ ]: ##### # 1. Plot the histogram of `income`. # 2. Create a new variable `income_imp` that imputes the median or # mean income for all the missing values and plot the histogram for this new variable. ##### Compare the histograms above. your answer here In [ ]: ##### # 4. Update your `poorhealth` prediction model(s) by incorporating `income_imp`. # 5. Calculate and compare the accuracy of this new model. # And if there is time: # 6. Create a new variable `income_imp2` that imputes the value via a model. # 7. Update your `poorhealth` prediction model(s) by incorporating `income_imp2`. # 8. Calculate and compare the accuracy of this newest model. ##### 5 and 8. Compare the accuracies. your answer here if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab7/notebook/"},{"title":"Lab 7:","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS-109A Introduction to Data Science Lab 7: $k$-NN Classification and Imputation Harvard University Fall 2019 Instructors: Pavlos Protopapas, Kevin Rader, Chris Tanner Lab Instructors: Chris Tanner and Eleni Kaxiras. Contributors: Kevin Rader In [2]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[2]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } span.sub-q { font-weight: bold; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Learning Goals In this lab, we'll explore classification models to predict the health status of survey respondents and be able to build a classification decision boundary to predict the resultsing unbalanced classes. By the end of this lab, you should: Be familiar with the sklearn implementations of $k$-NN Regression ROC curves and classification metrics Be able to optimize some loss function based on misclassification rates Be able to impute for missing values Be comfortable in the different approaches in handling missingness In [3]: import numpy as np import pandas as pd import matplotlib import matplotlib.pyplot as plt import statsmodels.api as sm from statsmodels.api import OLS import sklearn as sk from sklearn.decomposition import PCA from sklearn.linear_model import LogisticRegression from sklearn.linear_model import LogisticRegressionCV from sklearn.utils import resample from sklearn.model_selection import cross_val_score from sklearn.metrics import accuracy_score # %matplotlib inline import seaborn.apionly as sns //anaconda3/lib/python3.7/_collections_abc.py:841: MatplotlibDeprecationWarning: The examples.directory rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2. In the future, examples will be found relative to the 'datapath' directory. self[key] = other[key] //anaconda3/lib/python3.7/_collections_abc.py:841: MatplotlibDeprecationWarning: The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3. self[key] = other[key] //anaconda3/lib/python3.7/_collections_abc.py:841: MatplotlibDeprecationWarning: The text.latex.unicode rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2. self[key] = other[key] //anaconda3/lib/python3.7/_collections_abc.py:841: MatplotlibDeprecationWarning: The verbose.fileo rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3. self[key] = other[key] //anaconda3/lib/python3.7/_collections_abc.py:841: MatplotlibDeprecationWarning: The verbose.level rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3. self[key] = other[key] //anaconda3/lib/python3.7/site-packages/seaborn/apionly.py:9: UserWarning: As seaborn no longer sets a default style on import, the seaborn.apionly module is deprecated. It will be removed in a future version. warnings.warn(msg, UserWarning) Part 1: General Social Survey Data + EDA The dataset contains a subset of data from the General Social Survey (GSS) that is a bi-annual survey of roughly 2000 Americans. We will be using a small subset of the approx 4000 questions they ask. Specifically we'll use: id: respondant's unique ID health: self-reported health level with 4 categories: poor, fair, good, excellent partyid: political party affiliation with categories dem, rep, or other age: age in years sex: male or female sexornt: sexual orientation with categories hetero, gay, or bisexual/other educ: number of years of formal education (capped at 20 years) marital: marital status with categories married, never married, and no longer married race: with categories black, white, and other income: in thousands of dollars Our goal is to predict whether or not someone is in poor health based on the other measures. For this task, we will exercise our normal data science pipeline -- from EDA to modeling and visualization. In particular, we will show the performance of 2 classifiers: Logistic Regression $k$-NN Regression So without further ado... EDA Do the following basic EDA (always good ideas): Determine the dimensions of the data set. Get a glimpse of the data set. Calculate basic summary/descriptive statistics of the variables. We also ask that you do the following: Create a binary called poorhealth . Explore the distribution of the responses, health and poorhealth , Explore what variables may be related to whether or not some is of poor health. In [4]: gssdata = pd . read_csv ( \"data/gsshealth18.csv\" ) ##### # You code here: EDA # 1. Determine the dimensions of the data set. # 2. Get a glimpse of the data set. #### print ( \"The dimensions of the data set are:\" , gssdata . shape [ 0 ], \"observations and\" , gssdata . shape [ 1 ], \"variables.\" ) gssdata . head () The dimensions of the data set are: 1569 observations and 10 variables. Out[4]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id health partyid age sex sexornt educ marital race income 0 1 good rep 43.0 male bisexual/other 14.0 never married white NaN 1 2 excellent dem 74.0 female hetero 10.0 no longer married white NaN 2 5 excellent rep 71.0 male hetero 18.0 no longer married black NaN 3 6 good dem 67.0 female bisexual/other 16.0 no longer married white NaN 4 7 good dem 59.0 female bisexual/other 13.0 no longer married black 18.75 In [24]: # 3. Calculate basic summary/descriptive statistics of the variables. gssdata . describe () print ( gssdata [ 'health' ] . value_counts ()) print ( gssdata [ 'partyid' ] . value_counts ()) print ( gssdata [ 'sex' ] . value_counts ()) print ( gssdata [ 'sexornt' ] . value_counts ()) print ( gssdata [ 'marital' ] . value_counts ()) print ( gssdata [ 'race' ] . value_counts ()) good 771 excellent 359 fair 355 poor 84 Name: health, dtype: int64 dem 708 rep 514 other 347 Name: partyid, dtype: int64 female 872 male 697 Name: sex, dtype: int64 bisexual/other 907 hetero 640 gay 22 Name: sexornt, dtype: int64 married 655 never married 458 no longer married 454 Name: marital, dtype: int64 white 1137 black 259 other 173 Name: race, dtype: int64 In [25]: ##### # You code here: EDA # 4. Create a binary called `poorhealth`. # 5. Explore the distribution of the responses, `health` and `poorhealth`, # 6. Explore what variables may be related to whether or not some is of poor health. #### gssdata [ 'poorhealth' ] = 1 * ( gssdata [ 'health' ] == 'poor' ) gssdata [ 'poorhealth' ] . mean () Out[25]: 0.05353728489483748 Question : What classification accuracy could you achieve if you simply predicted poorhealth without a model? What classification accuracy would you get if you were to predict the multi-class health variable? Is accuracy the correct metric? Solution : Poor health is a quite rare health status: only 5.35\\% of respondents said they were in poor health. If we predicted all persons to be in better than poo health, our naive classifier would have $1-0.0535 = 0.9465 = 94.65\\%$ accuracy. Acuracy is almost certainly not the ideal metric to use here: we'd be better off looking at false positive and false negative rate instead (it is more important to correctly classify those in poor health than those in better than poor health). Data Cleaning - Basic Handling of Missingness Let's begin by fitting an unregularized logistic regression model to predict poor health based on all the other predictors in the model and three $k$-NN models with $k=5,10,20$. First we need to do a small amount of data clean-up. Determine the amount of missingness in each variable. If there is a lot , we will drop the variable from the predictor set (not quite yet). If there is a little, we will impute. Drop any variables with lots of missingnes (in a new data set). Do simple imputations for variables with a little bit of missingness. Create dummies for categorical predictors. In [26]: ######### # 1. Determine the amount of missingness in each variable. # Use isna() in combination with .sum() ######## # Your code here gssdata . isna () . sum () Out[26]: id 0 health 0 partyid 0 age 2 sex 0 sexornt 0 educ 2 marital 2 race 0 income 661 poorhealth 0 dtype: int64 In [39]: ####### # And then build your predictor set # 2. Drop any variables with lots of missingnes (in a new data set). # 3. Do simple imputations for variables with a little bit of missingness. # 4. Create dummies for categorical predictors. ######### # get the predictors without a ton of missingness # (income was not included since it had so much missingness) X = gssdata [[ 'partyid' , 'age' , 'sex' , 'sexornt' , 'educ' , 'marital' , 'race' ]] #create dummies (lots of ways to do it, two ways will be in the solutions # create dummies 2 different ways X [ 'female' ] = 1 * ( gssdata [ 'sex' ] == \"female\" ) dummies = pd . get_dummies ( X [[ 'marital' , 'race' , 'sexornt' , 'partyid' ]], drop_first = True ) # add the dummies in via the join command. X = X . join ( dummies ) # let's drop the redundat variables no longer needed since we created the dummies X = X . drop ([ 'partyid' , 'sex' , 'sexornt' , 'marital' , 'race' ], axis = 1 ) # now check the 'nulls' X . isna () . sum () //anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy Out[39]: age 2 educ 2 female 0 marital_never married 0 marital_no longer married 0 race_other 0 race_white 0 sexornt_gay 0 sexornt_hetero 0 partyid_other 0 partyid_rep 0 dtype: int64 In [40]: # handle missingness in age and education # missingness in marital was handled with get_dummies # impute the median age X [ 'age' ] = X [ 'age' ] . fillna ( X [ 'age' ] . median ()) # impute the most common education: having a HS degree (13 years) # see histogram for justification X [ 'educ' ] = X [ 'educ' ] . fillna ( 13 ) In [41]: plt . hist ( X [ 'educ' ]); In [39]: # we checked these to see if there were any patterns in the missingness. # Nothing really showed up. print ( gssdata [ 'age' ][ pd . isna ( gssdata [ 'marital' ])]) print ( gssdata [ 'age' ][ pd . isna ( gssdata [ 'educ' ])]) 25 50.0 1478 65.0 Name: age, dtype: float64 529 24.0 1546 75.0 Name: age, dtype: float64 In [42]: # Just to make sure missingness is gone X . isna () . sum () Out[42]: age 0 educ 0 female 0 marital_never married 0 marital_no longer married 0 race_other 0 race_white 0 sexornt_gay 0 sexornt_hetero 0 partyid_other 0 partyid_rep 0 dtype: int64 Part 2: Fit Basic Models In this section we ask you to: Split the data into 70-30 train-test splits (use the code provided...should have been done before EDA :( ) Fit an unregularize logistic regression model to predict poorhealth from all predictors except income. 2b. If you have time: use 'LogisticRegressionCV' to find a well-tuned L2 regularized model. Fit $k$-NN classification models with $k=1,15,25$ to predict poorhealth from all predictors except income. Report classification accuracy on both train and test set for all models. In [44]: ####### # Use the following train_test_split code to: # 1. Split the data into 70-30 train-test splits ####### from sklearn.model_selection import train_test_split itrain , itest = train_test_split ( range ( gssdata . shape [ 0 ]), train_size = 0.70 ) # Note: the train-test split above is for the INDICES for splitting in case we # want to use them again in the future...we can have an identical split X_train = X . loc [ itrain ] X_test = X . loc [ itest ] y_train = gssdata [ 'poorhealth' ][ itrain ] y_test = gssdata [ 'poorhealth' ][ itest ] In [108]: ###### # 2. Fit an unregularize logistic regression model to predict `poorhealth` # from all predictors except income. # 2b. If you have time: use 'LogisticRegressionCV' to find a well-tuned L2 regularized model. # 3. Fit $k$-NN classification models with k=1,15,25 to predict `poorhealth` # from all predictors except income. ###### from sklearn.neighbors import KNeighborsClassifier # unregularized Logistic Regression logit = sk . linear_model . LogisticRegression ( C = 100000 ) logit . fit ( X_train , y_train ) # k-NN for k=1, 15, and 25 knn1 = KNeighborsClassifier ( 1 ) knn1 . fit ( X_train , y_train ) knn15 = KNeighborsClassifier ( 15 ) knn15 . fit ( X_train , y_train ) knn25 = KNeighborsClassifier ( 25 ) knn25 . fit ( X_train , y_train ) logit . predict_proba ( X_train )[:, 1 ], #visualize the predictions via boxplots plt . boxplot ([ logit . predict_proba ( X_train )[:, 1 ], knn1 . predict_proba ( X_train )[:, 1 ], knn15 . predict_proba ( X_train )[:, 1 ], knn25 . predict_proba ( X_train )[:, 1 ]]) plt . legend ([ \"1=logistic\" , \"2=knn1\" , \"3=knn15\" , \"4=knn25\" ]); //anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning. FutureWarning) In [109]: ###### # 4. Report classification accuracy on both train and test set for all models. ###### print ( \"Classification accuracy for logistic were: \\n Train =\" , logit . score ( X_train , y_train ), \", Test =\" , logit . score ( X_test , y_test )) print ( \"Classification accuracy for knn1 were: \\n Train =\" , knn1 . score ( X_train , y_train ), \", Test =\" , knn1 . score ( X_test , y_test )) print ( \"Classification accuracy for knn15 were: \\n Train =\" , knn15 . score ( X_train , y_train ), \", Test =\" , knn15 . score ( X_test , y_test )) print ( \"Classification accuracy for knn25 were: \\n Train =\" , knn25 . score ( X_train , y_train ), \", Test =\" , knn25 . score ( X_test , y_test )) # Note the severe overfitting of knn1, while the others are identical! Classification accuracy for logistic were: Train = 0.9462659380692168 , Test = 0.9469214437367304 Classification accuracy for knn1 were: Train = 1.0 , Test = 0.9193205944798302 Classification accuracy for knn15 were: Train = 0.9462659380692168 , Test = 0.9469214437367304 Classification accuracy for knn25 were: Train = 0.9462659380692168 , Test = 0.9469214437367304 Part 3: Evaluate Models via Confusion matrices and ROC Curves In this part we ask that you: Plot the histograms of predicted probabilities for your favorite model from above Create the confusion matrices for (a) the default threshold for classification and (b) a well-chosen threshold for classification to balance errors more equally. Make ROC curves to evaluate a model's overall useability. Use the ROC curves to select a threshold to balance the two types of errors. As a reminder of Confustion Matrices: the samples that are +ive and the classifier predicts as +ive are called True Positives (TP) the samples that are -ive and the classifier predicts (wrongly) as +ive are called False Positives (FP) the samples that are -ive and the classifier predicts as -ive are called True Negatives (TN) the samples that are +ive and the classifier predicts as -ive are called False Negatives (FN) A classifier produces a confusion matrix which looks like this: IMPORTANT NOTE: In sklearn, to obtain the confusion matrix in the form above, always have the observed y first, i.e.: use as confusion_matrix(y_true, y_pred) In [110]: ##### # 1. Plot the histograms of predicted probabilities on test for your favorite # model from above ##### # We plot them for the logistic and knn15 plt . hist ( knn15 . predict_proba ( X_test )[:, 1 ]) plt . hist ( logit . predict_proba ( X_test )[:, 1 ], alpha = 0.7 ); # Note this illustrates the fact that neither model predicted proabilities above 0.5 # and thus all prediced classification were 0 by default.. It also shows that knn15 # predictions are in increments of 1/15, while the logistic has predicted probabilties # in a more 'continuous' like range of values. In [111]: ##### # 2. Create the confusion matrices for (a) the default threshold for classification and # (b) a well-chosen threshold for classification to balance errors more equally. ##### from sklearn.metrics import confusion_matrix # this function may help to manually make confusion table from a different threshold def t_repredict ( est , t , xtest ): probs = est . predict_proba ( xtest ) p0 = probs [:, 0 ] p1 = probs [:, 1 ] ypred = ( p1 > t ) * 1 return ypred # Using the logistic model throughout: # Re-calculating the default confusion matrix print ( confusion_matrix ( y_test , t_repredict ( knn15 , 0.5 , X_test ))) #And then looking at smaller threshold values: 0.32 and 0.06 print ( confusion_matrix ( y_test , t_repredict ( knn15 , 0.32 , X_test ))) print ( confusion_matrix ( y_test , t_repredict ( knn15 ), 0.06 , X_test ))) File \" \" , line 23 print(confusion_matrix(y_test,t_repredict(knn15),0.06,X_test))) &#94; SyntaxError : invalid syntax In [118]: ##### # 3. Make ROC curves to evaluate a model's overall useability. ##### from sklearn.metrics import roc_curve , auc # a function to make 'pretty' ROC curves for this model def make_roc ( name , clf , ytest , xtest , ax = None , labe = 5 , proba = True , skip = 0 ): initial = False if not ax : ax = plt . gca () initial = True if proba : #for stuff like logistic regression fpr , tpr , thresholds = roc_curve ( ytest , clf . predict_proba ( xtest )[:, 1 ]) else : #for stuff like SVM fpr , tpr , thresholds = roc_curve ( ytest , clf . decision_function ( xtest )) roc_auc = auc ( fpr , tpr ) if skip : l = fpr . shape [ 0 ] ax . plot ( fpr [ 0 : l : skip ], tpr [ 0 : l : skip ], '.-' , alpha = 0.3 , label = 'ROC curve for %s (area = %0.2f )' % ( name , roc_auc )) else : ax . plot ( fpr , tpr , '.-' , alpha = 0.3 , label = 'ROC curve for %s (area = %0.2f )' % ( name , roc_auc )) label_kwargs = {} label_kwargs [ 'bbox' ] = dict ( boxstyle = 'round,pad=0.3' , alpha = 0.2 , ) if labe != None : for k in range ( 0 , fpr . shape [ 0 ], labe ): #from https://gist.github.com/podshumok/c1d1c9394335d86255b8 threshold = str ( np . round ( thresholds [ k ], 2 )) ax . annotate ( threshold , ( fpr [ k ], tpr [ k ]), ** label_kwargs ) if initial : ax . plot ([ 0 , 1 ], [ 0 , 1 ], 'k--' ) ax . set_xlim ([ 0.0 , 1.0 ]) ax . set_ylim ([ 0.0 , 1.05 ]) ax . set_xlabel ( 'False Positive Rate' ) ax . set_ylabel ( 'True Positive Rate' ) ax . set_title ( 'ROC' ) ax . legend ( loc = \"lower right\" ) return ax sns . set_context ( \"poster\" ) make_roc ( \"Logistic\" , logit , y_test , X_test , ax = None , labe = 20 , proba = True , skip = 1 ); Question Use the ROC curves to select a threshold to balance the two types of errors. Answer It looks like based on the logistic model, a threshold of somwhere around 0.04 will give us a very high true positive rate (80\\% or so) before taking on \"too high\" of a false positive rate (just a tad over 50\\%). Part 4: Imputation In this part we ask that you explore the effects of imputation: Plot the histogram of income . Create a new variable income_imp that imputes the median or mean income for all the missing values and plot the histogram for this new variable. Compare the histograms above. Update your poorhealth prediction model(s) by incorporating income_imp . Compare the accuracy of this new model. And if there is time: Create a new variable income_imp2 that imputes the value via a model. Update your poorhealth prediction model(s) by incorporating income_imp2 . Compare the accuracy of this newest model. In [96]: ##### # 1. Plot the histogram of `income`. # 2. Create a new variable `income_imp` that imputes the median or # mean income for all the missing values and plot the histogram for this new variable. ##### # First create 'income_imp', and then add it into the predictor set income_imp = gssdata [ 'income' ] . fillna ( gssdata [ 'income' ] . median ()) X [ 'income_imp' ] = income_imp # plot the original and the version with imputations plt . hist ( gssdata [ 'income' ]) plt . hist ( X , alpha = 0.5 ); Question: Compare the histograms above. Solution: There is now a spike at the median compared to what was there before. They distributions are not all that similar in shape or spread (but center is very similar). In [173]: ##### # 4. Update your `poorhealth` prediction model(s) by incorporating `income_imp`. # 5. Calculate and compare the accuracy of this new model. ##### # re-use indices for splitting since now we added the imputed 'income' variable # Note: the response is unaffected so does not need to be redefined. X_train = X . loc [ itrain ] X_test = X . loc [ itest ] logit_imp1 = sk . linear_model . LogisticRegression ( C = 100000 ) logit_imp1 . fit ( X_train , y_train ) knn15_imp1 = KNeighborsClassifier ( 15 ) knn15_imp1 . fit ( X_train , y_train ) print ( confusion_matrix ( y_test , t_repredict ( logit , 0.07 , X_test ))) print ( confusion_matrix ( y_test , t_repredict ( logit_imp1 , 0.07 , X_test ))) X_train . head () [[316 130] [ 14 11]] [[316 130] [ 14 11]] //anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning. FutureWarning) Out[173]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } age educ female marital_never married marital_no longer married race_other race_white sexornt_gay sexornt_hetero partyid_other partyid_rep income_imp 69 42.0 14.0 1 0 0 0 1 0 1 1 0 37.50 1082 32.0 15.0 1 1 0 0 1 0 0 0 0 21.25 1143 22.0 14.0 0 1 0 0 1 0 0 0 0 37.50 871 24.0 12.0 0 0 0 0 1 0 1 0 1 67.50 380 40.0 12.0 1 0 1 0 0 0 0 0 0 3.50 Question: Compare the accuracies. Answer: Nothing has improved. The accuracies are identical for both the logistic and knn models (looking at varios different thresholds. In [170]: ##### # And if there is time: # 6. Create a new variable `income_imp2` that imputes the value via a model. # 7. Update your `poorhealth` prediction model(s) by incorporating `income_imp2`. # 8. Calculate and compare the accuracy of this newest model. ##### # the y_imp is observed incomes in train for building an imputation model to # impute values on training and test, and the X_imp is everything else in train # (we could use the true response health or poorhealth, but we decided not to here). income_train = gssdata [ 'income' ][ itrain ] # all the missing observations' predictors miss_index = gssdata [ 'income' ][ gssdata [ 'income' ] . isna ()] . index X_miss = X . loc [ gssdata [ 'income' ] . isna (),:] X_miss = X_miss . drop ( 'income_imp' , axis = 1 ) # all the available observed incomes (and predictors) within train to be used to # build a model to predict income y_imp = income_train . dropna () X_imp = X_train . drop ( 'income_imp' , axis = 1 ) . loc [ itrain ] X_imp = X_imp . loc [ income_train . isna () == False ,:] # fit the model lm = sk . linear_model . LinearRegression () lm . fit ( X_imp , y_imp ) # do the predictions without noise, and turn it into a series for imputation y_miss = lm . predict ( X_miss ) y_miss_series = pd . Series ( data = y_miss , index = miss_index ) # create the imputed income variable for all observations income_imp2 = gssdata [ 'income' ] . fillna ( y_miss_series ) # add income_imp into the train and test sets properly X_train [ 'income_imp' ] = income_imp2 [ itrain ] X_test [ 'income_imp' ] = income_imp2 [ itest ] # go back to the primary classifciatoin modeling... logit_imp2 = sk . linear_model . LogisticRegression ( C = 100000 ) logit_imp2 . fit ( X_train , y_train ) knn15_imp2 = KNeighborsClassifier ( 15 ) knn15_imp2 . fit ( X_train , y_train ) # quick peak at predictions to see if anything has changed print ( confusion_matrix ( y_test , t_repredict ( logit , 0.07 , X_test ))) print ( confusion_matrix ( y_test , t_repredict ( logit_imp2 , 0.07 , X_test ))) [[330 116] [ 15 10]] [[322 124] [ 15 10]] //anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning. FutureWarning) In [155]: X_imp . head () Out[155]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } age educ female marital_never married marital_no longer married race_other race_white sexornt_gay sexornt_hetero partyid_other partyid_rep 1082 32.0 15.0 1 1 0 0 1 0 0 0 0 871 24.0 12.0 0 0 0 0 1 0 1 0 1 380 40.0 12.0 1 0 1 0 0 0 0 0 0 648 43.0 16.0 1 0 0 0 1 0 0 0 0 1264 61.0 10.0 1 0 1 0 1 0 1 1 0 In [171]: ###### # Now to do imputation with uncertainty: # we can use the same imputation model from the previous part ###### # first add the standard y-hats just like before y_miss = lm . predict ( X_miss ) # we need to estimate the residual variance (MSE), sigma2_hat, from the observed incomes # that were used to train the model y_hat = lm . predict ( X_imp ) sigma2_hat = sk . metrics . mean_squared_error ( y_imp , y_hat ) # sample a residual from the assumed normal distribution e_miss = np . random . normal ( loc = 0 , scale = np . sqrt ( sigma2_hat ), size = y_miss . shape [ 0 ]) # create the income measurement with uncertainty to be imputed y_miss_series = pd . Series ( data = y_miss + e_miss , index = miss_index ) # imputed them properly into where they belong. income_imp3 = gssdata [ 'income' ] . fillna ( y_miss_series ) # add income_imp into the train and test sets properly X_train [ 'income_imp' ] = income_imp3 [ itrain ] X_test [ 'income_imp' ] = income_imp3 [ itest ] # go back to the primary classifciatoin modeling... logit_imp3 = sk . linear_model . LogisticRegression ( C = 100000 ) logit_imp3 . fit ( X_train , y_train ) knn15_imp3 = KNeighborsClassifier ( 15 ) knn15_imp3 . fit ( X_train , y_train ) print ( confusion_matrix ( y_test , t_repredict ( logit , 0.07 , X_test ))) print ( confusion_matrix ( y_test , t_repredict ( logit_imp3 , 0.07 , X_test ))) [[319 127] [ 15 10]] [[324 122] [ 14 11]] //anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning. FutureWarning) In [169]: # Let's use AUC for evaluations fpr , tpr , thresholds = roc_curve ( y_test , logit . predict_proba ( X_test )[:, 1 ]) print ( \"AUC for logistic model when income was dropped: \\n \" , auc ( fpr , tpr )) fpr , tpr , thresholds = roc_curve ( y_test , logit_imp1 . predict_proba ( X_test )[:, 1 ]) print ( \"AUC for logistic model when imputations were done with median imputation: \\n \" , auc ( fpr , tpr )) fpr , tpr , thresholds = roc_curve ( y_test , logit_imp2 . predict_proba ( X_test )[:, 1 ]) print ( \"AUC for logistic model when imputation were done via linear regression: \\n \" , auc ( fpr , tpr )) fpr , tpr , thresholds = roc_curve ( y_test , logit_imp3 . predict_proba ( X_test )[:, 1 ]) print ( \"AUC for logistic model when imputation were done via linear regression with uncertainty: \\n \" , auc ( fpr , tpr )) AUC for logistic model when income was dropped: 0.6481614349775785 AUC for logistic model when imputations were done with median imputation: 0.6481614349775785 AUC for logistic model when imputation were done via linear regression: 0.6476233183856502 AUC for logistic model when imputation were done via linear regression with uncertainty: 0.6590134529147982 Question: Compare the accuracies. Answer: Things have improved! Using the uncertainty in the imputations has slightly improved the AUC for the classification model. But this is ONLY slightly! if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab7/notebook-solutions/"},{"title":"Lab 8:","text":"Slides","tags":"labs","url":"labs/lab8/"},{"title":"Lab 9:","text":"Slides","tags":"labs","url":"labs/lab9/"},{"title":"Lecture 13:","text":"Slides","tags":"lectures","url":"lectures/lecture13/"},{"title":"Lecture 14:","text":"Slides","tags":"lectures","url":"lectures/lecture14/"},{"title":"Lecture 15:","text":"Slides","tags":"lectures","url":"lectures/lecture15/"},{"title":"Lecture 16:","text":"Slides","tags":"lectures","url":"lectures/lecture16/"},{"title":"Lecture 17:","text":"Slides","tags":"lectures","url":"lectures/lecture17/"},{"title":"Lecture 18:","text":"Slides","tags":"lectures","url":"lectures/lecture18/"},{"title":"Lecture 19:","text":"Slides","tags":"lectures","url":"lectures/lecture19/"},{"title":"Lecture 20:","text":"Slides","tags":"lectures","url":"lectures/lecture20/"},{"title":"Lecture 21:","text":"Slides","tags":"lectures","url":"lectures/lecture21/"},{"title":"Lecture 22:","text":"Slides","tags":"lectures","url":"lectures/lecture22/"},{"title":"Lecture 23:","text":"Slides","tags":"lectures","url":"lectures/lecture23/"},{"title":"Lecture 24:","text":"Slides","tags":"lectures","url":"lectures/lecture24/"},{"title":"Lab 5: Exploratory Data Analysis, seaborn, more Plotting","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109A Introduction to Data Science Lab 5: Exploratory Data Analysis, seaborn , more Plotting Harvard University Fall 2019 Instructors: Pavlos Protopapas, Kevin Rader, and Chris Tanner Material Preparation: Eleni Kaxiras. In [1]: #RUN THIS CELL import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } span.sub-q { font-weight: bold; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } In [2]: # import the necessary libraries % matplotlib inline import numpy as np import scipy as sp import matplotlib as mpl import matplotlib.cm as cm import matplotlib.pyplot as plt import pandas as pd import time pd . set_option ( 'display.width' , 500 ) pd . set_option ( 'display.max_columns' , 200 ) pd . set_option ( 'display.notebook_repr_html' , True ) import seaborn as sns from sklearn.linear_model import LinearRegression from sklearn.model_selection import train_test_split from sklearn.metrics import mean_squared_error import warnings warnings . filterwarnings ( 'ignore' ) % config InlineBackend.figure_format ='retina' In [3]: %% javascript IPython . OutputArea . auto_scroll_threshold = 9999 ; var element = $('#e6b92290-71e2-46fe-a20d-dce751b84d74'); IPython.OutputArea.auto_scroll_threshold = 9999; Learning Goals By the end of this lab, you should be able to: know how to implement the different types of plots such as histograms, boxplots, etc, that were mentioned in class. have seaborn as well as matplotlib in your plotting toolbox. This lab corresponds to lecture 6 up to 9 and maps to homework 3. Table of Contents 1 - Visualization Inspiration 2 - Intro to seaborn plotting 3 - Different types of plots (histograms, boxplots, etc) 4 - Excercise: EDA on Medical Data 1 - Visualization Inspiration source: nytimes.org Notice that in \"Summers Are Getting Hotter,\" above, the histogram has intervals for global summer temperatures on the x-axis, designated from extremely cold to extremely hot, and their frequency on the y-axis. That was an infographic intended for the general public. In contrast, take a look at the plots below of the same data published at a scientific journal . They look quite different, don't they? James Hansen, Makiko Sato, and Reto Ruedy , Perception of climate change. PNAS 2 - Implementing Various Types of Plots using matplotlib and seaborn . Before you start coding your visualization, you need to decide what type of vizualization to use. A box plot, a histogram, a scatter plot, or something else? That will depend on the purpose of the plot (is it for performing an inspection on your data (EDA, or for showing your results/conclusions to people) and the number variables that you want to plot. You have a lot of tools for plotting in Python. The basic one, of course, is matplotlib and there are other libraries that are built on top of it, such as seaborn , bokeh , or altair . In this class we will continue using matplotlib and also look into seaborn . Those two libraries are the ones you should be using for homework. Introduction to seaborn Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics. The library provides a database of useful datasets for educational purposes that can be loaded by typing: seaborn . load_dataset ( name , cache = True , data_home = None , ** kws ) For information on what these datasets are : https://github.com/mwaskom/seaborn-data The plotting functions in seaborn can be decided in two categories 'axes-level' functions, such as regplot , boxplot , kdeplot , scatterplot , distplot which can connect with the matplotlib Axes object and its parameters. You can use that object as you would in matplotlib : f , ( ax1 , ax2 ) = plt . subplots ( 2 ) sns . regplot ( x , y , ax = ax1 ) sns . kdeplot ( x , ax = ax2 ) ax1 = sns . distplot ( x , kde = False , bins = 20 ) 'figure-level' functions, such as lmplot , factorplot , jointplot , relplot , pairplot . In this case, seaborn organizes the resulting plot which may include several Axes in a meaningful way. That means that the functions need to have total control over the figure, so it isn't possible to plot, say, an lmplot onto one that already exists. Calling the function always initializes a figure and sets it up for the specific plot it's drawing. These functions return an object of the type FacetGrid with its own methods for operating on the resulting plot. To set the parameters for figure-level functions: sns . set_context ( \"notebook\" , font_scale = 1 , rc = { \"lines.linewidth\" : 2.5 }) The Titanic dataset The titanic.csv file contains data for 887 passengers on the Titanic. Each row represents one person. The columns describe different attributes about the person including whether they survived, their age, their on-board class, their sex, and the fare they paid. In [4]: titanic = sns . load_dataset ( 'titanic' ); titanic . info (); RangeIndex: 891 entries, 0 to 890 Data columns (total 15 columns): survived 891 non-null int64 pclass 891 non-null int64 sex 891 non-null object age 714 non-null float64 sibsp 891 non-null int64 parch 891 non-null int64 fare 891 non-null float64 embarked 889 non-null object class 891 non-null category who 891 non-null object adult_male 891 non-null bool deck 203 non-null category embark_town 889 non-null object alive 891 non-null object alone 891 non-null bool dtypes: bool(2), category(2), float64(2), int64(4), object(5) memory usage: 80.6+ KB In [5]: titanic . columns Out[5]: Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town', 'alive', 'alone'], dtype='object') Exercise: Drop the following features: 'embarked', 'who', 'adult_male', 'embark_town', 'alive', 'alone' In [6]: # your code here mary = [ 'embarked' , 'who' , 'adult_male' , 'embark_town' , 'alive' , 'alone' ] titanic = titanic . drop ( columns = mary ) titanic Out[6]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } survived pclass sex age sibsp parch fare class deck 0 0 3 male 22.0 1 0 7.2500 Third NaN 1 1 1 female 38.0 1 0 71.2833 First C 2 1 3 female 26.0 0 0 7.9250 Third NaN 3 1 1 female 35.0 1 0 53.1000 First C 4 0 3 male 35.0 0 0 8.0500 Third NaN ... ... ... ... ... ... ... ... ... ... 886 0 2 male 27.0 0 0 13.0000 Second NaN 887 1 1 female 19.0 0 0 30.0000 First B 888 0 3 female NaN 1 2 23.4500 Third NaN 889 1 1 male 26.0 0 0 30.0000 First C 890 0 3 male 32.0 0 0 7.7500 Third NaN 891 rows × 9 columns Exercise: Find for how many passengeres we do not have their deck information. In [7]: # your code here missing_decks = len ( titanic [( pd . isna ( titanic [ 'deck' ]) == True )]) missing_decks Out[7]: 688 Histograms Plotting one variable's distribution (categorical and continous) The most convenient way to take a quick look at a univariate distribution in seaborn is the distplot() function. By default, this will draw a histogram and fit a kernel density estimate (KDE). A histogram displays a quantitative (numerical) distribution by showing the number (or percentage) of the data values that fall in specified intervals. The intervals are on the x-axis and the number of values falling in each interval, shown as either a number or percentage, are represented by bars drawn above the corresponding intervals. In [9]: # What was the age distribution among passengers in the Titanic? import seaborn as sns sns . set ( color_codes = True ) f , ax = plt . subplots ( 1 , 1 , figsize = ( 8 , 3 )); ax = sns . distplot ( titanic . age , kde = False , bins = 20 ) # bug #ax = sns.distplot(titanic.age, kde=False, bins=20).set(xlim=(0, 90)); ax . set ( xlim = ( 0 , 90 )); ax . set_ylabel ( 'counts' ); In [10]: f , ax = plt . subplots ( 1 , 1 , figsize = ( 8 , 3 )) ax . hist ( titanic . age , bins = 20 ); ax . set_xlim ( 0 , 90 ); Exercise (pandas trick): Count all the infants on board (age less than 3) and all the children ages 3-10. In [11]: # your code here infants = len ( titanic [( titanic . age < 3 )]) children = len ( titanic [( titanic . age >= 3 ) & ( titanic . age < 10 )]) print ( f 'There were {infants} infants and {children} children on board the Titanic' ) There were 24 infants and 38 children on board the Titanic Pandas trick: We want to creat virtual \"bins\" for readability and replace ranges of values with categories. We will do this in an ad hoc way, it can be done better . For example in the previous plot we could set: (age<3) = 'infants' , (3 , (18 See matplotlib colors here. In [12]: # set the colors cmap = plt . get_cmap ( 'Pastel1' ) young = cmap ( 0.5 ) middle = cmap ( 0.2 ) older = cmap ( 0.8 ) # get the object we will change - patches is an array with len: num of bins fig , ax = plt . subplots () y_values , bins , patches = ax . hist ( titanic . age , 10 ) [ patches [ i ] . set_facecolor ( young ) for i in range ( 0 , 1 )] # bin 0 [ patches [ i ] . set_facecolor ( middle ) for i in range ( 1 , 3 )] # bins 1 and 2 [ patches [ i ] . set_facecolor ( older ) for i in range ( 3 , 10 )] # 7 remaining bins ax . grid ( True ) fig . show () Kernel Density Estimation The kernel density estimate can be a useful tool for plotting the shape of a distribution. The bandwidth (bw) parameter of the KDE controls how tightly the estimation is fit to the data, much like the bin size in a histogram. It corresponds to the width of the kernels we plotted above. The default behavior tries to guess a good value using a common reference rule, but it may be helpful to try larger or smaller values. In [13]: sns . kdeplot ( titanic . age , bw = 0.6 , label = \"bw: 0.6\" , shade = True , color = \"r\" ); sns . kdeplot ( titanic . age , bw = 2 , label = \"bw: 2\" , shade = True ); Exercise: Plot the distribution of fare paid by passengers In [14]: # your code here sns . kdeplot ( titanic . fare , bw = 0.5 , label = \"bw: 0.5\" , shade = True ); You can mix elements of matplotlib such as Axes with seaborn elements for a best use of both worlds. In [15]: import seaborn as sns sns . set ( color_codes = True ) x1 = np . random . normal ( size = 100 ) x2 = np . random . normal ( size = 100 ) fig , ax = plt . subplots ( 1 , 2 , figsize = ( 15 , 5 )) # seaborn goes in first subplot sns . set ( font_scale = 0.5 ) sns . distplot ( x1 , kde = False , bins = 15 , ax = ax [ 0 ]); sns . distplot ( x2 , kde = False , bins = 15 , ax = ax [ 0 ]); ax [ 0 ] . set_title ( 'seaborn Graph Here' , fontsize = 14 ) ax [ 0 ] . set_xlabel ( r '$x$' , fontsize = 14 ) ax [ 0 ] . set_ylabel ( r '$count$' , fontsize = 14 ) # matplotlib goes in second subplot ax [ 1 ] . hist ( x1 , alpha = 0.2 , bins = 15 , label = r '$x1$' ); ax [ 1 ] . hist ( x2 , alpha = 0.5 , bins = 15 , label = r '$x2$' ); ax [ 1 ] . set_xlabel ( r '$x$' , fontsize = 14 ) ax [ 1 ] . set_ylabel ( r '$count$' , fontsize = 14 ) ax [ 1 ] . set_title ( 'matplotlib Graph Here' , fontsize = 14 ) ax [ 1 ] . legend ( loc = 'best' , fontsize = 14 ); Introduding the heart disease dataset. More on this in the in-class exercise at the end of the notebook. In [16]: columns = [ \"age\" , \"sex\" , \"cp\" , \"restbp\" , \"chol\" , \"fbs\" , \"restecg\" , \"thalach\" , \"exang\" , \"oldpeak\" , \"slope\" , \"ca\" , \"thal\" , \"num\" ] heart_df = pd . read_csv ( '../data/heart_disease.csv' , header = None , names = columns ) heart_df . head () Out[16]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } age sex cp restbp chol fbs restecg thalach exang oldpeak slope ca thal num 0 63.0 1.0 1.0 145.0 233.0 1.0 2.0 150.0 0.0 2.3 3.0 0.0 6.0 0.0 1 67.0 1.0 4.0 160.0 286.0 0.0 2.0 108.0 1.0 1.5 2.0 3.0 3.0 2.0 2 67.0 1.0 4.0 120.0 229.0 0.0 2.0 129.0 1.0 2.6 2.0 2.0 7.0 1.0 3 37.0 1.0 3.0 130.0 250.0 0.0 0.0 187.0 0.0 3.5 3.0 0.0 3.0 0.0 4 41.0 0.0 2.0 130.0 204.0 0.0 2.0 172.0 0.0 1.4 1.0 0.0 3.0 0.0 Boxplots One variable. In [17]: # seaborn ax = sns . boxplot ( x = 'age' , data = titanic ) #ax = sns.boxplot(x=titanic['age']) # another way to write this ax . set_ylabel ( None ); ax . set_xlabel ( 'age' , fontsize = 14 ); ax . set_title ( 'Distribution of age in the Titanic' , fontsize = 14 ); Two variables Exercise: Did more young people or older ones get first class tickets on the Titanic? In [18]: # your code here # two variables seaborn ax = sns . boxplot ( x = \"class\" , y = \"age\" , data = titanic ) In [19]: # two variable boxplot in pandas titanic . boxplot ( 'age' , by = 'class' ) Out[19]: Scatterplots Plotting the distribution of two variables Also called a bivariate distribution where each observation is shown with a point with x and y values. You can draw a scatterplot with the matplotlib plt.scatter function, or the seaborn jointplot() function: In [20]: f , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 5 )) sns . scatterplot ( x = \"fare\" , y = \"age\" , data = titanic , ax = ax ); In [21]: sns . jointplot ( \"fare\" , \"age\" , data = titanic , s = 40 , edgecolor = \"w\" , linewidth = 1 ) Out[21]: You may control the seaborn Figure aesthetics . In [22]: # matplotlib fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . scatter ( heart_df [ 'age' ], heart_df [ 'restbp' ], alpha = 0.8 ); ax . set_xlabel ( r '$Age (yrs)$' , fontsize = 15 ); ax . set_ylabel ( r 'Resting Blood Pressure (mmHg)' , fontsize = 15 ); ax . set_title ( 'Age vs. Resting Blood Pressure' , fontsize = 14 ) plt . show (); Plotting the distribution of three variables In [23]: f , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 5 )) sns . scatterplot ( x = \"fare\" , y = \"age\" , hue = \"survived\" , data = titanic , ax = ax ); Plotting the distribution of four variables (going too far?) Exercise: Plot the distribution of fare paid by passengers according to age, survival and sex. Use size= for the fourth variable In [24]: # your code here f , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 5 )) sns . scatterplot ( x = \"fare\" , y = \"age\" , hue = \"survived\" , size = \"sex\" , data = titanic , ax = ax ); Pairplots In [25]: titanic . columns Out[25]: Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'class', 'deck'], dtype='object') In [26]: to_plot = [ 'age' , 'fare' , 'survived' , 'deck' ] In [34]: df_to_plot = titanic . loc [:, to_plot ] sns . pairplot ( df_to_plot ); In [28]: from pandas.plotting import scatter_matrix scatter_matrix ( df_to_plot , alpha = 0.8 , figsize = ( 10 , 10 ), diagonal = 'kde' ); Plotting Categorical Variables In [37]: titanic = sns . load_dataset ( 'titanic' ) f , ax = plt . subplots ( figsize = ( 7 , 3 )); ax = sns . countplot ( y = \"deck\" , data = titanic , color = \"c\" ); ax . set_title ( 'Titanic' ); In [38]: ax = sns . countplot ( x = \"class\" , data = titanic ) ax . set_title ( 'Titanic' ); In [39]: fig , ax = plt . subplots ( figsize = ( 10 , 6 )) # Create figure object sns . set_context ( \"notebook\" , font_scale = 1 , rc = { \"lines.linewidth\" : 2.5 }) ax = sns . countplot ( x = \"deck\" , data = titanic ) In [40]: sns . set ( style = \"ticks\" , palette = \"muted\" ) sns . relplot ( x = \"age\" , y = \"deck\" , col = \"class\" , data = titanic ); In [41]: sns . set_context ( \"notebook\" , font_scale = 1.5 , rc = { \"lines.linewidth\" : 2.5 }) sns . pairplot ( data = titanic , hue = \"deck\" ); Introduction to pandas plotting. There is plotting functionality built in pandas . Look for it in the pandas \"encyclopedia\", a mere 2883-page pdf from the creator Wes McKinney: pandas documentation (pdf) Example: The value_counts() Series method and top-level function computes a histogram of a 1D array of values. It can also be used as a function on regular arrays. Reminder: DataFrame: \"index\" (axis=0, default), \"columns\" (axis=1) Line Graph Good for time dependency or when a variable evolves In [42]: df = pd . DataFrame ( np . random . randn ( 1000 , 4 ), columns = [ 'A' , 'B' , 'C' , 'D' ]) df . head () Out[42]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 0 -0.072986 0.064586 0.076005 1.768125 1 -1.007168 0.091050 -1.019906 0.741020 2 -0.418693 -1.280488 0.467859 -1.031090 3 -1.178062 -0.718033 0.317143 -1.531387 4 0.297648 -0.211252 0.718495 0.370736 In [43]: # cumulative sum adds column values as it goes df = df . cumsum () df . head () Out[43]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 0 -0.072986 0.064586 0.076005 1.768125 1 -1.080154 0.155636 -0.943901 2.509145 2 -1.498847 -1.124852 -0.476042 1.478055 3 -2.676909 -1.842885 -0.158899 -0.053332 4 -2.379262 -2.054137 0.559596 0.317404 In [44]: plt . figure (); df . plot (); plt . legend ( loc = 'best' ); In [45]: ts = pd . Series ( np . random . randn ( 1000 ), index = pd . date_range ( '1/1/2000' , periods = 1000 )) df = pd . DataFrame ( np . random . randn ( 1000 , 4 ), index = ts . index , columns = list ( 'ABCD' )) df = df . cumsum () plt . figure (); df . plot (); Plotting methods allow for a handful of plot styles other than the default line plot. These methods can be provided as the kind keyword argument to plot(), and include: ‘bar' or ‘barh' for bar plots ‘hist' for histogram ‘box' for boxplot ‘kde' or ‘density' for density plots ‘area' for area plots ‘scatter' for scatter plots ‘hexbin' for hexagonal bin plots ‘pie' for pie plots In addition to these kind s, there are the DataFrame.hist() , and DataFrame.boxplot() methods, which use a separate interface. scatter_matrix in pandas.plotting takes a Series or DataFrame as an argument. Bar Plots In [46]: plt . figure (); df . iloc [ 0 ] . plot ( kind = 'bar' ); In [47]: df2 = pd . DataFrame ( np . random . rand ( 10 , 4 ), columns = [ 'a' , 'b' , 'c' , 'd' ]) df2 Out[47]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d 0 0.036437 0.028772 0.636406 0.252079 1 0.550359 0.806193 0.776958 0.408668 2 0.212565 0.949430 0.236970 0.336636 3 0.231369 0.899283 0.925506 0.750473 4 0.960434 0.217803 0.220513 0.541103 5 0.510726 0.459889 0.054106 0.230044 6 0.887885 0.284679 0.520790 0.455553 7 0.432802 0.437612 0.999108 0.604186 8 0.251041 0.253487 0.634895 0.679853 9 0.379598 0.809397 0.546982 0.347001 In [48]: df2 . plot . bar (); In [49]: # horizontal bar plot df2 . plot . barh ( stacked = False ); Histograms In [50]: df4 = pd . DataFrame ({ 'a' : np . random . randn ( 1000 ) + 1 , 'b' : np . random . randn ( 1000 ), 'c' : np . random . randn ( 1000 ) - 1 }, columns = [ 'a' , 'b' , 'c' ]) plt . figure (); df4 . plot . hist ( alpha = 0.5 , stacked = False , bins = 60 ); Boxplots In [51]: color = { 'boxes' : 'DarkGreen' , 'whiskers' : 'DarkOrange' , 'medians' : 'DarkBlue' , 'caps' : 'Gray' } df = pd . DataFrame ( np . random . rand ( 10 , 5 ), columns = [ 'A' , 'B' , 'C' , 'D' , 'E' ]) df . plot . box ( color = color ); Area plots You can create area plots with Series.plot.area() and DataFrame.plot.area() . Area plots are stacked by default. To produce stacked area plot, each column must be either all positive or all negative values. In [52]: df = pd . DataFrame ( np . random . rand ( 10 , 4 ), columns = [ 'a' , 'b' , 'c' , 'd' ]) df . plot . area ( stacked = True ); In [53]: df . plot . area ( stacked = False ); Scatterplot Scatter plot can be drawn by using the DataFrame.plot.scatter() method. Scatter plot requires numeric columns for the x and y axes. These can be specified by the x and y keywords. In [54]: ax = df . plot . scatter ( x = 'a' , y = 'b' , color = 'DarkBlue' , label = 'Group 1' ); df . plot . scatter ( x = 'c' , y = 'd' , color = 'DarkGreen' , label = 'Group 2' , ax = ax ); pandas Tricks The copy() method on pandas objects copies the underlying data (though not the axis indexes, since they are immutable) and returns a new object. Note that it is seldom necessary to copy objects. For example, there are only a handful of ways to alter a DataFrame in-place: Inserting, deleting, or modifying a column. Assigning to the index or columns attributes. For homogeneous data, directly modifying the values via the values attribute or advanced indexing. To be clear, no pandas method has the side effect of modifying your data; almost every method returns a new object, leaving the original object untouched. If the data is modified, it is because you did so explicitly 4 - Group Exercise: 1/2 hour in the Life of a Cardiologist Try each exercise on your own and then discuss with your peers sitting at your table. Feel free to engage the TFs and instructors as well. Visualize and explore the data. Use .describe() to look at your data and also examine if you have any missing values. What is the actual number of feature variables after converting categorical variables to dummy ones? List of available variables (includes target variable num ): age : continuous sex : categorical, 2 values {0: female, 1: male} cp (chest pain type): categorical, 4 values {1: typical angina, 2: atypical angina, 3: non-angina, 4: asymptomatic angina} restbp (resting blood pressure on admission to hospital): continuous (mmHg) chol (serum cholesterol level) : continuous (mg/dl) fbs (fasting blood sugar): categorical, 2 values {0: <= 120 mg/dl, 1: > 120 mg/dl} restecg (resting electrocardiography): categorical, 3 values {0: normal, 1: ST-T wave abnormality, 2: left ventricular hypertrophy} thalach (maximum heart rate achieved): continuous exang (exercise induced angina): categorical, 2 values {0: no, 1: yes} oldpeak (ST depression induced by exercise relative to rest): continuous slope (slope of peak exercise ST segment): categorical, 3 values {1: upsloping, 2: flat, 3: downsloping} ca (number of major vessels colored by fluoroscopy): discrete (0,1,2,3) thal : categorical, 3 values {3: normal, 6: fixed defect, 7: reversible defect} num (diagnosis of heart disease): categorical, 5 values {0: less than 50% narrowing in any major vessel, 1-4: more than 50% narrowing in 1-4 vessels} In [55]: # load the dataset heart_df = pd . read_csv ( '../data/heart_disease.csv' , header = None , names = columns ) heart_df . head () Out[55]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } age sex cp restbp chol fbs restecg thalach exang oldpeak slope ca thal num 0 63.0 1.0 1.0 145.0 233.0 1.0 2.0 150.0 0.0 2.3 3.0 0.0 6.0 0.0 1 67.0 1.0 4.0 160.0 286.0 0.0 2.0 108.0 1.0 1.5 2.0 3.0 3.0 2.0 2 67.0 1.0 4.0 120.0 229.0 0.0 2.0 129.0 1.0 2.6 2.0 2.0 7.0 1.0 3 37.0 1.0 3.0 130.0 250.0 0.0 0.0 187.0 0.0 3.5 3.0 0.0 3.0 0.0 4 41.0 0.0 2.0 130.0 204.0 0.0 2.0 172.0 0.0 1.4 1.0 0.0 3.0 0.0 Answer the following question using plots At what ages do people seek cardiological exams? Do men seek help more than women? Examine the variables. How do they relate to one another? (Variation on 02): What % of men and women seek cardio exams? Does resting blood pressure increase with age? Pandas trick: .replace The response variable (num) is categorical with 5 values, but we don't have enough data to predict all the categories. Therefore we'll replace num with hd (heart disease): categorical, 2 values {0: no, 1: yes} . Use the code below (take a minute to understand how it works, it's very useful!): In [56]: # Replace response variable values with a binary response (1: heart disease(hd) or 0: not) heart_df [ 'num' ] . replace ( to_replace = [ 1 , 2 , 3 , 4 ], value = 1 , inplace = True ) # Rename column for clarity heart_df = heart_df . rename ( columns = { 'num' : 'hd' }) heart_df . head () Out[56]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } age sex cp restbp chol fbs restecg thalach exang oldpeak slope ca thal hd 0 63.0 1.0 1.0 145.0 233.0 1.0 2.0 150.0 0.0 2.3 3.0 0.0 6.0 0.0 1 67.0 1.0 4.0 160.0 286.0 0.0 2.0 108.0 1.0 1.5 2.0 3.0 3.0 1.0 2 67.0 1.0 4.0 120.0 229.0 0.0 2.0 129.0 1.0 2.6 2.0 2.0 7.0 1.0 3 37.0 1.0 3.0 130.0 250.0 0.0 0.0 187.0 0.0 3.5 3.0 0.0 3.0 0.0 4 41.0 0.0 2.0 130.0 204.0 0.0 2.0 172.0 0.0 1.4 1.0 0.0 3.0 0.0 In [57]: # look at the features heart_df . info (); RangeIndex: 299 entries, 0 to 298 Data columns (total 14 columns): age 299 non-null float64 sex 299 non-null float64 cp 299 non-null float64 restbp 299 non-null float64 chol 299 non-null float64 fbs 299 non-null float64 restecg 299 non-null float64 thalach 299 non-null float64 exang 299 non-null float64 oldpeak 299 non-null float64 slope 299 non-null float64 ca 299 non-null float64 thal 299 non-null float64 hd 299 non-null float64 dtypes: float64(14) memory usage: 32.8 KB In [58]: heart_df . describe () Out[58]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } age sex cp restbp chol fbs restecg thalach exang oldpeak slope ca thal hd count 299.000000 299.00000 299.000000 299.000000 299.000000 299.000000 299.000000 299.000000 299.000000 299.000000 299.000000 299.000000 299.000000 299.000000 mean 54.521739 0.67893 3.163880 131.715719 246.785953 0.143813 0.989967 149.327759 0.331104 1.058528 1.605351 0.672241 4.745819 0.464883 std 9.030264 0.46767 0.964069 17.747751 52.532582 0.351488 0.994903 23.121062 0.471399 1.162769 0.616962 0.937438 1.940977 0.499601 min 29.000000 0.00000 1.000000 94.000000 100.000000 0.000000 0.000000 71.000000 0.000000 0.000000 1.000000 0.000000 3.000000 0.000000 25% 48.000000 0.00000 3.000000 120.000000 211.000000 0.000000 0.000000 132.500000 0.000000 0.000000 1.000000 0.000000 3.000000 0.000000 50% 56.000000 1.00000 3.000000 130.000000 242.000000 0.000000 1.000000 152.000000 0.000000 0.800000 2.000000 0.000000 3.000000 0.000000 75% 61.000000 1.00000 4.000000 140.000000 275.500000 0.000000 2.000000 165.500000 1.000000 1.600000 2.000000 1.000000 7.000000 1.000000 max 77.000000 1.00000 4.000000 200.000000 564.000000 1.000000 2.000000 202.000000 1.000000 6.200000 3.000000 3.000000 7.000000 1.000000 At this point you should split in train and test set and work only on the train!! . For simplicity we will not do this in the solutions. In [59]: # your code here # 01. what ages do people seek cardiological exams? In [60]: # %load solutions/q01.py fig , ax = plt . subplots ( figsize = ( 8 , 6 )) sns . set_context ( \"notebook\" , font_scale = 1.5 , rc = { \"lines.linewidth\" : 2.5 }) ax = sns . distplot ( heart_df . age , kde = False ) #, bins=10); ax . set_xlim ( 0 , 90 ); ax . set_title ( 'Ages seeking cardio exams' ); #ax.set_xlabel('age of patient') In [61]: # your code here # 02. do men seek help more than women? In [62]: # %load solutions/q02.py heart_df . replace ({ 'sex' : { 0. : 'F' , 1. : 'M' }}, inplace = True ) # We would use a countplot ax = sns . countplot ( x = \"sex\" , data = heart_df ) ax . set_title ( 'Count of M vs. F who seek cardio examinations' ); In [63]: heart_df . replace ({ 'sex' : { 'F' : 0. , 'M' : 1. }}, inplace = True ) The number of feature variables (after converting categorical variables to dummy ones) is: 1 (age) + 1 (sex) + 3 (cp) + 1 (restbp) + 1 (chol) + 1 (fbs) + 2 (restecg) + 1 (thalach) + 1 (exang) + 1 (oldpeak) + 2 (slope) + 1 (ca) + 2 (thal) = 18 In [64]: # your code here # 03. Examine the variables. How do they relate to one another? In [65]: # %load solutions/q03.py categorical = [ \"sex\" , \"cp\" , \"fbs\" , \"restecg\" , \"exang\" , \"slope\" , \"ca\" , \"thal\" , \"hd\" ] numerical = [ \"age\" , \"restbp\" , \"chol\" , \"thalach\" , \"oldpeak\" ] # pandas trick: give me all rows of numerical columns sns . set_context ( \"notebook\" , font_scale = 1 , rc = { \"lines.linewidth\" : 2.5 }) df_to_plot = heart_df . loc [:, numerical ] sns . pairplot ( df_to_plot ); plt . show () # Look at correlation coefficients too corr_matrix = heart_df . corr () corr_matrix [ 'hd' ] . sort_values ( ascending = False ) Out[65]: hd 1.000000 thal 0.530603 ca 0.455398 exang 0.427123 oldpeak 0.424947 cp 0.412597 slope 0.335926 sex 0.281912 age 0.223498 restecg 0.157941 restbp 0.153849 chol 0.067350 fbs 0.000192 thalach -0.430108 Name: hd, dtype: float64 In [66]: # your code here # 04. What percentage of men and women seek cardio exams? In [69]: # %load solutions/q04.py # first find percentages per_men = ( heart_df . sex . value_counts ()[ 1 ]) / ( heart_df . sex . value_counts ()[ 0 ] + heart_df . sex . value_counts ()[ 1 ]) per_wom = ( heart_df . sex . value_counts ()[ 0 ]) / ( heart_df . sex . value_counts ()[ 0 ] + heart_df . sex . value_counts ()[ 1 ]) per_men , per_wom labels = 'Men' , 'Women' explode = ( 0 , 0.1 ) # only \"explode\" the 2nd slice sizes = [ per_men , per_wom ] # First and last time I will use a pie chart, let alone an exploding one!! fig1 , ax1 = plt . subplots () ax1 . pie ( sizes , explode = explode , labels = labels , autopct = ' %1.1f%% ' , shadow = True , startangle = 90 ) ax1 . axis ( 'equal' ) # Equal aspect ratio ensures that pie is drawn as a circle. plt . show () In [70]: # your code here # 05. Does resting blood pressure increase with age? In [71]: # %load solutions/q05.py fig , ax = plt . subplots ( figsize = ( 20 , 6 )) ax = sns . boxplot ( x = \"age\" , y = \"restbp\" , data = heart_df ) ax . set_ylabel ( None ); ax . set_xlabel ( 'age' , fontsize = 14 ); ax . set_ylabel ( 'restbp (mmHg)' , fontsize = 14 ); ax . set_title ( 'Percentile Distibution for age and rest blood pressure' , fontsize = 14 ); Bonus: Find the hidden pattern Read the following file into a pandas Dataframe: '../data/mystery.csv' and plot it. How does it look? You should see a beautiful pattern. If not, think of ways to fix the issue. In [ ]: mystery = pd . read_csv ( '../data/mystery.csv' , sep = ' ' , header = None ) mystery . head () In [ ]: # your code here In [ ]: # this solution will be revealed in the next lab # %load solutions/mystery.py if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab-5/solutions/"},{"title":"Lab 5: Exploratory Data Analysis, seaborn, more Plotting","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109A Introduction to Data Science Lab 5: Exploratory Data Analysis, seaborn , more Plotting Harvard University Fall 2019 Instructors: Pavlos Protopapas, Kevin Rader, and Chris Tanner Material Preparation: Eleni Kaxiras. In [67]: #RUN THIS CELL import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[67]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } span.sub-q { font-weight: bold; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } In [68]: # import the necessary libraries % matplotlib inline import numpy as np import scipy as sp import matplotlib as mpl import matplotlib.cm as cm import matplotlib.pyplot as plt import pandas as pd import time pd . set_option ( 'display.width' , 500 ) pd . set_option ( 'display.max_columns' , 200 ) pd . set_option ( 'display.notebook_repr_html' , True ) import seaborn as sns from sklearn.linear_model import LinearRegression from sklearn.model_selection import train_test_split from sklearn.metrics import mean_squared_error import warnings warnings . filterwarnings ( 'ignore' ) % config InlineBackend.figure_format ='retina' In [69]: %% javascript IPython . OutputArea . auto_scroll_threshold = 9999 ; var element = $('#bdc5bcd7-3da8-477e-adf4-a4dc89aec960'); IPython.OutputArea.auto_scroll_threshold = 9999; Learning Goals By the end of this lab, you should be able to: know how to implement the different types of plots such as histograms, boxplots, etc, that were mentioned in class. have seaborn as well as matplotlib in your plotting toolbox. This lab corresponds to lecture 6 up to 9 and maps to homework 3. Table of Contents 1 - Visualization Inspiration 2 - Intro to seaborn plotting 3 - Different types of plots (histograms, boxplots, etc) 4 - Excercise: EDA on Medical Data 1 - Visualization Inspiration source: nytimes.org Notice that in \"Summers Are Getting Hotter,\" above, the histogram has intervals for global summer temperatures on the x-axis, designated from extremely cold to extremely hot, and their frequency on the y-axis. That was an infographic intended for the general public. In contrast, take a look at the plots below of the same data published at a scientific journal . They look quite different, don't they? James Hansen, Makiko Sato, and Reto Ruedy , Perception of climate change. PNAS 2 - Implementing Various Types of Plots using matplotlib and seaborn . Before you start coding your visualization, you need to decide what type of vizualization to use. A box plot, a histogram, a scatter plot, or something else? That will depend on the purpose of the plot (is it for performing an inspection on your data (EDA, or for showing your results/conclusions to people) and the number variables that you want to plot. You have a lot of tools for plotting in Python. The basic one, of course, is matplotlib and there are other libraries that are built on top of it, such as seaborn , bokeh , or altair . In this class we will continue using matplotlib and also look into seaborn . Those two libraries are the ones you should be using for homework. Introduction to seaborn Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics. The library provides a database of useful datasets for educational purposes that can be loaded by typing: seaborn . load_dataset ( name , cache = True , data_home = None , ** kws ) For information on what these datasets are : https://github.com/mwaskom/seaborn-data The plotting functions in seaborn can be decided in two categories 'axes-level' functions, such as regplot , boxplot , kdeplot , scatterplot , distplot which can connect with the matplotlib Axes object and its parameters. You can use that object as you would in matplotlib : f , ( ax1 , ax2 ) = plt . subplots ( 2 ) sns . regplot ( x , y , ax = ax1 ) sns . kdeplot ( x , ax = ax2 ) ax1 = sns . distplot ( x , kde = False , bins = 20 ) 'figure-level' functions, such as lmplot , factorplot , jointplot , relplot . In this case, seaborn organizes the resulting plot which may include several Axes in a meaningful way. That means that the functions need to have total control over the figure, so it isn't possible to plot, say, an lmplot onto one that already exists. Calling the function always initializes a figure and sets it up for the specific plot it's drawing. These functions return an object of the type FacetGrid with its own methods for operating on the resulting plot. To set the parameters for figure-level functions: sns . set_context ( \"notebook\" , font_scale = 1 , rc = { \"lines.linewidth\" : 2.5 }) The Titanic dataset The titanic.csv file contains data for 887 passengers on the Titanic. Each row represents one person. The columns describe different attributes about the person including whether they survived, their age, their on-board class, their sex, and the fare they paid. In [70]: titanic = sns . load_dataset ( 'titanic' ); titanic . info (); RangeIndex: 891 entries, 0 to 890 Data columns (total 15 columns): survived 891 non-null int64 pclass 891 non-null int64 sex 891 non-null object age 714 non-null float64 sibsp 891 non-null int64 parch 891 non-null int64 fare 891 non-null float64 embarked 889 non-null object class 891 non-null category who 891 non-null object adult_male 891 non-null bool deck 203 non-null category embark_town 889 non-null object alive 891 non-null object alone 891 non-null bool dtypes: bool(2), category(2), float64(2), int64(4), object(5) memory usage: 80.6+ KB In [71]: titanic . columns Out[71]: Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town', 'alive', 'alone'], dtype='object') Exercise: Drop the following features: 'embarked', 'who', 'adult_male', 'embark_town', 'alive', 'alone' In [72]: # your code here # your code here columns = [ 'embarked' , 'who' , 'adult_male' , 'embark_town' , 'alive' , 'alone' ] titanic = titanic . drop ( columns = columns ) titanic Out[72]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } survived pclass sex age sibsp parch fare class deck 0 0 3 male 22.0 1 0 7.2500 Third NaN 1 1 1 female 38.0 1 0 71.2833 First C 2 1 3 female 26.0 0 0 7.9250 Third NaN 3 1 1 female 35.0 1 0 53.1000 First C 4 0 3 male 35.0 0 0 8.0500 Third NaN 5 0 3 male NaN 0 0 8.4583 Third NaN 6 0 1 male 54.0 0 0 51.8625 First E 7 0 3 male 2.0 3 1 21.0750 Third NaN 8 1 3 female 27.0 0 2 11.1333 Third NaN 9 1 2 female 14.0 1 0 30.0708 Second NaN 10 1 3 female 4.0 1 1 16.7000 Third G 11 1 1 female 58.0 0 0 26.5500 First C 12 0 3 male 20.0 0 0 8.0500 Third NaN 13 0 3 male 39.0 1 5 31.2750 Third NaN 14 0 3 female 14.0 0 0 7.8542 Third NaN 15 1 2 female 55.0 0 0 16.0000 Second NaN 16 0 3 male 2.0 4 1 29.1250 Third NaN 17 1 2 male NaN 0 0 13.0000 Second NaN 18 0 3 female 31.0 1 0 18.0000 Third NaN 19 1 3 female NaN 0 0 7.2250 Third NaN 20 0 2 male 35.0 0 0 26.0000 Second NaN 21 1 2 male 34.0 0 0 13.0000 Second D 22 1 3 female 15.0 0 0 8.0292 Third NaN 23 1 1 male 28.0 0 0 35.5000 First A 24 0 3 female 8.0 3 1 21.0750 Third NaN 25 1 3 female 38.0 1 5 31.3875 Third NaN 26 0 3 male NaN 0 0 7.2250 Third NaN 27 0 1 male 19.0 3 2 263.0000 First C 28 1 3 female NaN 0 0 7.8792 Third NaN 29 0 3 male NaN 0 0 7.8958 Third NaN ... ... ... ... ... ... ... ... ... ... 861 0 2 male 21.0 1 0 11.5000 Second NaN 862 1 1 female 48.0 0 0 25.9292 First D 863 0 3 female NaN 8 2 69.5500 Third NaN 864 0 2 male 24.0 0 0 13.0000 Second NaN 865 1 2 female 42.0 0 0 13.0000 Second NaN 866 1 2 female 27.0 1 0 13.8583 Second NaN 867 0 1 male 31.0 0 0 50.4958 First A 868 0 3 male NaN 0 0 9.5000 Third NaN 869 1 3 male 4.0 1 1 11.1333 Third NaN 870 0 3 male 26.0 0 0 7.8958 Third NaN 871 1 1 female 47.0 1 1 52.5542 First D 872 0 1 male 33.0 0 0 5.0000 First B 873 0 3 male 47.0 0 0 9.0000 Third NaN 874 1 2 female 28.0 1 0 24.0000 Second NaN 875 1 3 female 15.0 0 0 7.2250 Third NaN 876 0 3 male 20.0 0 0 9.8458 Third NaN 877 0 3 male 19.0 0 0 7.8958 Third NaN 878 0 3 male NaN 0 0 7.8958 Third NaN 879 1 1 female 56.0 0 1 83.1583 First C 880 1 2 female 25.0 0 1 26.0000 Second NaN 881 0 3 male 33.0 0 0 7.8958 Third NaN 882 0 3 female 22.0 0 0 10.5167 Third NaN 883 0 2 male 28.0 0 0 10.5000 Second NaN 884 0 3 male 25.0 0 0 7.0500 Third NaN 885 0 3 female 39.0 0 5 29.1250 Third NaN 886 0 2 male 27.0 0 0 13.0000 Second NaN 887 1 1 female 19.0 0 0 30.0000 First B 888 0 3 female NaN 1 2 23.4500 Third NaN 889 1 1 male 26.0 0 0 30.0000 First C 890 0 3 male 32.0 0 0 7.7500 Third NaN 891 rows × 9 columns Exercise: Find for how many passengeres we do not have their deck information. In [73]: # your code here # your code here missing_decks = len ( titanic [( pd . isna ( titanic [ 'deck' ]) == True )]) missing_decks Out[73]: 688 Histograms Plotting one variable's distribution (categorical and continous) The most convenient way to take a quick look at a univariate distribution in seaborn is the distplot() function. By default, this will draw a histogram and fit a kernel density estimate (KDE). A histogram displays a quantitative (numerical) distribution by showing the number (or percentage) of the data values that fall in specified intervals. The intervals are on the x-axis and the number of values falling in each interval, shown as either a number or percentage, are represented by bars drawn above the corresponding intervals. In [74]: # What was the age distribution among passengers in the Titanic? import seaborn as sns sns . set ( color_codes = True ) f , ax = plt . subplots ( 1 , 1 , figsize = ( 8 , 3 )); ax = sns . distplot ( titanic . age , kde = False , bins = 20 ) # bug #ax = sns.distplot(titanic.age, kde=False, bins=20).set(xlim=(0, 90)); ax . set ( xlim = ( 0 , 90 )); ax . set_ylabel ( 'counts' ); In [75]: f , ax = plt . subplots ( 1 , 1 , figsize = ( 8 , 3 )) ax . hist ( titanic . age , bins = 20 ); ax . set_xlim ( 0 , 90 ); Exercise (pandas trick): Count all the infants on board (age less than 3) and all the children ages 5-10. In [76]: # your code here infants = len ( titanic [( titanic . age < 3 )]) children = len ( titanic [( titanic . age >= 3 ) & ( titanic . age < 10 )]) print ( f 'There were {infants} infants and {children} children on board the Titanic' ) There were 24 infants and 38 children on board the Titanic Pandas trick: We want to creat virtual \"bins\" for readability and replace ranges of values with categories. We will do this in an ad hoc way, it can be done better . For example in the previous plot we could set: (age<3) = 'infants' , (3 , (18 See matplotlib colors here. In [77]: # set the colors cmap = plt . get_cmap ( 'Pastel1' ) young = cmap ( 0.5 ) middle = cmap ( 0.2 ) older = cmap ( 0.8 ) # get the object we will change - patches is an array with len: num of bins fig , ax = plt . subplots () y_values , bins , patches = ax . hist ( titanic . age , 10 ) [ patches [ i ] . set_facecolor ( young ) for i in range ( 0 , 1 )] # bin 0 [ patches [ i ] . set_facecolor ( middle ) for i in range ( 1 , 3 )] # bins 1 and 2 [ patches [ i ] . set_facecolor ( older ) for i in range ( 3 , 10 )] # 7 remaining bins ax . grid ( True ) fig . show () Kernel Density Estimation The kernel density estimate can be a useful tool for plotting the shape of a distribution. The bandwidth (bw) parameter of the KDE controls how tightly the estimation is fit to the data, much like the bin size in a histogram. It corresponds to the width of the kernels we plotted above. The default behavior tries to guess a good value using a common reference rule, but it may be helpful to try larger or smaller values. In [78]: sns . kdeplot ( titanic . age , bw = 0.6 , label = \"bw: 0.6\" , shade = True , color = \"r\" ); sns . kdeplot ( titanic . age , bw = 2 , label = \"bw: 2\" , shade = True ); Exercise: Plot the distribution of fare paid by passengers In [79]: # your code here sns . kdeplot ( titanic . fare , bw = 0.5 , label = \"bw: 0.5\" , shade = True ); You can mix elements of matplotlib such as Axes with seaborn elements for a best use of both worlds. In [80]: import seaborn as sns sns . set ( color_codes = True ) x1 = np . random . normal ( size = 100 ) x2 = np . random . normal ( size = 100 ) fig , ax = plt . subplots ( 1 , 2 , figsize = ( 15 , 5 )) # seaborn goes in first subplot sns . set ( font_scale = 0.5 ) sns . distplot ( x1 , kde = False , bins = 15 , ax = ax [ 0 ]); sns . distplot ( x2 , kde = False , bins = 15 , ax = ax [ 0 ]); ax [ 0 ] . set_title ( 'seaborn Graph Here' , fontsize = 14 ) ax [ 0 ] . set_xlabel ( r '$x$' , fontsize = 14 ) ax [ 0 ] . set_ylabel ( r '$count$' , fontsize = 14 ) # matplotlib goes in second subplot ax [ 1 ] . hist ( x1 , alpha = 0.2 , bins = 15 , label = r '$x1$' ); ax [ 1 ] . hist ( x2 , alpha = 0.5 , bins = 15 , label = r '$x2$' ); ax [ 1 ] . set_xlabel ( r '$x$' , fontsize = 14 ) ax [ 1 ] . set_ylabel ( r '$count$' , fontsize = 14 ) ax [ 1 ] . set_title ( 'matplotlib Graph Here' , fontsize = 14 ) ax [ 1 ] . legend ( loc = 'best' , fontsize = 14 ); Introduding the heart disease dataset. More on this in the in-class exercise at the end of the notebook. In [81]: columns = [ \"age\" , \"sex\" , \"cp\" , \"restbp\" , \"chol\" , \"fbs\" , \"restecg\" , \"thalach\" , \"exang\" , \"oldpeak\" , \"slope\" , \"ca\" , \"thal\" , \"num\" ] heart_df = pd . read_csv ( '../data/heart_disease.csv' , header = None , names = columns ) heart_df . head () Out[81]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } age sex cp restbp chol fbs restecg thalach exang oldpeak slope ca thal num 0 63.0 1.0 1.0 145.0 233.0 1.0 2.0 150.0 0.0 2.3 3.0 0.0 6.0 0.0 1 67.0 1.0 4.0 160.0 286.0 0.0 2.0 108.0 1.0 1.5 2.0 3.0 3.0 2.0 2 67.0 1.0 4.0 120.0 229.0 0.0 2.0 129.0 1.0 2.6 2.0 2.0 7.0 1.0 3 37.0 1.0 3.0 130.0 250.0 0.0 0.0 187.0 0.0 3.5 3.0 0.0 3.0 0.0 4 41.0 0.0 2.0 130.0 204.0 0.0 2.0 172.0 0.0 1.4 1.0 0.0 3.0 0.0 Boxplots One variable. In [82]: # seaborn ax = sns . boxplot ( x = 'age' , data = titanic ) #ax = sns.boxplot(x=titanic['age']) # another way to write this ax . set_ylabel ( None ); ax . set_xlabel ( 'age' , fontsize = 14 ); ax . set_title ( 'Distribution of age in the Titanic' , fontsize = 14 ); Two variables Exercise: Did more young people or older ones get first class tickets on the Titanic? In [83]: # your code here # two variables seaborn ax = sns . boxplot ( x = 'class' , y = 'age' , data = titanic ) In [84]: # two variable boxplot in pandas titanic . boxplot ( 'age' , by = 'class' ) Out[84]: Scatterplots Plotting the distribution of two variables Also called a bivariate distribution where each observation is shown with a point with x and y values. You can draw a scatterplot with the matplotlib plt.scatter function, or the seaborn jointplot() function: In [85]: f , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 5 )) sns . scatterplot ( x = \"fare\" , y = \"age\" , data = titanic , ax = ax ); In [86]: sns . jointplot ( \"fare\" , \"age\" , data = titanic , s = 40 , edgecolor = \"w\" , linewidth = 1 ) Out[86]: You may control the seaborn Figure aesthetics . In [87]: # matplotlib fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . scatter ( heart_df [ 'age' ], heart_df [ 'restbp' ], alpha = 0.8 ); ax . set_xlabel ( r '$Age (yrs)$' , fontsize = 15 ); ax . set_ylabel ( r 'Resting Blood Pressure (mmHg)' , fontsize = 15 ); ax . set_title ( 'Age vs. Resting Blood Pressure' , fontsize = 14 ) plt . show (); Plotting the distribution of three variables In [22]: f , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 5 )) sns . scatterplot ( x = \"fare\" , y = \"age\" , hue = \"survived\" , data = titanic , ax = ax ); Plotting the distribution of four variables (going too far?) Exercise: Plot the distribution of fare paid by passengers according to age, survival and sex. Use size= for the fourth variable In [23]: # your code here f , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 5 )) sns . scatterplot ( x = \"fare\" , y = \"age\" , hue = \"survived\" , size = \"sex\" , data = titanic , ax = ax ); Pairplots In [24]: titanic . columns Out[24]: Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'class', 'deck'], dtype='object') In [25]: to_plot = [ 'age' , 'fare' , 'survived' , 'deck' ] In [28]: df_to_plot = titanic . loc [:, to_plot ] sns . pairplot ( df_to_plot ); In [29]: from pandas.plotting import scatter_matrix scatter_matrix ( df_to_plot , alpha = 0.8 , figsize = ( 10 , 10 ), diagonal = 'kde' ); Plotting Categorical Variables In [35]: titanic = sns . load_dataset ( 'titanic' ) f , ax = plt . subplots ( figsize = ( 7 , 3 )); ax = sns . countplot ( y = \"deck\" , data = titanic , color = \"c\" ); ax . set_title ( 'Titanic' ); In [42]: ax = sns . countplot ( x = \"class\" , data = titanic ) ax . set_title ( 'Titanic' ); In [43]: fig , ax = plt . subplots ( figsize = ( 10 , 6 )) # Create figure object sns . set_context ( \"notebook\" , font_scale = 1 , rc = { \"lines.linewidth\" : 2.5 }) ax = sns . countplot ( x = \"deck\" , data = titanic ) In [44]: sns . set ( style = \"ticks\" , palette = \"muted\" ) sns . relplot ( x = \"age\" , y = \"deck\" , col = \"class\" , data = titanic ); In [45]: sns . set_context ( \"notebook\" , font_scale = 1.5 , rc = { \"lines.linewidth\" : 2.5 }) sns . pairplot ( data = titanic , hue = \"deck\" ); Introduction to pandas plotting. There is plotting functionality built in pandas . Look for it in the pandas \"encyclopedia\", a mere 2883-page pdf from the creator Wes McKinney: pandas documentation (pdf) Example: The value_counts() Series method and top-level function computes a histogram of a 1D array of values. It can also be used as a function on regular arrays. Reminder: DataFrame: \"index\" (axis=0, default), \"columns\" (axis=1) Line Graph Good for time dependency or when a variable evolves In [46]: df = pd . DataFrame ( np . random . randn ( 1000 , 4 ), columns = [ 'A' , 'B' , 'C' , 'D' ]) df . head () Out[46]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 0 0.201468 0.002378 0.460038 -0.620872 1 -1.347740 2.317959 -0.128938 1.129856 2 0.827727 -1.546181 -1.576246 -1.113427 3 0.345499 1.469756 -0.234321 1.381242 4 -0.301247 -0.680943 0.669998 -0.203680 In [47]: # cumulative sum adds column values as it goes df = df . cumsum () df . head () Out[47]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A B C D 0 0.201468 0.002378 0.460038 -0.620872 1 -1.146272 2.320337 0.331100 0.508984 2 -0.318545 0.774156 -1.245146 -0.604443 3 0.026954 2.243912 -1.479467 0.776799 4 -0.274293 1.562969 -0.809469 0.573119 In [48]: plt . figure (); df . plot (); plt . legend ( loc = 'best' ); In [49]: ts = pd . Series ( np . random . randn ( 1000 ), index = pd . date_range ( '1/1/2000' , periods = 1000 )) df = pd . DataFrame ( np . random . randn ( 1000 , 4 ), index = ts . index , columns = list ( 'ABCD' )) df = df . cumsum () plt . figure (); df . plot (); Plotting methods allow for a handful of plot styles other than the default line plot. These methods can be provided as the kind keyword argument to plot(), and include: ‘bar' or ‘barh' for bar plots ‘hist' for histogram ‘box' for boxplot ‘kde' or ‘density' for density plots ‘area' for area plots ‘scatter' for scatter plots ‘hexbin' for hexagonal bin plots ‘pie' for pie plots In addition to these kind s, there are the DataFrame.hist() , and DataFrame.boxplot() methods, which use a separate interface. scatter_matrix in pandas.plotting takes a Series or DataFrame as an argument. Bar Plots In [50]: plt . figure (); df . iloc [ 0 ] . plot ( kind = 'bar' ); In [51]: df2 = pd . DataFrame ( np . random . rand ( 10 , 4 ), columns = [ 'a' , 'b' , 'c' , 'd' ]) df2 Out[51]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } a b c d 0 0.507876 0.850593 0.986939 0.082241 1 0.230224 0.268668 0.462782 0.440504 2 0.597335 0.136271 0.931408 0.238425 3 0.860248 0.465814 0.312943 0.441529 4 0.895884 0.683348 0.955019 0.545084 5 0.990852 0.210919 0.998533 0.153769 6 0.008812 0.337127 0.981830 0.321036 7 0.190601 0.309422 0.617435 0.442801 8 0.700053 0.867143 0.472762 0.792051 9 0.994677 0.087399 0.767110 0.780876 In [52]: df2 . plot . bar (); In [53]: # horizontal bar plot df2 . plot . barh ( stacked = False ); Histograms In [54]: df4 = pd . DataFrame ({ 'a' : np . random . randn ( 1000 ) + 1 , 'b' : np . random . randn ( 1000 ), 'c' : np . random . randn ( 1000 ) - 1 }, columns = [ 'a' , 'b' , 'c' ]) plt . figure (); df4 . plot . hist ( alpha = 0.5 , stacked = False , bins = 60 ); Boxplots In [55]: color = { 'boxes' : 'DarkGreen' , 'whiskers' : 'DarkOrange' , 'medians' : 'DarkBlue' , 'caps' : 'Gray' } df = pd . DataFrame ( np . random . rand ( 10 , 5 ), columns = [ 'A' , 'B' , 'C' , 'D' , 'E' ]) df . plot . box ( color = color ); Area plots You can create area plots with Series.plot.area() and DataFrame.plot.area() . Area plots are stacked by default. To produce stacked area plot, each column must be either all positive or all negative values. In [56]: df = pd . DataFrame ( np . random . rand ( 10 , 4 ), columns = [ 'a' , 'b' , 'c' , 'd' ]) df . plot . area ( stacked = True ); In [57]: df . plot . area ( stacked = False ); Scatterplot Scatter plot can be drawn by using the DataFrame.plot.scatter() method. Scatter plot requires numeric columns for the x and y axes. These can be specified by the x and y keywords. In [58]: ax = df . plot . scatter ( x = 'a' , y = 'b' , color = 'DarkBlue' , label = 'Group 1' ); df . plot . scatter ( x = 'c' , y = 'd' , color = 'DarkGreen' , label = 'Group 2' , ax = ax ); pandas Tricks The copy() method on pandas objects copies the underlying data (though not the axis indexes, since they are immutable) and returns a new object. Note that it is seldom necessary to copy objects. For example, there are only a handful of ways to alter a DataFrame in-place: Inserting, deleting, or modifying a column. Assigning to the index or columns attributes. For homogeneous data, directly modifying the values via the values attribute or advanced indexing. To be clear, no pandas method has the side effect of modifying your data; almost every method returns a new object, leaving the original object untouched. If the data is modified, it is because you did so explicitly 4 - Group Exercise: 1/2 hour in the Life of a Cardiologist Try each exercise on your own and then discuss with your peers sitting at your table. Feel free to engage the TFs and instructors as well. Visualize and explore the data. Use .describe() to look at your data and also examine if you have any missing values. What is the actual number of feature variables after converting categorical variables to dummy ones? List of available variables (includes target variable num ): age : continuous sex : categorical, 2 values {0: female, 1: male} cp (chest pain type): categorical, 4 values {1: typical angina, 2: atypical angina, 3: non-angina, 4: asymptomatic angina} restbp (resting blood pressure on admission to hospital): continuous (mmHg) chol (serum cholesterol level) : continuous (mg/dl) fbs (fasting blood sugar): categorical, 2 values {0: <= 120 mg/dl, 1: > 120 mg/dl} restecg (resting electrocardiography): categorical, 3 values {0: normal, 1: ST-T wave abnormality, 2: left ventricular hypertrophy} thalach (maximum heart rate achieved): continuous exang (exercise induced angina): categorical, 2 values {0: no, 1: yes} oldpeak (ST depression induced by exercise relative to rest): continuous slope (slope of peak exercise ST segment): categorical, 3 values {1: upsloping, 2: flat, 3: downsloping} ca (number of major vessels colored by fluoroscopy): discrete (0,1,2,3) thal : categorical, 3 values {3: normal, 6: fixed defect, 7: reversible defect} num (diagnosis of heart disease): categorical, 5 values {0: less than 50% narrowing in any major vessel, 1-4: more than 50% narrowing in 1-4 vessels} In [59]: # load the dataset heart_df = pd . read_csv ( '../data/heart_disease.csv' , header = None , names = columns ) heart_df . head () Out[59]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } age sex cp restbp chol fbs restecg thalach exang oldpeak slope ca thal num 0 63.0 1.0 1.0 145.0 233.0 1.0 2.0 150.0 0.0 2.3 3.0 0.0 6.0 0.0 1 67.0 1.0 4.0 160.0 286.0 0.0 2.0 108.0 1.0 1.5 2.0 3.0 3.0 2.0 2 67.0 1.0 4.0 120.0 229.0 0.0 2.0 129.0 1.0 2.6 2.0 2.0 7.0 1.0 3 37.0 1.0 3.0 130.0 250.0 0.0 0.0 187.0 0.0 3.5 3.0 0.0 3.0 0.0 4 41.0 0.0 2.0 130.0 204.0 0.0 2.0 172.0 0.0 1.4 1.0 0.0 3.0 0.0 Answer the following question using plots At what ages do people seek cardiological exams? Do men seek help more than women? Examine the variables. How do they relate to one another? (Variation on 02): What % of men and women seek cardio exams? Does resting blood pressure increase with age? Pandas trick: .replace The response variable (num) is categorical with 5 values, but we don't have enough data to predict all the categories. Therefore we'll replace num with hd (heart disease): categorical, 2 values {0: no, 1: yes} . Use the code below (take a minute to understand how it works, it's very useful!): In [63]: # Replace response variable values with a binary response (1: heart disease(hd) or 0: not) #heart_df['num'].replace(to_replace=[1,2,3,4],value=1,inplace=True) # Rename column for clarity #heart_df = heart_df.rename(columns = {'num':'hd'}) heart_df . head () Out[63]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } age sex cp restbp chol fbs restecg thalach exang oldpeak slope ca thal hd 0 63.0 1.0 1.0 145.0 233.0 1.0 2.0 150.0 0.0 2.3 3.0 0.0 6.0 0.0 1 67.0 1.0 4.0 160.0 286.0 0.0 2.0 108.0 1.0 1.5 2.0 3.0 3.0 1.0 2 67.0 1.0 4.0 120.0 229.0 0.0 2.0 129.0 1.0 2.6 2.0 2.0 7.0 1.0 3 37.0 1.0 3.0 130.0 250.0 0.0 0.0 187.0 0.0 3.5 3.0 0.0 3.0 0.0 4 41.0 0.0 2.0 130.0 204.0 0.0 2.0 172.0 0.0 1.4 1.0 0.0 3.0 0.0 In [64]: # look at the features heart_df . info (); RangeIndex: 299 entries, 0 to 298 Data columns (total 14 columns): age 299 non-null float64 sex 299 non-null float64 cp 299 non-null float64 restbp 299 non-null float64 chol 299 non-null float64 fbs 299 non-null float64 restecg 299 non-null float64 thalach 299 non-null float64 exang 299 non-null float64 oldpeak 299 non-null float64 slope 299 non-null float64 ca 299 non-null float64 thal 299 non-null float64 hd 299 non-null float64 dtypes: float64(14) memory usage: 32.8 KB In [65]: heart_df . describe () Out[65]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } age sex cp restbp chol fbs restecg thalach exang oldpeak slope ca thal hd count 299.000000 299.00000 299.000000 299.000000 299.000000 299.000000 299.000000 299.000000 299.000000 299.000000 299.000000 299.000000 299.000000 299.000000 mean 54.521739 0.67893 3.163880 131.715719 246.785953 0.143813 0.989967 149.327759 0.331104 1.058528 1.605351 0.672241 4.745819 0.464883 std 9.030264 0.46767 0.964069 17.747751 52.532582 0.351488 0.994903 23.121062 0.471399 1.162769 0.616962 0.937438 1.940977 0.499601 min 29.000000 0.00000 1.000000 94.000000 100.000000 0.000000 0.000000 71.000000 0.000000 0.000000 1.000000 0.000000 3.000000 0.000000 25% 48.000000 0.00000 3.000000 120.000000 211.000000 0.000000 0.000000 132.500000 0.000000 0.000000 1.000000 0.000000 3.000000 0.000000 50% 56.000000 1.00000 3.000000 130.000000 242.000000 0.000000 1.000000 152.000000 0.000000 0.800000 2.000000 0.000000 3.000000 0.000000 75% 61.000000 1.00000 4.000000 140.000000 275.500000 0.000000 2.000000 165.500000 1.000000 1.600000 2.000000 1.000000 7.000000 1.000000 max 77.000000 1.00000 4.000000 200.000000 564.000000 1.000000 2.000000 202.000000 1.000000 6.200000 3.000000 3.000000 7.000000 1.000000 At this point you should split in train and test set and work only on the train!! . For simplicity we will not do this in the solutions. In [ ]: # your code here # 01. what ages do people seek cardiological exams? In [66]: % load solutions/q01.py --------------------------------------------------------------------------- NameError Traceback (most recent call last) /usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py in find_user_code (self, target, raw, py_only, skip_encoding_cookie, search_ns) 3644 try : # User namespace -> 3645 codeobj = eval ( target , self . user_ns ) 3646 except Exception : in NameError : name 'solutions' is not defined During handling of the above exception, another exception occurred: ValueError Traceback (most recent call last) in ----> 1 get_ipython ( ) . run_line_magic ( 'load' , 'solutions/q01.py' ) /usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py in run_line_magic (self, magic_name, line, _stack_depth) 2312 kwargs [ 'local_ns' ] = sys . _getframe ( stack_depth ) . f_locals 2313 with self . builtin_trap : -> 2314 result = fn ( * args , ** kwargs ) 2315 return result 2316 in load (self, arg_s) /usr/local/lib/python3.7/site-packages/IPython/core/magic.py in (f, *a, **k) 185 # but it's overkill for just that one bit of state. 186 def magic_deco ( arg ) : --> 187 call = lambda f , * a , ** k : f ( * a , ** k ) 188 189 if callable ( arg ) : /usr/local/lib/python3.7/site-packages/IPython/core/magics/code.py in load (self, arg_s) 333 search_ns = 'n' in opts 334 --> 335 contents = self . shell . find_user_code ( args , search_ns = search_ns ) 336 337 if 's' in opts : /usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py in find_user_code (self, target, raw, py_only, skip_encoding_cookie, search_ns) 3646 except Exception : 3647 raise ValueError((\"'%s' was not found in history, as a file, url, \" -> 3648 \"nor in the user namespace.\") % target) 3649 3650 if isinstance ( codeobj , str ) : ValueError : 'solutions/q01.py' was not found in history, as a file, url, nor in the user namespace. In [ ]: # your code here # 02. do men seek help more than women? In [ ]: # %load solutions/q02.py In [ ]: # your code here # 03. Examine the variables. How do they relate to one another? In [ ]: # %load solutions/q03.py In [ ]: # your code here # 04. What percentage of men and women seek cardio exams? In [ ]: # %load solutions/q04.py In [ ]: # your code here # 05. Does resting blood pressure increase with age? In [ ]: # %load solutions/q05.py Bonus: Find the hidden pattern Read the following file into a pandas Dataframe: '../data/mystery.csv' and plot it. How does it look? You should see a beautiful pattern. If not, think of ways to fix the issue. In [ ]: mystery = pd . read_csv ( '../data/mystery.csv' , sep = ' ' , header = None ) mystery . head () In [ ]: # your code here In [ ]: # %load solutions/mystery.py if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab-5/student/"},{"title":"Lab 3: Scikit-learn for Regression","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109A Introduction to Data Science Lab 3: Scikit-learn for Regression Harvard University Fall 2018 Instructors: Pavlos Protopapas and Kevin Rader Authors: David Sondak, Will Claybaugh, Eleni Kaxiras In [2]: # RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[2]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } span.sub-q { font-weight: bold; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Table of Contents Array creation and reshape Some plotting Simple linear regression $k$-nearest neighbors Learning Goals Overall description and goal for the lab. By the end of this lab, you should be able to: Understand array reshaping Review how to make plots Feel comfortable with simple linear regression Feel comfortable with $k$ nearest neighbors This lab corresponds to lecture 4 and maps on to homework 2 (and beyond). In [8]: # import the necessary libraries import warnings warnings . filterwarnings ( 'ignore' ) % matplotlib inline import numpy as np import scipy as sp import matplotlib as mpl import matplotlib.cm as cm import matplotlib.pyplot as plt import pandas as pd import time pd . set_option ( 'display.width' , 500 ) pd . set_option ( 'display.max_columns' , 100 ) pd . set_option ( 'display.notebook_repr_html' , True ) import seaborn as sns Simple Linear Regression Linear regression and its many extensions are a workhorse of the statistics and data science community, both in application and as a reference point for other models. Most of the major concepts in machine learning can be and often are discussed in terms of various linear regression models. Thus, this section will introduce you to building and fitting linear regression models and some of the process behind it, so that you can 1) fit models to data you encounter 2) experiment with different kinds of linear regression and observe their effects 3) see some of the technology that makes regression models work. Linear regression with a toy dataset We first examine a toy problem, focusing our efforts on fitting a linear model to a small dataset with three observations. Each observation consists of one predictor $x_i$ and one response $y_i$ for $i = 1, 2, 3$, \\begin{align*} (x , y) = \\{(x_1, y_1), (x_2, y_2), (x_3, y_3)\\}. \\end{align*} To be very concrete, let's set the values of the predictors and responses. \\begin{equation*} (x , y) = \\{(1, 2), (2, 2), (3, 4)\\} \\end{equation*} There is no line of the form $\\beta_0 + \\beta_1 x = y$ that passes through all three observations, since the data are not collinear. Thus our aim is to find the line that best fits these observations in the least-squares sense , as discussed in lecture. Exercise (10 min) Make two numpy arrays out of this data, x_train and y_train Check the dimentions of these arrays Try to reshape them into a different shape Make points into a very simple scatterplot Make a better scatterplot In [28]: # your code here x_train = np . array ([ 1 , 2 , 3 ]) y_train = np . array ([ 2 , 3 , 6 ]) type ( x_train ) Out[28]: numpy.ndarray In [12]: x_train . shape Out[12]: (3,) In [14]: x_train = x_train . reshape ( 3 , 1 ) x_train . shape Out[14]: (3, 1) In [15]: xx = np . array ([[ 1 , 3 , 5 ],[ 6 , 2 , 1 ]]) xx . shape Out[15]: (2, 3) In [18]: xx = xx . reshape ( 3 , - 1 ) xx Out[18]: array([[1, 3], [5, 6], [2, 1]]) In [29]: # make a simple scatterplot x_train = np . array ([ 1 , 2 , 3 ]) y_train = np . array ([ 2 , 2 , 4 ]) plt . scatter ( x_train , y_train ) # check dimensions print ( x_train . shape , y_train . shape ) (3,) (3,) In [38]: def nice_scatterplot ( x , y , title ): # font size f_size = 18 # make the figure fig , ax = plt . subplots ( 1 , 1 , figsize = ( 8 , 5 )) # Create figure object # set axes limits to make the scale nice ax . set_xlim ( np . min ( x ) - 1 , np . max ( x ) + 1 ) ax . set_ylim ( np . min ( y ) - 1 , np . max ( y ) + 1 ) # adjust size of tickmarks in axes ax . tick_params ( labelsize = f_size ) # remove tick labels ax . tick_params ( labelbottom = False , bottom = False ) # adjust size of axis label ax . set_xlabel ( r '$x$' , fontsize = f_size ) ax . set_ylabel ( r '$y$' , fontsize = f_size ) # set figure title label ax . set_title ( title , fontsize = f_size ) # you may set up grid with this ax . grid ( True , lw = 1.75 , ls = '--' , alpha = 0.15 ) # make actual plot (Notice the label argument!) #ax.scatter(x, y, label=r'$my points$') #ax.scatter(x, y, label='$my points$') ax . scatter ( x , y , label = r '$my\\,points$' ) ax . legend ( loc = 'best' , fontsize = f_size ); return ax nice_scatterplot ( x_train , y_train , 'hello nice plot' ) Out[38]: Formulae Linear regression is special among the models we study beuase it can be solved explicitly. While most other models (and even some advanced versions of linear regression) must be solved itteratively, linear regression has a formula where you can simply plug in the data. For the single predictor case it is: \\begin{align} \\beta_1 &= \\frac{\\sum_{i=1}&#94;n{(x_i-\\bar{x})(y_i-\\bar{y})}}{\\sum_{i=1}&#94;n{(x_i-\\bar{x})&#94;2}}\\\\ \\beta_0 &= \\bar{y} - \\beta_1\\bar{x}\\ \\end{align} Where $\\bar{y}$ and $\\bar{x}$ are the mean of the y values and the mean of the x values, respectively. From the re-aranged second equation we can see that the best-fit line passes through $(\\bar{x},\\bar{y})$, the center of mass of the data From any of the first equations, we can see that the slope of the line has to do with whether or not an x value that is above/below the center of mass is typically paired with a y value that is likewise above/below, or typically paired with one that is opposite. Building a model from scratch In this part, we will solve the equations for simple linear regression and find the best fit solution to our toy problem. The snippets of code below implement the linear regression equations on the observed predictors and responses, which we'll call the training data set. Let's walk through the code. We have to reshape our arrrays to 2D. We will see later why. Exercise (5 min) make an array with shape (2,3) reshape it to a size that you want In [ ]: # your code here xx = np . array ([[ 1 , 2 , 3 ],[ 4 , 6 , 8 ]]) xxx = xx . reshape ( - 1 , 2 ) xxx . shape In [39]: # Reshape to be a proper 2D array x_train = x_train . reshape ( x_train . shape [ 0 ], 1 ) y_train = y_train . reshape ( y_train . shape [ 0 ], 1 ) print ( x_train . shape ) (3, 1) In [40]: # first, compute means y_bar = np . mean ( y_train ) x_bar = np . mean ( x_train ) # build the two terms numerator = np . sum ( ( x_train - x_bar ) * ( y_train - y_bar ) ) denominator = np . sum (( x_train - x_bar ) ** 2 ) print ( numerator . shape , denominator . shape ) #check shapes () () Why the empty brackets? (The numerator and denominator are scalars, as expected.) In [47]: #slope beta1 beta_1 = numerator / denominator #intercept beta0 beta_0 = y_bar - beta_1 * x_bar print ( \"The best-fit line is {0:3.2f} + {1:3.2f} * x\" . format ( beta_0 , beta_1 )) print ( f 'The best fit is {beta_0} ' ) The best-fit line is -0.33 + 2.00 * x The best fit is -0.3333333333333335 Exercise (5 min) Turn the code from the above cells into a function called simple_linear_regression_fit , that inputs the training data and returns beta0 and beta1 . To do this, copy and paste the code from the above cells below and adjust the code as needed, so that the training data becomes the input and the betas become the output. def simple_linear_regression_fit ( x_train : np . ndarray , y_train : np . ndarray ) -> np . ndarray : return Check your function by calling it with the training data from above and printing out the beta values. In [50]: def simple_linear_regression_fit ( x_train : np . ndarray , y_train : np . ndarray ) -> np . ndarray : \"\"\" Inputs: x_train: a (num observations by 1) array holding the values of the predictor variable y_train: a (num observations by 1) array holding the values of the response variable Returns: beta_vals: a (num_features by 1) array holding the intercept and slope coeficients \"\"\" # Check input array sizes if len ( x_train . shape ) < 2 : print ( \"Reshaping features array.\" ) x_train = x_train . reshape ( x_train . shape [ 0 ], 1 ) if len ( y_train . shape ) < 2 : print ( \"Reshaping observations array.\" ) y_train = y_train . reshape ( y_train . shape [ 0 ], 1 ) # first, compute means y_bar = np . mean ( y_train ) x_bar = np . mean ( x_train ) # build the two terms numerator = np . sum ( ( x_train - x_bar ) * ( y_train - y_bar ) ) denominator = np . sum (( x_train - x_bar ) ** 2 ) #slope beta1 beta_1 = numerator / denominator #intercept beta0 beta_0 = y_bar - beta_1 * x_bar return np . array ([ beta_0 , beta_1 ]) Let's run this function and see the coefficients In [55]: x_train = np . array ([ 1 , 2 , 3 ]) y_train = np . array ([ 2 , 2 , 4 ]) betas = simple_linear_regression_fit ( x_train , y_train ) beta_0 = betas [ 0 ] beta_1 = betas [ 1 ] print ( \"The best-fit line is {0:8.6f} + {1:8.6f} * x\" . format ( beta_0 , beta_1 )) Reshaping features array. Reshaping observations array. The best-fit line is 0.666667 + 1.000000 * x Exercise (5 min) Do the values of beta0 and beta1 seem reasonable? Plot the training data using a scatter plot. Plot the best fit line with beta0 and beta1 together with the training data. In [65]: fig_scat , ax_scat = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) # Plot best-fit line x_train = np . array ([[ 1 , 2 , 3 ]]) . T best_fit = beta_0 + beta_1 * x_train ax_scat . scatter ( x_train , y_train , s = 300 , label = 'Training Data' ) ax_scat . plot ( x_train , best_fit , ls = '--' , label = 'Best Fit Line' ) ax_scat . set_xlabel ( r '$x_ {train} $' ) ax_scat . set_ylabel ( r '$y$' ); The values of beta0 and beta1 seem roughly reasonable. They capture the positive correlation. The line does appear to be trying to get as close as possible to all the points. Building a model with statsmodels and sklearn Now that we can concretely fit the training data from scratch, let's learn two python packages to do it all for us: statsmodels and scikit-learn (sklearn) . Our goal is to show how to implement simple linear regression with these packages. For an important sanity check, we compare the $\\beta$ values from statsmodels and sklearn to the $\\beta$ values that we found from above with our own implementation. For the purposes of this lab, statsmodels and sklearn do the same thing. More generally though, statsmodels tends to be easier for inference [finding the values of the slope and intercept and dicussing uncertainty in those values], whereas sklearn has machine-learning algorithms and is better for prediction [guessing y values for a given x value]. (Note that both packages make the same guesses, it's just a question of which activity they provide more support for. Note: statsmodels and sklearn are different packages! Unless we specify otherwise, you can use either one. Below is the code for statsmodels . Statsmodels does not by default include the column of ones in the $X$ matrix, so we include it manually with sm.add_constant . In [58]: import statsmodels.api as sm In [66]: # create the X matrix by appending a column of ones to x_train X = sm . add_constant ( x_train ) # this is the same matrix as in our scratch problem! print ( X ) # build the OLS model (ordinary least squares) from the training data toyregr_sm = sm . OLS ( y_train , X ) # do the fit and save regression info (parameters, etc) in results_sm results_sm = toyregr_sm . fit () # pull the beta parameters out from results_sm beta0_sm = results_sm . params [ 0 ] beta1_sm = results_sm . params [ 1 ] print ( \"The regression coefficients from the statsmodels package are: beta_0 = {0:8.6f} and beta_1 = {1:8.6f} \" . format ( beta0_sm , beta1_sm )) [[ 1. 1.] [ 1. 2.] [ 1. 3.]] The regression coefficients from the statsmodels package are: beta_0 = 0.666667 and beta_1 = 1.000000 Besides the beta parameters, results_sm contains a ton of other potentially useful information. In [60]: import warnings warnings . filterwarnings ( 'ignore' ) print ( results_sm . summary ()) OLS Regression Results ============================================================================== Dep. Variable: y R-squared: 0.750 Model: OLS Adj. R-squared: 0.500 Method: Least Squares F-statistic: 3.000 Date: Fri, 21 Sep 2018 Prob (F-statistic): 0.333 Time: 11:31:12 Log-Likelihood: -2.0007 No. Observations: 3 AIC: 8.001 Df Residuals: 1 BIC: 6.199 Df Model: 1 Covariance Type: nonrobust ============================================================================== coef std err t P>|t| [0.025 0.975] ------------------------------------------------------------------------------ const 0.6667 1.247 0.535 0.687 -15.181 16.514 x1 1.0000 0.577 1.732 0.333 -6.336 8.336 ============================================================================== Omnibus: nan Durbin-Watson: 3.000 Prob(Omnibus): nan Jarque-Bera (JB): 0.531 Skew: -0.707 Prob(JB): 0.767 Kurtosis: 1.500 Cond. No. 6.79 ============================================================================== Warnings: [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. Now let's turn our attention to the sklearn library. In [67]: from sklearn import linear_model In [68]: # build the least squares model toyregr = linear_model . LinearRegression () # save regression info (parameters, etc) in results_skl results = toyregr . fit ( x_train , y_train ) # pull the beta parameters out from results_skl beta0_skl = toyregr . intercept_ beta1_skl = toyregr . coef_ [ 0 ] print ( \"The regression coefficients from the sklearn package are: beta_0 = {0:8.6f} and beta_1 = {1:8.6f} \" . format ( beta0_skl , beta1_skl )) The regression coefficients from the sklearn package are: beta_0 = 0.666667 and beta_1 = 1.000000 We should feel pretty good about ourselves now, and we're ready to move on to a real problem! The shape of things in scikit-learn Before diving right in to a \"real\" problem, we really ought to discuss more of the details of sklearn . We do this now. Along the way, we'll import the real-world dataset. Scikit-learn is the main python machine learning library. It consists of many learners which can learn models from data, as well as a lot of utility functions such as train_test_split . It can be used in python by the incantation import sklearn . In scikit-learn, an estimator is a Python object that implements the methods fit(X, y) and predict(T) Let's see the structure of scikit-learn needed to make these fits. .fit always takes two arguments: estimator . fit ( Xtrain , ytrain ) We will consider two estimators in this lab: LinearRegression and KNeighborsRegressor . Critically, Xtrain must be in the form of an array of arrays (or a 2x2 array) with the inner arrays each corresponding to one sample, and whose elements correspond to the feature values for that sample (visuals coming in a moment). ytrain on the other hand is a simple array of responses. These are continuous for regression problems. Practice with sklearn We begin by loading up the mtcars dataset and cleaning it up a little bit. In [73]: import pandas as pd #load mtcars dfcars = pd . read_csv ( \"data/mtcars.csv\" ) dfcars = dfcars . rename ( columns = { \"Unnamed: 0\" : \"car name\" }) dfcars . head () Out[73]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } car name mpg cyl disp hp drat wt qsec vs am gear carb 0 Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 1 Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 2 Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 3 Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 4 Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 Next, let's split the dataset into a training set and test set. In [74]: # split into training set and testing set from sklearn.model_selection import train_test_split #set random_state to get the same split every time traindf , testdf = train_test_split ( dfcars , test_size = 0.2 , random_state = 42 ) In [75]: # testing set is around 20% of the total data; training set is around 80% print ( \"Shape of full dataset is: {0} \" . format ( dfcars . shape )) print ( \"Shape of training dataset is: {0} \" . format ( traindf . shape )) print ( \"Shape of test dataset is: {0} \" . format ( testdf . shape )) Shape of full dataset is: (32, 12) Shape of training dataset is: (25, 12) Shape of test dataset is: (7, 12) Now we have training and test data. We still need to select a predictor and a response from this dataset. Keep in mind that we need to choose the predictor and response from both the training and test set. You will do this in the exercises below. However, we provide some starter code for you to get things going. In [76]: # Extract the response variable that we're interested in y_train = traindf . mpg Notice the shape of y_train . In [77]: np . shape ( y_train ) Out[77]: (25,) Another way to see the shape is to use the shape method. In [78]: y_train . shape Out[78]: (25,) This is not an \"array of arrays\". That's okay! Remember, sklearn requires an array of arrays only for the predictor array! You will have to pay close attention to this in the exercises later. For now, let's discuss two ways out of this debacle. All we'll do is get y_train to be an array of arrays. This doesn't hurt anything because sklearn doesn't care too much about the shape of y_train . First, let's reshape y_train to be an array of arrays using the reshape method. We want the first dimension of y_train to be size $25$ and the second dimension to be size $1$. In [79]: y_train_reshape = y_train . values . reshape ( y_train . shape [ 0 ], 1 ) In [80]: y_train_reshape . shape Out[80]: (25, 1) Notice that y_train.shape[0] gives the size of the first dimension. There's an even easier way to get the correct shape right from the beginning. In [ ]: y_train_reshape = traindf [[ 'mpg' ]] In [ ]: y_train_reshape . shape Finally, there is a nice shortcut to reshaping an array. numpy can infer a dimension based on the other dimensions specified. In [ ]: y_train_reshape = y_train . values . reshape ( - 1 , 1 ) y_train_reshape . shape In this case, we said the second dimension should be size $1$. Since the requirement of the reshape() method is that the requested dimensions be compatible, numpy decides the the first dimension must be size $25$. What would the .shape return if we did y_train.values.reshape(-1,5) ? Okay, enough of that. The whole reason we went through that whole process was to show you how to reshape your data into the correct format. IMPORTANT: Remember that your response variable ytrain can be a vector but your predictor variable xtrain must be an array! Simple linear regression with automobile data We will now use sklearn to predict automobile mileage per gallon (mpg) and evaluate these predictions. We already loaded the data and split them into a training set and a test set. We need to choose the variables that we think will be good predictors for the dependent variable mpg . Exercise (10 min) Pick one variable to use as a predictor for simple linear regression. Create a markdown cell below and discuss your reasons. Justify your choice with some visualizations. Is there a second variable you'd like to use? For example, we're not doing multiple linear regression here, but if we were, is there another variable you'd like to include if we were using two predictors? In [ ]: # Your code here In [82]: y_mpg = dfcars . mpg x_wt = dfcars . wt x_hp = dfcars . hp fig_wt , ax_wt = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax_wt . scatter ( x_wt , y_mpg ) ax_wt . set_xlabel ( r 'Car Weight' ) ax_wt . set_ylabel ( r 'Car MPG' ) fig_hp , ax_hp = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax_hp . scatter ( x_hp , y_mpg ) ax_hp . set_xlabel ( r 'Car HP' ) ax_hp . set_ylabel ( r 'Car MPG' ) Out[82]: Exercise Use sklearn to fit the training data using simple linear regression. Use the model to make mpg predictions on the test set. Plot the data and the prediction. Print out the mean squared error for the training set and the test set and compare. Hints: Use the following to perform the analysis: from sklearn.linear_model import LinearRegression from sklearn.model_selection import train_test_split from sklearn.metrics import mean_squared_error In [83]: from sklearn.linear_model import LinearRegression from sklearn.model_selection import train_test_split from sklearn.metrics import mean_squared_error dfcars = pd . read_csv ( \"data/mtcars.csv\" ) dfcars = dfcars . rename ( columns = { \"Unnamed: 0\" : \"name\" }) dfcars . head () Out[83]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name mpg cyl disp hp drat wt qsec vs am gear carb 0 Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 1 Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 2 Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 3 Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 4 Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 In [84]: traindf , testdf = train_test_split ( dfcars , test_size = 0.2 , random_state = 42 ) y_train = np . array ( traindf . mpg ) X_train = np . array ( traindf . wt ) X_train = X_train . reshape ( X_train . shape [ 0 ], 1 ) In [85]: y_test = np . array ( testdf . mpg ) X_test = np . array ( testdf . wt ) X_test = X_test . reshape ( X_test . shape [ 0 ], 1 ) #create linear model regression = LinearRegression () #fit linear model regression . fit ( X_train , y_train ) predicted_y = regression . predict ( X_test ) r2 = regression . score ( X_test , y_test ) print ( r2 ) 0.68797618576 In [86]: print ( regression . score ( X_train , y_train )) print ( mean_squared_error ( predicted_y , y_test )) print ( mean_squared_error ( y_train , regression . predict ( X_train ))) print ( 'Coefficients: \\n ' , regression . coef_ [ 0 ], regression . intercept_ ) 0.770137990979 12.4759856599 7.77369776639 Coefficients: -5.33694140056 36.9373103135 In [87]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( y_test , predicted_y , 'o' ) grid = np . linspace ( np . min ( dfcars . mpg ), np . max ( dfcars . mpg ), 100 ) ax . plot ( grid , grid , color = \"black\" ) # 45 degree line ax . set_xlabel ( \"actual y\" ) ax . set_ylabel ( \"predicted y\" ) fig1 , ax1 = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax1 . plot ( dfcars . wt , dfcars . mpg , 'o' ) xgrid = np . linspace ( np . min ( dfcars . wt ), np . max ( dfcars . wt ), 100 ) ax1 . plot ( xgrid , regression . predict ( xgrid . reshape ( 100 , 1 ))) Out[87]: [ ] $k$-nearest neighbors Great, so we did a simple linear regression on the car data. Now that you're familiar with sklearn , you're ready to do a KNN regression. Let's use $5$ nearest neighbors. In [ ]: from sklearn.neighbors import KNeighborsRegressor knnreg = KNeighborsRegressor ( n_neighbors = 5 ) In [ ]: knnreg . fit ( X_train , y_train ) r2 = knnreg . score ( X_test , y_test ) r2 Exercise What is the $R&#94;{2}$ score on the training set? In [ ]: # Your code here In [ ]: # solution knnreg . score ( X_train , y_train ) Lets vary the number of neighbors and see what we get. In [ ]: regdict = {} # Do a bunch of KNN regressions for k in [ 1 , 2 , 4 , 6 , 8 , 10 , 15 ]: knnreg = KNeighborsRegressor ( n_neighbors = k ) knnreg . fit ( X_train , y_train ) regdict [ k ] = knnreg # Store the regressors in a dictionary In [ ]: # Now let's plot it all fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( dfcars . wt , dfcars . mpg , 'o' , label = \"data\" ) xgrid = np . linspace ( np . min ( dfcars . wt ), np . max ( dfcars . wt ), 100 ) for k in [ 1 , 2 , 6 , 10 , 15 ]: predictions = regdict [ k ] . predict ( xgrid . reshape ( 100 , 1 )) if k in [ 1 , 6 , 15 ]: ax . plot ( xgrid , predictions , label = \" {} -NN\" . format ( k )) ax . legend (); Notice how the $1$-NN goes through every point on the training set but utterly fails elsewhere. Lets look at the scores on the training set. In [ ]: ks = range ( 1 , 15 ) # Grid of k's scores_train = [] # R2 scores for k in ks : knnreg = KNeighborsRegressor ( n_neighbors = k ) # Create KNN model knnreg . fit ( X_train , y_train ) # Fit the model to training data score_train = knnreg . score ( X_train , y_train ) # Calculate R&#94;2 score scores_train . append ( score_train ) # Plot fig , ax = plt . subplots ( 1 , 1 , figsize = ( 12 , 8 )) ax . plot ( ks , scores_train , 'o-' ) ax . set_xlabel ( r '$k$' ) ax . set_ylabel ( r '$R&#94; {2} $' ) Why do we get a perfect $R&#94;2$ at k=1? Exercise (5 min) Make the same plot as above on the test set. What is the best $k$? In [ ]: ks = range ( 1 , 15 ) # Grid of k's scores_test = [] # R2 scores for k in ks : knnreg = KNeighborsRegressor ( n_neighbors = k ) # Create KNN model knnreg . fit ( X_train , y_train ) # Fit the model to training data score_test = knnreg . score ( X_test , y_test ) # Calculate R&#94;2 score scores_test . append ( score_test ) # Plot fig , ax = plt . subplots ( 1 , 1 , figsize = ( 12 , 8 )) ax . plot ( ks , scores_test , 'o-' , ms = 12 ) ax . set_xlabel ( r '$k$' ) ax . set_ylabel ( r '$R&#94; {2} $' ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab-3/solutions/"}]}