{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"padding-top: 25px;padding-bottom: 25px;text-align: left; padding-left: 10px; background-color: #DDDDDD; \n",
    "    color: black;\"> <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science </h1>\n",
    "\n",
    "## Homework 1: Data Collection - Web Scraping - Data Parsing\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2019**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Kevin Rader, and Chris Tanner\n",
    "\n",
    "\n",
    "\n",
    "<hr style='height:2px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RUN THIS CELL TO GET THE RIGHT FORMATTING \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions\n",
    "- To submit your assignment follow the instructions given in Canvas.\n",
    "- The deliverables to be submitted in Canvas are: <br/>\n",
    "    a) this python notebook with your code and answers<br/>\n",
    "    b) the bibtex file, `publist.bib`, you created<br/>\n",
    "    c) the CSV file, `publist.csv`, you created <br/>\n",
    "    d) The JSON file, `publist.json` you created<br/>\n",
    "    \n",
    "- Exercise **responsible scraping**. Web servers can become slow or unresponsive if they receive too many requests from the same source in a short amount of time. Use a delay of 10 seconds between requests in your code. This helps not to get blocked by the target website. Run the webpage fetching part of the homework only once and do not re-run after you have saved the results in the JSON file (details below). \n",
    "- Web scraping requests can take several minutes. This is another reason why you should not wait until the last minute to do this homework.\n",
    "\n",
    "\n",
    "\n",
    "# Data Collection - Web Scraping - Data Parsing \n",
    " \n",
    "\n",
    "In this homework, your goal is to learn how to acquire, parse, clean, and analyze data. Initially you will read the data from a file, and then later scrape them directly from a website. You will look for specific pieces of information by parsing the data, clean the data to prepare them for analysis, and finally, answer some questions.\n",
    "\n",
    "In doing so you will get more familiar with three of the common file formats for storing and transferring data, which are:\n",
    "- CSV, a text-based file format used for storing tabular data that are separated by some delimiter, usually comma or space.\n",
    "- HTML/XML.\n",
    "- JavaScript Object Notation (JSON), a text-based open standard designed for transmitting structured data over the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Help a professor parse their publications and extract information.\n",
    "\n",
    "### Overview\n",
    "\n",
    "In this part your goal is to parse the HTML page of a professor containing some of his/her publications, and answer some questions. This page is provided to you in the file `data/publist_super_clean.html`. There are 45 publications in descending order from No. 244 to No. 200.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this file \n",
    "PUB_FILENAME = 'data/publist_super_clean.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Question 1 [40 pts]: Parsing and Converting to bibTex and CSV using Beautiful Soup and python string manipulation </b></div>\n",
    "\n",
    "A lot of the bibliographic and publication information is displayed in various websites in a not-so-structured HTML files. Some publishers prefer to store and transmit this information in a .bibTex file which looks roughly like this (we've simplified a few things):\n",
    "```\n",
    "@article { \n",
    "     author = \"John Doyle\",\n",
    "     title = \"Interaction between atoms\",\n",
    "     URL = \"Papers/PhysRevB_81_085406_2010.pdf\",\n",
    "     journal = \"Phys. Rev. B\",\n",
    "     volume = \"81\"\n",
    "}\n",
    "```\n",
    "You will notice that this file format is a set of items, each of which is a set of key-value pairs. In the python world, you can think of this as a list of dictionaries.\n",
    "Each line is an item, and has multiple features, or keys, as represented by that line's value for the column corresponding to the key.\n",
    "\n",
    "You are given an .html file containing a list of papers scraped from the author's website and you are to write the information into .bibTex and .CSV formats. A useful tool for parsing an .html file is BeautifulSoup  (http://www.crummy.com/software/BeautifulSoup/) (BS), which makes parsing HTML a lot easier.\n",
    "\n",
    "**1.1 [5 pts]** Write a function called `make_soup` that accepts `filename` for the HTML filename as an input and returns a BS object.\n",
    "    \n",
    "**1.2 [25 pts]** Write a function that reads in the BS object, parses it, and converts it into a list of dictionaries.  Each element of this list should correspond to one paper and should have the following format (with different values for each publication):\n",
    "```\n",
    "{'author': 'L.A. Agapito, N. Kioussis and E. Kaxiras',\n",
    " 'title': 'Electric-field control of magnetism in graphene quantum dots:\\n Ab initio calculations',\n",
    " 'URL': 'Papers/PhysRevB_82_201411_2010.pdf',\n",
    " 'journal': 'Phys. Rev. B',\n",
    " 'volume': '82'}\n",
    "```\n",
    "\n",
    "\n",
    "**1.3 [5 pts]** Convert the list of dictionaries into standard .bibTex format using python string manipulation, and write the results into a file called `publist.bib`.\n",
    "\n",
    "**1.4 [5 pts]** Convert the list of dictionaries into standard tabular .csv format using pandas, and write the results into a file called `publist.csv`. The csv file should have a header and no integer index for the rows.\n",
    "\n",
    "    \n",
    "#### HINT \n",
    "- Inspect the HTML code for tags that indicate information chunks such as `title` of the paper.  The `find_all` method of BeautifulSoup might be useful.\n",
    "- Question 1.2 is better handled if you break the code into functions, each performing a small task such as finding the author(s) for each paper. \n",
    "- Question 1.3 is effectively tackled by first using python string formatting on a template string.\n",
    "- Make sure you catch exceptions when needed. \n",
    "- Make sure you check for **missing data** and handle these cases as you see fit. \n",
    "\n",
    "\n",
    "#### Resources\n",
    "- [BeautifulSoup Tutorial](https://www.dataquest.io/blog/web-scraping-tutorial-python/).\n",
    "- More about the [BibTex format](http://www.bibtex.org).<BR>\n",
    "    \n",
    "### Answers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries \n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **1.1 [5 pts]  Write a function called `make_soup` that accepts `filename` for the HTML filename as an input and returns a BS object.**\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_soup(filename: str) -> BeautifulSoup: \n",
    "    '''Open the file and convert into a BS object. \n",
    "       \n",
    "       Args:\n",
    "           filename: A string name of the file.\n",
    "       \n",
    "       Returns:\n",
    "           A BS object containing the HTML page ready to be parsed.\n",
    "    '''\n",
    "    # your code here\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check your code - print the BS object, you should get a familiar HTML page as text\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should look **like** this:\n",
    "```\n",
    "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\"\n",
    "   \"http://www.w3.org/TR/html4/loose.dtd\">\n",
    "\n",
    "<title>Kaxiras E journal publications</title>\n",
    "<head>\n",
    "<meta content=\"text/html;charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
    "<link href=\"../styles/style_pubs.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
    "<meta content=\"\" name=\"description\"/>\n",
    "<meta content=\"Kaxiras E, Multiscale Methods, Computational Materials\" name=\"keywords\"/>\n",
    "</head>\n",
    "<body>\n",
    "<ol start=\"244\">\n",
    "<li>\n",
    "<a href=\"Papers/2011/PhysRevB_84_125411_2011.pdf\" target=\"paper244\">\n",
    "\"Approaching the intrinsic band gap in suspended high-mobility graphene nanoribbons\"</a>\n",
    "<br/>Ming-Wei Lin, Cheng Ling, Luis A. Agapito, Nicholas Kioussis, Yiyang Zhang, Mark Ming-Cheng Cheng,\n",
    "<i>PHYSICAL REVIEW B </i> <b>84</b>,  125411 (2011)\n",
    "<br/>\n",
    "</li>\n",
    "</ol>\n",
    "<ol start=\"243\">\n",
    "<li>\n",
    "<a href=\"Papers/2011/PhysRevB_84_035325_2011.pdf\" target=\"paper243\">\n",
    "\"Effect of symmetry breaking on the optical absorption of semiconductor nanoparticles\"</a>\n",
    "<br/>JAdam Gali, Efthimios Kaxiras, Gergely T. Zimanyi, Sheng Meng,\n",
    "<i>PHYSICAL REVIEW B </i> <b>84</b>,  035325 (2011)\n",
    "<br/>\n",
    "</li>\n",
    "</ol>\n",
    "\n",
    "...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 [25 pts] Write a function that reads in the BS object, parses it, and converts it into a list of dictionaries.  Each element of this list should correspond to one paper and should have the following format (with different values for each publication):**\n",
    "```\n",
    "{'author': 'L.A. Agapito, N. Kioussis and E. Kaxiras',\n",
    " 'title': 'Electric-field control of magnetism in graphene quantum dots:\\n Ab initio calculations',\n",
    " 'URL': 'Papers/PhysRevB_82_201411_2010.pdf',\n",
    " 'journal': 'Phys. Rev. B',\n",
    " 'volume': '82'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3 [5 pts] Convert the list of dictionaries into standard .bibTex format using python string manipulation, and write the results into a file called `publist.bib`.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4 [5 pts] Convert the list of dictionaries into standard tabular .csv format using pandas, and write the results into a file called `publist.csv`. The csv file should have a header and no integer index.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:2px'>\n",
    "\n",
    "## Follow the stars in IMDb's list of \"The Top 100 Stars for 2017\" \n",
    "\n",
    "### Overview\n",
    "In this part, your goal is to extract information from IMDb's Top 100 Stars for 2017 (https://www.imdb.com/list/ls025814950/) and perform some analysis on each star in the list. In particular we are interested to know: \n",
    "+ how many performers made their first movie at age 17? \n",
    "+ how many performers started as child actors? \n",
    "+ who is the most prolific actress or actor in IMDb's list of the Top 100 Stars for 2017? \n",
    "\n",
    "These questions are addressed in more details in the questions below. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Question 2 [60 pts]: Web Scraping using Beautiful Soup and exploring using Pandas </b></div>\n",
    "\n",
    "**2.1 [5 pts]** Download the webpage of the \"Top 100 Stars for 2017\" (https://www.imdb.com/list/ls025814950/) into a `requests` object and name it `my_page`. Explain what the following attributes are (1 or 2 sentences for each):\n",
    "\n",
    "- `my_page.text`, \n",
    "- `my_page.status_code`,\n",
    "- `my_page.content`.\n",
    "\n",
    "**2.2 [5 pts]** Create a Beautiful Soup object named `star_soup` using `my_page` as input.\n",
    "\n",
    "**2.3 [15 pts]** Write a function called `parse_stars` that accepts `star_soup` as its input and generates a list of dictionaries named `starlist` (see definition below). The order of dictionaries does not matter. One of the fields of this dictionary is the `url` of each star's individual page, which you need to save in the `page` field. Note that there is a ton of information about each star on these webpages. Each dictionary corresponds to a star profile and it should have the following data:\n",
    "\n",
    "```\n",
    "name: the name of the actor/actress as it appears at the top\n",
    "gender: 0 or 1: translate the word 'actress' into 1 and 'actor' into '0'\n",
    "url: the url of the link under their name that leads to a page with details\n",
    "page: BS object with html text acquired by scraping the above 'url' page' \n",
    "```\n",
    "\n",
    "\n",
    "**2.4 [15 pts]** Write a function called `create_star_table`, which takes `starlist` as an input and extracts information about each star (see function definition for the exact information to be extracted and the exact output definition).  Only extract information from the first box on each star's page. If the first box is acting, consider only acting credits and the star's acting debut, if the first box is Directing, consider only directing credits and directorial debut.\n",
    "\n",
    "   \n",
    "**2.6 [10 pts]** We provide a JSON file called `data/staff_starinfo.json` created by CS109 teaching staff for consistency, which you should use for the rest of the homework. Import the contents of this JSON file  into a pandas dataframe called `frame`. Check the types of variables in each column and clean these variables if needed. Add a new column to your dataframe with the age of each actor when they made their first appearance, movie or TV, (name this column `age_at_first_movie`). Check some of the values of this new column. Do you find any problems? You don't need to fix them.\n",
    "\n",
    "**2.7 [6 pts]** You are now ready to answer the following intriguing questions: \n",
    "- **2.7.1** How many performers made their first appearance (movie or TV) when he/she was 17 years old?\n",
    "\n",
    "- **2.7.2** How many performers started as child actors? Define child actor as a person younger than 12 years old. \n",
    "\n",
    "**2.8 [2 pts]** Make a plot of the number of credits against the name of actor/actress. Who is the most prolific actress or actor in IMDb's list of the Top 100 Stars for 2017? Define **most prolific** as the performer with the most credits.\n",
    "    \n",
    "**2.9 [2 pts]** In 4 or fewer sentences, comment on what you see in the plots above.  Are there any surprises or patterns?  Please **have some fun** with this question.\n",
    "     \n",
    "### Hints\n",
    "- Create a variable that groups actors/actresses by the age of their first movie. Use pandas' `.groupby` to divide the dataframe into groups of performers that for example started performing as children (age $<$ 12). The grouped variable is a `GroupBy` pandas object and this object has all of the information needed to then apply operations to each of the groups.\n",
    "- When cleaning the data make sure the variables with which you are performing calculations are in numerical format.\n",
    "- The column with the year has some values that are double, e.g. **'2000-2001'** and the column with age has some empty cells. You need to deal with these in a reasonable fashion before performing calculations on the data. \n",
    "- You should include both movies and TV shows.\n",
    "    \n",
    "### Resources\n",
    "- The `requests` library makes working with HTTP requests easy. For more on the `requests` library see http://docs.python-requests.org/\n",
    "\n",
    "### Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 [5 pts] Download the webpage of the \"Top 100 Stars for 2017\" (https://www.imdb.com/list/ls025814950/) into a `requests` object and name it `my_page`. Explain what the following attributes are (1 or 2 sentences for each):**\n",
    "\n",
    "- `my_page.text`, \n",
    "- `my_page.status_code`,\n",
    "- `my_page.content`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 [5 pts] Create a Beautiful Soup object named `star_soup` using `my_page` as input.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check your code - you should see a familiar HTML code\n",
    "print (star_soup.prettify()[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 [15 pts] Write a function called `parse_stars` that accepts `star_soup` as its input and generates a list of dictionaries named `starlist` (see definition below)....**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Function\n",
    "--------\n",
    "parse_stars\n",
    "\n",
    "Input\n",
    "------\n",
    "star_soup: the soup object with the scraped page\n",
    "   \n",
    "Returns\n",
    "-------\n",
    "a list of dictionaries; each dictionary corresponds to a star profile and has the following data:\n",
    "\n",
    "    name: the name of the actor/actress as it appears at the top\n",
    "    gender: 0 or 1: translate the word 'actress' into 1 and 'actor' into '0'\n",
    "    url: the url of the link under their name that leads to a page with details\n",
    "    page: BS object with 'html text acquired by scraping the above 'url' page' \n",
    "\n",
    "Example:\n",
    "--------\n",
    "{'name': Tom Hardy,\n",
    "  'gender': 0,\n",
    "  'url': https://www.imdb.com/name/nm0362766/?ref_=nmls_hd,\n",
    "  'page': BS object with 'html text acquired by scraping the 'url' page'\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should give you 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(starlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check your code\n",
    "# this list is large because of the html code into the `page` field\n",
    "# to get a better picture, print only the first element\n",
    "starlist[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should look like this:\n",
    "```\n",
    "{'name': 'Gal Gadot',\n",
    " 'gender': 1,\n",
    " 'url': 'https://www.imdb.com/name/nm2933757?ref_=nmls_hd',\n",
    " 'page': \n",
    " <!DOCTYPE html>\n",
    " \n",
    " <html xmlns:fb=\"http://www.facebook.com/2008/fbml\" xmlns:og=\"http://ogp.me/ns#\">\n",
    " <head>\n",
    " <meta charset=\"utf-8\"/>\n",
    " <meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
    " <meta content=\"app-id=342792525, app-argument=imdb:///name/nm2933757?src=mdot\" name=\"apple-itunes-app\"/>\n",
    " <script type=\"text/javascript\">var IMDbTimer={starttime: new Date().getTime(),pt:'java'};</script>\n",
    " <script>\n",
    "     if (typeof uet == 'function') {\n",
    "       uet(\"bb\", \"LoadTitle\", {wb: 1});\n",
    "     }\n",
    " </script>\n",
    " <script>(function(t){ (t.events = t.events || {})[\"csm_head_pre_title\"] = new Date().getTime(); })(IMDbTimer);</script>\n",
    " \n",
    "... \n",
    "\n",
    "\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4 [15 pts] Write a function called `create_star_table`, which takes `starlist` as an input and extracts information about each star (see function definition for the exact information to be extracted and the exact output definition).  Only extract information from the first box on each star's page. If the first box is acting, consider only acting credits and the star's acting debut, if the first box is Directing, consider only directing credits and directorial debut.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Function\n",
    "--------\n",
    "create_star_table\n",
    "\n",
    "Input\n",
    "------\n",
    "the starlist\n",
    "   \n",
    "Returns\n",
    "-------\n",
    "\n",
    "a list of dictionaries; each dictionary corresponds to a star profile and has the following data:\n",
    "\n",
    "    star_name: the name of the actor/actress as it appears at the top\n",
    "    gender: 0 or 1 (1 for 'actress' and 0 for 'actor')  \n",
    "    year_born : year they were born\n",
    "    first_movie: title of their first movie or TV show\n",
    "    year_first_movie: the year they made their first movie or TV show\n",
    "    credits: number of movies or TV shows they have made in their career.\n",
    "    \n",
    "--------\n",
    "Example:\n",
    "\n",
    "{'star_name': Tom Hardy,\n",
    "  'gender': 0,\n",
    "  'year_born': 1997,\n",
    "  'first_movie' : 'Batman',\n",
    "  'year_first_movie' : 2017,\n",
    "  'credits' : 24}\n",
    "  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_star_table(starlist: list) -> list:\n",
    "# your code here\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check your code\n",
    "star_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should look like this (the order of elements is not important):\n",
    "```\n",
    "[{'name': 'Gal Gadot',\n",
    "  'gender': 1,\n",
    "  'year_born': '1985',\n",
    "  'first_movie': 'Bubot',\n",
    "  'year_first_movie': '2007',\n",
    "  'credits': '25'},\n",
    " {'name': 'Tom Hardy',\n",
    "  'gender': 0,\n",
    "  'year_born': '1977',\n",
    "  'first_movie': 'Tommaso',\n",
    "  'year_first_movie': '2001',\n",
    "  'credits': '55'},\n",
    "  \n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5 [4 pts] Now that you have scraped all the info you need, it's good practice to save the last data structure you created to disk. Save the data structure to a JSON file named `starinfo.json` and submit this JSON file in Canvas. If you do this, if you have to restart, you won't need to redo all the requests and parsings from before.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check your JSON saving, re-open the JSON file and reload the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"starinfo.json\", \"r\") as fd:\n",
    "    star_table = json.load(fd)\n",
    "    \n",
    "# output should be the same\n",
    "star_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.6 [10 pts] We provide a JSON file called `data/staff_starinfo.json` created by CS109 teaching staff for consistency, which you should use for the rest of the homework. Import the contents of this JSON file  into a pandas dataframe called `frame`. Check the types of variables in each column and clean these variables if needed. Add a new column to your dataframe with the age of each actor when they made their first appearance, movie or TV, (name this column `age_at_first_movie`). Check some of the values of this new column. Do you find any problems? You don't need to fix them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.7 [6 pts] You are now ready to answer the following intriguing questions:**\n",
    "- **2.7.1** How many performers made their first appearance (movie or TV) when he/she was 17 years old?\n",
    "- **2.7.2** How many performers started as child actors? Define child actor as a person younger than 12 years old. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**2.8 [2 pts] Make a plot of the number of credits against the name of actor/actress. Who is the most prolific actress or actor in IMDb's list of the Top 100 Stars for 2017? Define *most prolific* as the performer with the most credits.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.9 [2 pts]** In 4 or fewer sentences, comment on what you see in the plots above.  Are there any surprises or patterns?  Please **have some fun** with this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
